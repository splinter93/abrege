#!/usr/bin/env node

/**
 * üîß Script de correction automatique du streaming Groq
 * Corrige les probl√®mes critiques de streaming identifi√©s dans l'audit
 */

const fs = require('fs');
const path = require('path');

const GROQ_FILE_PATH = path.join(__dirname, '../src/services/llm/groqGptOss120b.ts');

console.log('üîß Correction automatique du streaming Groq...');

// Lire le fichier actuel
let content = fs.readFileSync(GROQ_FILE_PATH, 'utf8');

// 1. Corriger le BATCH_SIZE et ajouter les constantes
content = content.replace(
  /const BATCH_SIZE = 20;.*?const MAX_FLUSH_RETRIES = 3;/s,
  `const BATCH_SIZE = 50; // ‚úÖ CORRECTION CRITIQUE: De 20 √† 50 pour √©liminer les saccades
  const MAX_FLUSH_RETRIES = 5; // ‚úÖ AUGMENT√â: De 3 √† 5 pour plus de robustesse
  const STREAM_TIMEOUT = 30000; // ‚úÖ NOUVEAU: Timeout de s√©curit√© 30s`
);

// 2. Remplacer la section de streaming probl√©matique
const OLD_STREAMING_SECTION = `  // ‚úÖ NOUVEAU: Timeout de s√©curit√© pour √©viter les blocages infinis
  const streamPromise = (async () => {
    while (true) {
      const { done, value } = await reader.read();
      if (done) {
        logger.info('[Groq OSS] üéâ reader.read() ‚Üí done');
        break;
      }
      
      // ‚úÖ CORRECTION: Gestion robuste des chunks
      const chunk = new TextDecoder().decode(value);
      
      // ‚úÖ AM√âLIORATION: Gestion des chunks incomplets avec timeout
      if (pendingDataLine && !chunk.includes('\\n')) {
        // Si on a du pending et que le chunk n'a pas de newline, c'est probablement un JSON incomplet
        pendingDataLine += chunk;
        logger.dev(\`[Groq OSS] üîÑ Chunk incomplet accumul√© (\${chunk.length} chars), total pending: \${pendingDataLine.length}\`);
        continue;
      }
      
      const lines = chunk.split('\\n');
      
      for (let i = 0; i < lines.length; i++) {
        const line = lines[i];
        if (!line.startsWith('data: ')) continue;
        
        const data = line.slice(6);
        if (data === '[DONE]') break;
        
        try {
          // ‚úÖ CORRECTION: Gestion robuste du pendingDataLine
          const toParse = pendingDataLine + data;
          let parsed: any;
          
          try { 
            parsed = JSON.parse(toParse); 
            pendingDataLine = ''; // ‚úÖ Reset seulement si parsing r√©ussi
          } catch (parseError) { 
            // ‚úÖ AM√âLIORATION: Log du probl√®me de parsing
            if (toParse.length > 100) {
              logger.warn(\`[Groq OSS] ‚ö†Ô∏è JSON incomplet d√©tect√© (\${toParse.length} chars), accumulation...\`);
            }
            pendingDataLine = toParse; 
            continue; 
          }
          
          const delta = parsed.choices?.[0]?.delta;
          if (!delta) continue;
          
          if (delta.reasoning && delta.channel === 'analysis') {
            await channel.send({ type: 'broadcast', event: 'llm-reasoning', payload: { reasoning: delta.reasoning, sessionId } });
            logger.info(\`[Groq OSS] üß† Reasoning chunk: \${delta.reasoning}\`);
            continue;
          }
          
          // Collect tool calls only here; broadcast once later with persistence
          if (delta.tool_calls) {
            for (const toolCall of delta.tool_calls) {
              const id = toolCall.id || \`call_\${Date.now()}_\${Math.random().toString(36).slice(2)}\`;
              if (!toolCallMap[id]) {
                toolCallMap[id] = { id, name: toolCall.function?.name || '', arguments: toolCall.function?.arguments || '' };
                toolCallOrder.push(id);
              } else {
                if (toolCall.function?.name) toolCallMap[id].name = toolCall.function.name;
                if (toolCall.function?.arguments) toolCallMap[id].arguments += toolCall.function?.arguments;
              }
            }
          } else {
            const token =
              delta.content ??
              delta.message?.content ??
              (typeof delta.text === 'string' ? delta.text : undefined) ??
              (typeof (delta as any).output_text === 'string' ? (delta as any).output_text : undefined);
              
            if (token) {
              accumulatedContent += token;
              tokenBuffer += token;
              bufferSize++;
              
              // ‚úÖ CORRECTION: Flush plus fr√©quent pour √©viter la perte de tokens
              if (bufferSize >= BATCH_SIZE) {
                await flushTokenBuffer();
              }
            }
          }
        } catch (parseError) {
          // ‚úÖ AM√âLIORATION: Log des erreurs de parsing
          logger.warn(\`[Groq OSS] ‚ö†Ô∏è Erreur parsing ligne: \${line.substring(0, 100)}...\`, parseError);
          continue;
        }
      }
    }
  } catch (err) {
    logger.error('[Groq OSS] ‚ùå Streaming read error:', err);
    throw err;
  }`;

const NEW_STREAMING_SECTION = `  try {
    // ‚úÖ NOUVEAU: Timeout de s√©curit√© pour √©viter les blocages infinis
    const streamPromise = (async () => {
      while (true) {
        const { done, value } = await reader.read();
        if (done) {
          logger.info('[Groq OSS] üéâ reader.read() ‚Üí done');
          break;
        }
        
        // ‚úÖ CORRECTION: Gestion robuste des chunks
        const chunk = new TextDecoder().decode(value);
        
        // ‚úÖ AM√âLIORATION: Gestion des chunks incomplets avec timeout
        if (pendingDataLine && !chunk.includes('\\n')) {
          // Si on a du pending et que le chunk n'a pas de newline, c'est probablement un JSON incomplet
          pendingDataLine += chunk;
          logger.dev(\`[Groq OSS] üîÑ Chunk incomplet accumul√© (\${chunk.length} chars), total pending: \${pendingDataLine.length}\`);
          continue;
        }
        
        const lines = chunk.split('\\n');
        
        for (let i = 0; i < lines.length; i++) {
          const line = lines[i];
          if (!line.startsWith('data: ')) continue;
          
          const data = line.slice(6);
          if (data === '[DONE]') break;
          
          try {
            // ‚úÖ CORRECTION: Gestion robuste du pendingDataLine
            const toParse = pendingDataLine + data;
            let parsed: any;
            
            try { 
              parsed = JSON.parse(toParse); 
              pendingDataLine = ''; // ‚úÖ Reset seulement si parsing r√©ussi
            } catch (parseError) { 
              // ‚úÖ AM√âLIORATION: Log du probl√®me de parsing
              if (toParse.length > 100) {
                logger.warn(\`[Groq OSS] ‚ö†Ô∏è JSON incomplet d√©tect√© (\${toParse.length} chars), accumulation...\`);
              }
              pendingDataLine = toParse; 
              continue; 
            }
            
            const delta = parsed.choices?.[0]?.delta;
            if (!delta) continue;
            
            if (delta.reasoning && delta.channel === 'analysis') {
              await channel.send({ type: 'broadcast', event: 'llm-reasoning', payload: { reasoning: delta.reasoning, sessionId } });
              logger.info(\`[Groq OSS] üß† Reasoning chunk: \${delta.reasoning}\`);
              continue;
            }
            
            // Collect tool calls only here; broadcast once later with persistence
            if (delta.tool_calls) {
              for (const toolCall of delta.tool_calls) {
                const id = toolCall.id || \`call_\${Date.now()}_\${Math.random().toString(36).slice(2)}\`;
                if (!toolCallMap[id]) {
                  toolCallMap[id] = { id, name: toolCall.function?.name || '', arguments: toolCall.function?.arguments || '' };
                  toolCallOrder.push(id);
                } else {
                  if (toolCall.function?.name) toolCallMap[id].name = toolCall.function.name;
                  if (toolCall.function?.arguments) toolCallMap[id].arguments += toolCall.function?.arguments;
                }
              }
            } else {
              const token =
                delta.content ??
                delta.message?.content ??
                (typeof delta.text === 'string' ? delta.text : undefined) ??
                (typeof (delta as any).output_text === 'string' ? (delta as any).output_text : undefined);
                
              if (token) {
                accumulatedContent += token;
                tokenBuffer += token;
                bufferSize++;
                
                // ‚úÖ CORRECTION: Flush plus fr√©quent pour √©viter la perte de tokens
                if (bufferSize >= BATCH_SIZE) {
                  await flushTokenBuffer();
                }
              }
            }
          } catch (parseError) {
            // ‚úÖ AM√âLIORATION: Log des erreurs de parsing
            logger.warn(\`[Groq OSS] ‚ö†Ô∏è Erreur parsing ligne: \${line.substring(0, 100)}...\`, parseError);
            continue;
          }
        }
      }
    })();

    // ‚úÖ NOUVEAU: Race entre le streaming et le timeout de s√©curit√©
    const timeoutPromise = new Promise((_, reject) => {
      setTimeout(() => reject(new Error('Stream timeout - 30 secondes d√©pass√©es')), STREAM_TIMEOUT);
    });
    
    await Promise.race([streamPromise, timeoutPromise]);
    logger.info('[Groq OSS] ‚úÖ Streaming termin√© avec succ√®s');
  } catch (err) {
    if (err instanceof Error && err.message.includes('Stream timeout')) {
      logger.error('[Groq OSS] ‚ùå Timeout de s√©curit√© atteint - arr√™t forc√© du streaming');
      // Forcer le flush du buffer restant
      await flushTokenBuffer(0, true);
    } else {
      logger.error('[Groq OSS] ‚ùå Streaming read error:', err);
      throw err;
    }
  }`;

// Remplacer la section
if (content.includes(OLD_STREAMING_SECTION)) {
  content = content.replace(OLD_STREAMING_SECTION, NEW_STREAMING_SECTION);
  console.log('‚úÖ Section de streaming corrig√©e');
} else {
  console.log('‚ö†Ô∏è Section de streaming non trouv√©e, v√©rification manuelle requise');
}

// Sauvegarder le fichier corrig√©
fs.writeFileSync(GROQ_FILE_PATH, content, 'utf8');

console.log('‚úÖ Fichier Groq corrig√© avec succ√®s !');
console.log('üìã R√©sum√© des corrections appliqu√©es :');
console.log('   - BATCH_SIZE augment√© de 20 √† 50');
console.log('   - MAX_FLUSH_RETRIES augment√© de 3 √† 5');
console.log('   - STREAM_TIMEOUT ajout√© (30 secondes)');
console.log('   - Structure de streaming corrig√©e');
console.log('   - Timeout de s√©curit√© impl√©ment√©');
console.log('');
console.log('üöÄ Le streaming devrait maintenant √™tre beaucoup plus stable !'); 