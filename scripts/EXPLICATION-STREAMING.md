# Explication : Streaming vs Endpoint Classique

## üéØ Endpoint Classique (√Ä UTILISER NORMALEMENT)

**Endpoint** : `POST /api/v2/note/{ref}/content:apply`

**Payload normal** :
```json
{
  "ops": [{
    "id": "op-123",
    "action": "insert",
    "target": {
      "type": "position",
      "position": { "mode": "end" }
    },
    "where": "at",
    "content": "Ton texte complet ici, pas besoin de chunks !"
  }]
}
```

**‚úÖ C'est ce que le LLM doit utiliser normalement.**

---

## üåä Streaming (OPTIONNEL - Juste pour l'affichage progressif)

**Endpoint** : `POST /api/v2/note/{ref}/stream:write`

**Les "chunks"** = petits morceaux de texte envoy√©s progressivement pour l'affichage en temps r√©el.

**Exemple** :
```json
// Chunk 1
{ "chunk": "Hello ", "position": "end" }

// Chunk 2
{ "chunk": "world", "position": "end" }

// Chunk 3 (fin)
{ "chunk": "!", "position": "end", "end": true }
```

**‚ö†Ô∏è C'est juste pour l'UX (voir le texte appara√Ætre progressivement).**

**Le LLM n'a PAS besoin d'utiliser √ßa.** Il peut utiliser l'endpoint classique directement.

---

## üîß Pourquoi le streaming ne s'affiche pas ?

Le streaming n√©cessite :
1. ‚úÖ Envoi des chunks via `POST /stream:write` (√ßa marche)
2. ‚ùì √âcoute SSE via `GET /stream:listen` (√† v√©rifier)
3. ‚ùì Hook `useEditorStreamListener` actif (√† v√©rifier)

**Si √ßa ne marche pas, utilise juste l'endpoint classique qui fonctionne d√©j√† !**

