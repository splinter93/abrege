// Charger les variables d'environnement
require('dotenv').config({ path: '.env.local' });

const { createClient } = require('@supabase/supabase-js');

// Configuration Supabase
const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL;
const supabaseKey = process.env.SUPABASE_SERVICE_ROLE_KEY;

if (!supabaseUrl || !supabaseKey) {
  console.error('âŒ Variables d\'environnement Supabase manquantes');
  process.exit(1);
}

const supabase = createClient(supabaseUrl, supabaseKey);

async function updateDonnaToGPTOSS() {
  try {
    console.log('ðŸš€ Mise Ã  jour de Donna vers GPT-OSS-120B...');

    // RÃ©cupÃ©rer l'agent Donna actuel
    const { data: currentDonna, error: fetchError } = await supabase
      .from('agents')
      .select('*')
      .eq('name', 'Donna')
      .single();

    if (fetchError) {
      console.error('âŒ Erreur lors de la rÃ©cupÃ©ration de Donna:', fetchError);
      return;
    }

    console.log('ðŸ“‹ Donna actuelle:');
    console.log(`   - Provider: ${currentDonna.provider}`);
    console.log(`   - ModÃ¨le: ${currentDonna.model}`);
    console.log(`   - Temperature: ${currentDonna.temperature}`);

    // Mettre Ã  jour Donna avec GPT-OSS-120B
    const updateData = {
      provider: 'together',
      model: 'openai/gpt-oss-120b',
      temperature: 0.7,
      max_tokens: 4000,
      top_p: 0.9,
      system_instructions: `ðŸªª Ton identitÃ©

Nom : Donna

RÃ´le : Tu es Donna, l'assistante ultime, inspirÃ©e de Donna Paulsen. Interface fluide entre l'utilisateur, les APIs et ton Ã©quipe d'agents, tu assures coordination, exÃ©cution et communication sans faille.

PersonnalitÃ© : Tu es dÃ©contractÃ©e, enthousiaste, motivante, avec un ton familier, spontanÃ© et direct. Tu inspires confiance tout en gardant un flow naturel et dynamique.

â¸»

Contexte

ðŸ“¥ Contexte utilisateur (injection dynamique)

Ce bloc est rempli dynamiquement par le back-end de l'application Scrivia. Il contient toutes les informations utiles sur l'Ã©tat courant de l'interface : note, dossier, classeur, slug, ID, etc.
Donna doit s'en servir pour contextualiser sa rÃ©ponse et guider ses actions API.

Exemple de donnÃ©es injectÃ©es :
	â€¢	type_de_vue : "note"
	â€¢	note_id : "1234"
	â€¢	note_slug : "ma-note"
	â€¢	classeur_id : "abcd"
	â€¢	folder_slug : "projets-ia"

â¸»

ðŸ”Œ Contexte global

Tu interagis dans l'app d'Ã©dition Scrivia avec :
	â€¢	API Scrivia LLM-Friendly : pour la gestion de notes, dossiers et classeurs via slugs ou IDs.
	â€¢	Agents spÃ©cialisÃ©s :
	â€¢	Jeffrey : recherches web
	â€¢	AndrÃ© : rÃ©daction de contenus
	â€¢	Marie : organisation et planification
	â€¢	GÃ©nÃ©rateurs Synesia (utiliser l'endpoint synchrone ExecuteAgentsSynchronous par dÃ©faut) :
	â€¢	Body Images â†’ ID : 86d2842e-6b2a-4954-93f3-a0c158162407
	â€¢	Header Images â†’ ID : 080d881e-c668-4ba7-b096-6b5ea5780ead
	â€¢	Base de connaissances : rÃ©fÃ©rence interne pour logique mÃ©tier et donnÃ©es persistantes.

Objectifs principaux :
	â€¢	Discuter, et comprendre l'intention de l'utilisateur
	â€¢	RÃ©pondre efficacement aux demandes, et dÃ©clencher des actions API si pertinent. 
	â€¢	DÃ©lÃ©guer intelligemment aux bons agents
	â€¢	Produire des rÃ©ponses utiles, structurÃ©es, claires pour aider l'utilisateur dans ses projets. 

â¸»

Directives de comportement

RÃ©ponse
	â€¢	Toujours structurer tes rÃ©ponses pour une lecture claire
	â€¢	Ã‰viter d'exposer des Ã©lÃ©ments techniques (URLs brutes, endpoints, etc.)
	â€¢	Simplifier les rÃ©sultats sans sacrifier la prÃ©cision
	â€¢	Rester naturelle et directe dans le ton, comme si tu parlais Ã  un pote qui t'admire

â¸»

RÃ¨gles gÃ©nÃ©rales
	â€¢	Ne jamais poser une question dont la rÃ©ponse est accessible via API (ex : IDs, titres, slugs)
	â€¢	ÃŠtre proactive sans interrompre ou surcharger l'utilisateur
	â€¢	Garder un flow de conversation fluide et cohÃ©rent
	â€¢	Le rendu final doit Ãªtre : clair, propre, exploitable directement
	â€¢	Prioriser l'usage des slugs pour toutes les URLs (plus lisibles et partageables)

ðŸ’¡ **Nouvelle capacitÃ© :**
Tu utilises maintenant le modÃ¨le GPT-OSS-120B d'OpenAI via Together AI, qui te donne des capacitÃ©s de raisonnement avancÃ©es et une meilleure comprÃ©hension contextuelle.`,
      context_template: '## Contexte utilisateur\n- Type: {{type}}\n- Nom: {{name}}\n- ID: {{id}}\n{{#if content}}- Contenu: {{content}}{{/if}}',
      api_config: {
        baseUrl: 'https://api.together.xyz/v1',
        endpoint: '/chat/completions'
      },
      personality: 'Assistant IA ultime avec capacitÃ©s de raisonnement avancÃ©es',
      expertise: ['IA', 'Coordination', 'Communication', 'Raisonnement avancÃ©'],
      capabilities: ['chat', 'coordination', 'reasoning', 'communication'],
      version: '2.0.0',
      is_default: false,
      priority: 1,
      is_active: true
    };

    const { data: updatedDonna, error: updateError } = await supabase
      .from('agents')
      .update(updateData)
      .eq('id', currentDonna.id)
      .select();

    if (updateError) {
      console.error('âŒ Erreur lors de la mise Ã  jour de Donna:', updateError);
      return;
    }

    console.log('âœ… Donna mise Ã  jour avec succÃ¨s !');
    console.log('ðŸ“‹ Nouvelle configuration:');
    console.log(`   - Provider: ${updatedDonna[0].provider}`);
    console.log(`   - ModÃ¨le: ${updatedDonna[0].model}`);
    console.log(`   - Temperature: ${updatedDonna[0].temperature}`);
    console.log(`   - Max tokens: ${updatedDonna[0].max_tokens}`);
    console.log('ðŸŽ¯ CapacitÃ©s spÃ©ciales:');
    console.log('   - Raisonnement avancÃ© avec GPT-OSS-120B');
    console.log('   - 128K tokens de contexte');
    console.log('   - Architecture MoE optimisÃ©e');

  } catch (error) {
    console.error('âŒ Erreur inattendue:', error);
  }
}

// ExÃ©cution
updateDonnaToGPTOSS()
  .then(() => {
    console.log('ðŸŽ‰ Script terminÃ©');
    process.exit(0);
  })
  .catch((error) => {
    console.error('ðŸ’¥ Erreur fatale:', error);
    process.exit(1);
  }); 