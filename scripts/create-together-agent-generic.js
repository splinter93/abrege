// Charger les variables d'environnement
require('dotenv').config({ path: '.env.local' });

const { createClient } = require('@supabase/supabase-js');

// Configuration Supabase
const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL;
const supabaseKey = process.env.SUPABASE_SERVICE_ROLE_KEY;

if (!supabaseUrl || !supabaseKey) {
  console.error('âŒ Variables d\'environnement Supabase manquantes');
  process.exit(1);
}

const supabase = createClient(supabaseUrl, supabaseKey);

// Configuration des modÃ¨les disponibles
const TOGETHER_MODELS = {
  'gpt-oss-120b': {
    name: 'GPT-OSS-120B',
    model: 'openai/gpt-oss-120b',
    description: 'ModÃ¨le open-source GPT-OSS-120B d\'OpenAI avec raisonnement avancÃ©',
    capabilities: ['reasoning', 'analysis', 'content_generation']
  },
  'llama-3.1-405b': {
    name: 'Llama 3.1-405B',
    model: 'meta-llama/Llama-3.1-405B-Instruct',
    description: 'ModÃ¨le Llama 3.1 avec 405B paramÃ¨tres pour la gÃ©nÃ©ration de texte',
    capabilities: ['text_generation', 'content_creation', 'analysis']
  },
  'qwen3-235b': {
    name: 'Qwen3 235B A22B FP8',
    model: 'Qwen/Qwen3-235B-A22B-fp8-tput',
    description: 'ModÃ¨le hybride instruct + reasoning (232Bx22B MoE) optimisÃ© pour high-throughput',
    capabilities: ['hybrid_reasoning', 'high_throughput', 'cost_efficient', 'analysis']
  },
  'deepseek-coder': {
    name: 'DeepSeek Coder',
    model: 'deepseek-ai/deepseek-coder-33b-instruct',
    description: 'ModÃ¨le spÃ©cialisÃ© dans le code et la programmation',
    capabilities: ['coding', 'programming', 'debugging']
  },
  'qwen-2.5': {
    name: 'Qwen 2.5',
    model: 'qwen/Qwen2.5-72B-Instruct',
    description: 'ModÃ¨le Qwen 2.5 avec 72B paramÃ¨tres pour la conversation',
    capabilities: ['chat', 'conversation', 'analysis']
  },
  'mixtral-8x7b': {
    name: 'Mixtral 8x7B',
    model: 'mistralai/Mixtral-8x7B-Instruct-v0.1',
    description: 'ModÃ¨le Mixtral 8x7B pour des tÃ¢ches gÃ©nÃ©rales',
    capabilities: ['general', 'chat', 'analysis']
  }
};

async function createTogetherAgent(modelKey) {
  try {
    const modelConfig = TOGETHER_MODELS[modelKey];
    
    if (!modelConfig) {
      console.error('âŒ ModÃ¨le non reconnu. ModÃ¨les disponibles:');
      Object.keys(TOGETHER_MODELS).forEach(key => {
        console.log(`   - ${key}: ${TOGETHER_MODELS[key].name}`);
      });
      return;
    }

    console.log(`ğŸš€ CrÃ©ation de l'agent Together AI - ${modelConfig.name}...`);

    const agentData = {
      name: `Together AI - ${modelConfig.name}`,
      provider: 'together',
      model: modelConfig.model,
      temperature: 0.7,
      max_tokens: 4000,
      top_p: 0.9,
      system_instructions: `Tu es un assistant IA basÃ© sur le modÃ¨le ${modelConfig.name}, dÃ©ployÃ© via Together AI.

ğŸ¯ **CapacitÃ©s principales :**
${modelConfig.description}
- Support multilingue (FR/EN)
- RÃ©ponses naturelles et engageantes

ğŸ”§ **Contexte d'utilisation :**
Tu interagis dans l'application AbrÃ¨ge pour aider les utilisateurs avec :
- La gestion de notes et dossiers
- L'organisation de classeurs
- La rÃ©daction et l'Ã©dition de contenu
- L'analyse et la synthÃ¨se d'informations

ğŸ“ **Directives :**
- RÃ©ponds de maniÃ¨re claire et structurÃ©e
- Utilise le contexte fourni pour personnaliser tes rÃ©ponses
- Sois utile, prÃ©cis et bienveillant
- PrivilÃ©gie les slugs pour les rÃ©fÃ©rences (plus lisibles)
- Reste naturel et direct dans tes interactions

ğŸ’¡ **SpÃ©cialitÃ©s :**
- ModÃ¨le ${modelConfig.name}
- CapacitÃ©s: ${modelConfig.capabilities.join(', ')}
- OptimisÃ© pour les tÃ¢ches de l'application AbrÃ¨ge`,
      context_template: '## Contexte utilisateur\n- Type: {{type}}\n- Nom: {{name}}\n- ID: {{id}}\n{{#if content}}- Contenu: {{content}}{{/if}}',
      api_config: {
        baseUrl: 'https://api.together.xyz/v1',
        endpoint: '/chat/completions'
      },
      personality: `Assistant IA basÃ© sur ${modelConfig.name}`,
      expertise: ['IA', ...modelConfig.capabilities],
      capabilities: modelConfig.capabilities,
      version: '1.0.0',
      is_default: false,
      priority: 5,
      is_active: true
    };

    const { data, error } = await supabase
      .from('agents')
      .insert([agentData])
      .select();

    if (error) {
      console.error('âŒ Erreur lors de la crÃ©ation de l\'agent:', error);
      return;
    }

    console.log('âœ… Agent crÃ©Ã© avec succÃ¨s !');
    console.log('ğŸ“‹ DÃ©tails de l\'agent:');
    console.log(`   - ID: ${data[0].id}`);
    console.log(`   - Nom: ${data[0].name}`);
    console.log(`   - Provider: ${data[0].provider}`);
    console.log(`   - ModÃ¨le: ${data[0].model}`);
    console.log(`   - Temperature: ${data[0].temperature}`);
    console.log(`   - Max tokens: ${data[0].max_tokens}`);

  } catch (error) {
    console.error('âŒ Erreur inattendue:', error);
  }
}

// RÃ©cupÃ©rer le modÃ¨le depuis les arguments
const modelKey = process.argv[2];

if (!modelKey) {
  console.log('ğŸ“‹ Usage: node scripts/create-together-agent-generic.js <model-key>');
  console.log('ğŸ¯ ModÃ¨les disponibles:');
  Object.keys(TOGETHER_MODELS).forEach(key => {
    console.log(`   - ${key}: ${TOGETHER_MODELS[key].name}`);
  });
  console.log('');
  console.log('ğŸ’¡ Exemple: node scripts/create-together-agent-generic.js llama-3.1-405b');
  process.exit(1);
}

// ExÃ©cution
createTogetherAgent(modelKey)
  .then(() => {
    console.log('ğŸ‰ Script terminÃ©');
    process.exit(0);
  })
  .catch((error) => {
    console.error('ğŸ’¥ Erreur fatale:', error);
    process.exit(1);
  }); 