# üîç Audit Complet: Impl√©mentation Tool Calls Groq vs Documentation Officielle

**Date**: 26 octobre 2025  
**R√©f√©rence**: [Groq Tool Use Documentation](https://console.groq.com/docs/tool-use#agentic-tooling)

---

## üìã Checklist Conformit√© Doc Groq

### ‚úÖ 1. Structure des Tool Calls (OpenAI-Compatible)

**Doc Groq** :
```json
{
  "model": "llama-3.3-70b-versatile",
  "messages": [...],
  "tools": [{
    "type": "function",
    "function": {
      "name": "get_weather",
      "description": "Get the current weather",
      "parameters": { ... }
    }
  }],
  "tool_choice": "auto",
  "max_completion_tokens": 4096
}
```

**Notre Impl√©mentation** (`groq.ts:819-832`) :
```typescript
const payload = {
  model: this.config.model,               // ‚úÖ Correct
  messages: cleanedMessages,              // ‚úÖ Correct
  temperature: this.config.temperature,   // ‚úÖ Correct
  max_completion_tokens: this.config.maxTokens, // ‚úÖ Correct
  top_p: this.config.topP,                // ‚úÖ Correct
  stream: false,                          // ‚úÖ ou true selon le mode
  parallel_tool_calls: false              // ‚úÖ Conforme aux best practices
};

if (tools && tools.length > 0) {
  payload.tools = tools;                  // ‚úÖ Correct
  payload.tool_choice = "auto";           // ‚úÖ Correct
}
```

**‚úÖ CONFORME** : Structure identique √† la doc

---

### ‚úÖ 2. Gestion `parallel_tool_calls`

**Doc Groq** :
```
openai/gpt-oss-20b  : Parallel Tool Use ‚ùå
openai/gpt-oss-120b : Parallel Tool Use ‚ùå
llama-3.3-70b       : Parallel Tool Use ‚úÖ
qwen3-32b           : Parallel Tool Use ‚úÖ
```

**Notre Config** (`groq.ts:110, 826`) :
```typescript
parallelToolCalls: false  // ‚úÖ Hardcod√© √† false
```

**‚ö†Ô∏è PROBL√àME POTENTIEL** : On force `false` m√™me pour les mod√®les qui supportent le parall√®le (Llama, Qwen).

**Impact** :
- ‚úÖ **GPT-OSS** : Correct (ne supporte pas le parall√®le)
- ‚ö†Ô∏è **Llama/Qwen** : On limite artificiellement (mais d'apr√®s tes tests, Llama fait n'importe quoi en parall√®le donc c'est OK)

**Recommandation** : Garder `false` pour forcer le s√©quentiel propre.

---

### ‚úÖ 3. Format Messages Tool Results

**Doc Groq** :
```python
messages.append({
    "role": "tool",
    "content": str(function_response),
    "tool_call_id": tool_call.id,
    # ‚ùå Doc n'a pas 'name' !
})
```

**Notre Impl√©mentation** (`groq.ts:426-432, 816`) :
```typescript
// Dans convertChatMessagesToApiFormat
if (msg.role === 'tool') {
  if (toolCallId) messageObj.tool_call_id = toolCallId; // ‚úÖ
  if (toolName) messageObj.name = toolName;             // ‚úÖ On l'ajoute !
}

// Dans preparePayload
...(msg.name && { name: msg.name }) // ‚úÖ Inclus dans payload
```

**‚úÖ AM√âLIORATION** : On ajoute `name` (requis par Groq) alors que la doc l'oublie.

**Preuve** : L'erreur "Tools should have a name!" prouve que Groq l'exige.

---

### ‚úÖ 4. Streaming Tool Use

**Doc Groq** :
```python
stream = await client.chat.completions.create(
    messages=[...],
    tools=[...],
    model="llama-3.3-70b-versatile",
    temperature=0.5,
    stream=True  # ‚úÖ Streaming activ√©
)

async for chunk in stream:
    print(json.dumps(chunk.model_dump()))
```

**Notre Impl√©mentation** (`groq.ts:283-403`) :
```typescript
async *callWithMessagesStream(messages: ChatMessage[], tools: Tool[]): AsyncGenerator<StreamChunk> {
  const payload = await this.preparePayload(apiMessages, tools);
  payload.stream = true; // ‚úÖ Streaming activ√©
  
  const response = await fetch(`${this.config.baseUrl}/chat/completions`, {
    method: 'POST',
    headers: { 'Authorization': `Bearer ${this.config.apiKey}` },
    body: JSON.stringify(payload)
  });
  
  const reader = response.body.getReader();
  const decoder = new TextDecoder();
  
  // Parser SSE chunks
  for (const line of lines) {
    if (trimmed.startsWith('data: ')) {
      const chunk = JSON.parse(jsonStr);
      const delta = chunk.choices?.[0]?.delta;
      
      yield {
        type: 'delta',
        content: delta?.content,
        tool_calls: delta?.tool_calls,
        finishReason: chunk.choices?.[0]?.finish_reason
      };
    }
  }
}
```

**‚úÖ CONFORME** : Format SSE standard, parsing correct

---

### ‚ö†Ô∏è 5. Error Handling

**Doc Groq** :
> "Groq API will return a 400 error with explanation in 'failed_generation' field"

**Notre Impl√©mentation** (`groq.ts:320-328`) :
```typescript
if (!response.ok) {
  const errorText = await response.text();
  throw new Error(`Groq API Error: ${response.status} - ${errorText}`);
}
```

**‚ö†Ô∏è INSUFFISANT** : On ne parse pas le champ `failed_generation` sp√©cifique √† Groq.

**Recommandation** :
```typescript
if (!response.ok) {
  const errorData = await response.json();
  const failedGeneration = errorData.failed_generation || errorData.error?.message;
  throw new Error(`Groq API Error: ${response.status} - ${failedGeneration}`);
}
```

---

### ‚úÖ 6. Best Practices (Selon Doc)

**Doc Groq** :
1. ‚úÖ "Provide detailed tool descriptions" ‚Üí On le fait via OpenAPI schemas
2. ‚ö†Ô∏è "Use Instructor library for structured outputs" ‚Üí On ne l'utilise pas (optionnel)
3. ‚úÖ "Handle tool execution errors with is_error: true" ‚Üí On a `success: boolean`
4. ‚ùå "Implement routing system for fine-tuned models" ‚Üí On n'a pas de routing sp√©cial

---

## üéØ Points de Conformit√©

### ‚úÖ CONFORME (7/9)
1. ‚úÖ Structure payload OpenAI-compatible
2. ‚úÖ `tool_choice: "auto"`
3. ‚úÖ `max_completion_tokens` utilis√©
4. ‚úÖ Streaming SSE correct
5. ‚úÖ Messages tool avec `tool_call_id` + `name`
6. ‚úÖ `parallel_tool_calls: false` (s√©curis√©)
7. ‚úÖ Tool descriptions d√©taill√©es (via OpenAPI)

### ‚ö†Ô∏è √Ä AM√âLIORER (2/9)
1. ‚ö†Ô∏è Error handling : Parser `failed_generation`
2. ‚ö†Ô∏è `parallel_tool_calls` hardcod√© : Devrait s'adapter au mod√®le

---

## üî¨ Analyse Comportement Mod√®les

### Tests Effectu√©s

| Mod√®le | Parallel Support (Doc) | Comportement R√©el | Qualit√© Tool Use |
|--------|------------------------|-------------------|------------------|
| **xAI Grok 4** | N/A | S√©quentiel intelligent avec commentaires | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excellent |
| **Groq GPT-OSS-20B** | ‚ùå Non | S√©quentiel basique (pas de texte avec tools) | ‚≠ê‚≠ê‚≠ê Correct |
| **Groq Llama 3.3-70B** | ‚úÖ Oui | Parall√®le anarchique (5 tools d'un coup) | ‚≠ê‚≠ê Mauvais |
| **Groq Qwen 3-32B** | ‚úÖ Oui | S√©quentiel intelligent (1 tool √† la fois) | ‚≠ê‚≠ê‚≠ê‚≠ê Tr√®s bon |

**Conclusion** :
- Le support "Parallel ‚úÖ" ne garantit PAS la qualit√©
- **Qwen** est le meilleur mod√®le Groq pour tool use (proche de Grok)
- **Llama** spam en parall√®le malgr√© `parallel_tool_calls: false`

---

## üêõ Bugs Identifi√©s et Corrig√©s Cette Session

### Bug 1: Provider/Mod√®le Incoh√©rent
**Sympt√¥me** : `xAI API Error: 404 - model openai/gpt-oss-20b does not exist`  
**Fix** : Provider auto-d√©duit du mod√®le

### Bug 2: Champ `name` Manquant
**Sympt√¥me** : `Groq API Error: Tools should have a name!`  
**Fix** : Ajout de `name` dans messages tool (ligne 816)

### Bug 3: Tool Results Polluent l'Historique
**Sympt√¥me** : LLM recommence les tool calls apr√®s "merci"  
**Fix** : Garde seulement les tool results du DERNIER round

---

## üí° Recommandations Production

### Court Terme
1. ‚úÖ **Garder `parallel_tool_calls: false`** pour forcer le s√©quentiel
2. ‚úÖ **Recommander Qwen 3-32B** pour Groq (meilleur tool use)
3. ‚ö†Ô∏è **Am√©liorer error handling** : Parser `failed_generation`

### Moyen Terme
1. Adapter `parallel_tool_calls` selon le mod√®le :
   ```typescript
   const supportsParallel = ['llama', 'qwen', 'kimi'].some(m => model.includes(m));
   parallel_tool_calls: supportsParallel ? true : false
   ```

2. Ajouter instructions syst√®me pour guider Llama vers s√©quentiel :
   ```
   "‚ö†Ô∏è R√àGLE: Appelle UN SEUL tool √† la fois. Commente avant et apr√®s chaque tool."
   ```

### Long Terme
1. Impl√©menter Instructor library pour structured outputs
2. Routing intelligent selon capacit√©s du mod√®le
3. Monitoring des tool calls (success rate, latency)

---

## üìä Scoring Final

| Crit√®re | Note | Commentaire |
|---------|------|-------------|
| **Conformit√© structure** | 10/10 | Format OpenAI parfait |
| **Gestion streaming** | 9/10 | SSE correct, manque failed_generation |
| **Messages tool** | 10/10 | tool_call_id + name (mieux que la doc) |
| **Parallel handling** | 8/10 | Trop strict mais s√©curis√© |
| **Error handling** | 7/10 | Basique, manque failed_generation |
| **Best practices** | 8/10 | Bonnes bases, peut am√©liorer |

**Total** : **52/60** (87%) - **Tr√®s Bon**

---

## ‚úÖ Conclusion

Notre impl√©mentation est **conforme et robuste** :
- ‚úÖ Suit les specs OpenAI/Groq
- ‚úÖ G√®re correctement streaming + tool calls
- ‚úÖ Meilleure que les exemples doc (on ajoute `name`)
- ‚ö†Ô∏è Peut am√©liorer error handling
- ‚ö†Ô∏è Peut adapter `parallel_tool_calls` selon mod√®le

**Pr√™t pour production** avec les mod√®les recommand√©s :
- **xAI Grok 4** : Pour tool use premium
- **Groq Qwen 3-32B** : Pour tool use Groq de qualit√©
- **Groq GPT-OSS** : Pour texte simple sans tools complexes

