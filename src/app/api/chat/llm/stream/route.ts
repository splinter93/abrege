import { NextRequest } from 'next/server';
import { simpleLogger as logger } from '@/utils/logger';
import { createClient } from '@supabase/supabase-js';
import { XAIProvider } from '@/services/llm/providers/implementations/xai';
import type { ChatMessage } from '@/types/chat';
import type { Tool } from '@/services/llm/types/strictTypes';

// Force Node.js runtime for streaming
export const runtime = 'nodejs';
export const dynamic = 'force-dynamic';

// Client Supabase admin
const supabase = createClient(
  process.env.NEXT_PUBLIC_SUPABASE_URL!,
  process.env.SUPABASE_SERVICE_ROLE_KEY!
);

/**
 * ‚úÖ Route API Streaming pour xAI Grok
 * Retourne un ReadableStream avec SSE
 */
export async function POST(request: NextRequest) {
  let sessionId: string | undefined;
  let userToken: string | undefined;
  
  try {
    const body = await request.json();
    const { message, context, history, agentConfig } = body;

    // Validation des param√®tres requis
    if (!message || !context || !history) {
      return new Response(
        JSON.stringify({ error: 'Param√®tres manquants', required: ['message', 'context', 'history'] }),
        { status: 400, headers: { 'Content-Type': 'application/json' } }
      );
    }

    // Extraire le token d'authentification
    const authHeader = request.headers.get('authorization');
    
    if (!authHeader || !authHeader.startsWith('Bearer ')) {
      return new Response(
        JSON.stringify({ error: 'Token d\'authentification manquant ou invalide' }),
        { status: 401, headers: { 'Content-Type': 'application/json' } }
      );
    }
    
    userToken = authHeader.replace('Bearer ', '');
    sessionId = context.sessionId;
    
    logger.info(`[Stream Route] üåä D√©marrage streaming pour session ${sessionId}`);

    // ‚úÖ Valider le JWT et extraire userId
    let userId: string;
    
    try {
      if (userToken.includes('.')) {
        // C'est un JWT
        const { data: { user }, error } = await supabase.auth.getUser(userToken);
        
        if (error || !user) {
          logger.error('[Stream Route] ‚ùå JWT invalide:', error);
          return new Response(
            JSON.stringify({ error: 'JWT invalide ou expir√©' }),
            { status: 401, headers: { 'Content-Type': 'application/json' } }
          );
        }
        
        userId = user.id;
      } else {
        // C'est d√©j√† un userId
        userId = userToken;
      }
    } catch (verifyError) {
      logger.error('[Stream Route] ‚ùå Erreur validation token:', verifyError);
      return new Response(
        JSON.stringify({ error: 'Token invalide' }),
        { status: 401, headers: { 'Content-Type': 'application/json' } }
      );
    }

    // ‚úÖ R√©cup√©rer l'agent comme la route classique (table 'agents')
    const agentId = context.agentId;
    const providerName = context.provider || 'xai';
    let finalAgentConfig = agentConfig;
    
    try {
      // 1) Priorit√© √† l'agent explicitement s√©lectionn√©
      if (agentId) {
        logger.dev(`[Stream Route] üîç R√©cup√©ration de l'agent par ID: ${agentId}`);
        const { data: agentById, error: agentByIdError } = await supabase
          .from('agents')
          .select('*')
          .eq('id', agentId)
          .eq('is_active', true)
          .single();

        if (!agentByIdError && agentById) {
          finalAgentConfig = agentById;
          logger.dev(`[Stream Route] ‚úÖ Agent trouv√©: ${agentById.name}`);
        }
      }

      // 2) Sinon fallback par provider
      if (!finalAgentConfig && providerName) {
        logger.dev(`[Stream Route] üîç R√©cup√©ration de l'agent pour le provider: ${providerName}`);
        const { data: agent, error } = await supabase
          .from('agents')
          .select('*')
          .eq('provider', providerName)
          .eq('is_active', true)
          .order('priority', { ascending: false })
          .limit(1)
          .single();

        if (!error && agent) {
          finalAgentConfig = agent;
          logger.dev(`[Stream Route] ‚úÖ Agent trouv√© par provider: ${agent.name}`);
        }
      }

      // 3) Fallback final : premier agent actif
      if (!finalAgentConfig) {
        logger.dev(`[Stream Route] üîç R√©cup√©ration du premier agent actif`);
        const { data: defaultAgent, error } = await supabase
          .from('agents')
          .select('*')
          .eq('is_active', true)
          .order('priority', { ascending: false })
          .limit(1)
          .single();

        if (!error && defaultAgent) {
          finalAgentConfig = defaultAgent;
          logger.dev(`[Stream Route] ‚úÖ Agent par d√©faut: ${defaultAgent.name}`);
        }
      }
    } catch (error) {
      logger.error(`[Stream Route] ‚ùå Erreur r√©cup√©ration agent:`, error);
    }

    // Cr√©er le provider xAI
    const provider = new XAIProvider({
      model: finalAgentConfig?.model || 'grok-4-fast',
      temperature: finalAgentConfig?.temperature || 0.7,
      maxTokens: finalAgentConfig?.max_tokens || 8000
    });

    // ‚úÖ Construire le contexte UI (comme dans la route classique)
    const uiContext = context.uiContext || {};
    
    logger.dev('[Stream Route] üïµÔ∏è‚Äç‚ôÇÔ∏è Contexte UI re√ßu:', {
      hasUIContext: !!context.uiContext,
      uiContextKeys: context.uiContext ? Object.keys(context.uiContext) : [],
      contextType: context.type,
      contextId: context.id
    });

    // ‚úÖ Construire le system message avec contexte (comme la route classique)
    const { SystemMessageBuilder } = await import('@/services/llm/SystemMessageBuilder');
    const systemMessageBuilder = SystemMessageBuilder.getInstance();
    
    const systemMessageResult = systemMessageBuilder.buildSystemMessage(
      finalAgentConfig || {},
      {
        type: context.type || 'chat_session',
        name: context.name || 'Chat',
        id: context.id || sessionId,
        ...uiContext
      }
    );
    
    const systemMessage = systemMessageResult.content;
    
    logger.dev('[Stream Route] üìù System message construit:', {
      length: systemMessage.length,
      hasContext: systemMessage.includes('Contexte actuel'),
      agentName: finalAgentConfig?.name || 'default'
    });
    
    const messages: ChatMessage[] = [
      {
        role: 'system',
        content: systemMessage,
        timestamp: new Date().toISOString()
      },
      ...history,
      {
        role: 'user',
        content: message,
        timestamp: new Date().toISOString()
      }
    ];

    // ‚úÖ Charger les tools (OpenAPI + MCP) ET les endpoints
    let tools: Tool[] = [];
    let openApiEndpoints = new Map<string, any>();
    
    if (context.agentId) {
      try {
        // 1. Charger les sch√©mas OpenAPI de l'agent
        const { data: agentSchemas } = await supabase
          .from('agent_openapi_schemas')
          .select('openapi_schema_id')
          .eq('agent_id', context.agentId);

        if (agentSchemas && agentSchemas.length > 0) {
          const { openApiSchemaService } = await import('@/services/llm/openApiSchemaService');
          
          const schemaIds = agentSchemas.map(s => s.openapi_schema_id);
          const { tools: openApiTools, endpoints } = await openApiSchemaService.getToolsAndEndpointsFromSchemas(schemaIds);
          
          // ‚úÖ Garder les endpoints pour OpenApiToolExecutor
          openApiEndpoints = endpoints;
          
          // 2. Charger les tools MCP de l'agent
          const { mcpConfigService } = await import('@/services/llm/mcpConfigService');
          const hybridTools = await mcpConfigService.buildHybridTools(
            context.agentId,
            userToken,
            openApiTools
          ) as Tool[];
          
          // Limiter √† 15 tools pour xAI
          tools = hybridTools.slice(0, 15);
          
          const mcpCount = tools.filter(t => (t as any).server_label).length;
          const openApiCount = tools.length - mcpCount;
          
          logger.dev(`[Stream Route] ‚úÖ ${tools.length} tools charg√©s (${mcpCount} MCP + ${openApiCount} OpenAPI), ${openApiEndpoints.size} endpoints`);
        }
      } catch (toolsError) {
        logger.warn('[Stream Route] ‚ö†Ô∏è Erreur chargement tools:', toolsError);
        // Continue sans tools
      }
    }

    // ‚úÖ Cr√©er le ReadableStream pour SSE avec gestion tool calls
    const stream = new ReadableStream({
      async start(controller) {
        const encoder = new TextEncoder();
        const startTime = Date.now();
        const TIMEOUT_MS = 60000; // 60s timeout
        
        // ‚úÖ V√©rifier timeout
        const checkTimeout = () => {
          if (Date.now() - startTime > TIMEOUT_MS) {
            throw new Error('Stream timeout (60s)');
          }
        };
        
        try {
          logger.dev('[Stream Route] üì° D√©marrage du stream SSE');
          
          // Helper pour envoyer un chunk SSE
          const sendSSE = (data: unknown) => {
            checkTimeout(); // V√©rifier avant chaque envoi
            const chunk = `data: ${JSON.stringify(data)}\n\n`;
            controller.enqueue(encoder.encode(chunk));
          };

          // Envoyer un chunk de d√©but
          sendSSE({
            type: 'start',
            sessionId,
            timestamp: Date.now()
          });

          // ‚úÖ Boucle agentic en streaming (max 5 tours)
          let currentMessages = [...messages];
          let roundCount = 0;
          const maxRounds = 5;

          while (roundCount < maxRounds) {
            roundCount++;
            logger.dev(`[Stream Route] üîÑ Round ${roundCount}/${maxRounds}`);

            // Accumuler tool calls et content du stream
            let accumulatedContent = '';
            const toolCallsMap = new Map<string, any>(); // Accumuler par ID pour g√©rer les chunks
            let finishReason: string | null = null;

            // ‚úÖ Stream depuis xAI
            for await (const chunk of provider.callWithMessagesStream(currentMessages, tools)) {
              // Envoyer le chunk au client
              sendSSE(chunk);

              // Accumuler content
              if (chunk.content) {
                accumulatedContent += chunk.content;
              }
              
              // ‚úÖ Accumuler tool calls (peuvent venir en plusieurs chunks)
              if (chunk.tool_calls && chunk.tool_calls.length > 0) {
                for (const tc of chunk.tool_calls) {
                  if (!toolCallsMap.has(tc.id)) {
                    toolCallsMap.set(tc.id, {
                      id: tc.id,
                      type: tc.type,
                      function: {
                        name: tc.function.name || '',
                        arguments: tc.function.arguments || ''
                      }
                    });
                  } else {
                    // Accumuler les arguments progressifs
                    const existing = toolCallsMap.get(tc.id);
                    if (tc.function.name) existing.function.name = tc.function.name;
                    if (tc.function.arguments) existing.function.arguments += tc.function.arguments;
                  }
                }
              }

              // ‚úÖ Capturer finish_reason
              if (chunk.finishReason) {
                finishReason = chunk.finishReason;
                logger.dev(`[Stream Route] üèÅ Finish reason d√©tect√©: ${finishReason}`);
              }
            }

            // ‚úÖ D√©cision bas√©e sur finish_reason
            if (finishReason === 'tool_calls' && toolCallsMap.size > 0) {
              logger.dev(`[Stream Route] üîß Tool calls d√©tect√©s (${toolCallsMap.size}), ex√©cution...`);
            } else if (finishReason === 'stop') {
              logger.dev('[Stream Route] ‚úÖ R√©ponse finale (stop), fin du stream');
              break;
            } else if (finishReason === 'length') {
              logger.warn('[Stream Route] ‚ö†Ô∏è Token limit atteint');
              break;
            } else {
              logger.dev('[Stream Route] ‚úÖ Pas de tool calls, fin du stream');
              break;
            }

            const accumulatedToolCalls = Array.from(toolCallsMap.values());

            // ‚úÖ Ex√©cuter les tool calls
            logger.dev(`[Stream Route] üîß Ex√©cution de ${accumulatedToolCalls.length} tool calls`);
            
            // Envoyer un √©v√©nement d'ex√©cution de tools
            sendSSE({
              type: 'tool_execution',
              toolCount: accumulatedToolCalls.length,
              timestamp: Date.now()
            });

            // Ajouter le message assistant avec tool calls
            currentMessages.push({
              role: 'assistant',
              content: accumulatedContent || null,
              tool_calls: accumulatedToolCalls,
              timestamp: new Date().toISOString()
            });

            // ‚úÖ Cr√©er les executors UNE FOIS (en dehors de la boucle)
            const { ApiV2ToolExecutor } = await import('@/services/llm/executors/ApiV2ToolExecutor');
            const { OpenApiToolExecutor } = await import('@/services/llm/executors/OpenApiToolExecutor');
            
            const mcpExecutor = new ApiV2ToolExecutor();
            const openApiExecutor = new OpenApiToolExecutor('', openApiEndpoints);
            
            // ‚úÖ Ex√©cuter chaque tool call
            for (const toolCall of accumulatedToolCalls) {
              checkTimeout(); // V√©rifier timeout avant chaque tool
              try {
                logger.dev(`[Stream Route] üîß Ex√©cution tool: ${toolCall.function.name}`);
                
                // ‚úÖ D√©tecter le type de tool (MCP ou OpenAPI)
                const isMcpTool = (toolCall as any).server_label !== undefined;
                
                // ‚úÖ Utiliser le bon executor
                const result = isMcpTool 
                  ? await mcpExecutor.executeToolCall(toolCall, userToken)
                  : await openApiExecutor.executeToolCall(toolCall, userToken);

                // Ajouter le r√©sultat aux messages
                currentMessages.push({
                  role: 'tool',
                  tool_call_id: toolCall.id,
                  name: toolCall.function.name,
                  content: typeof result.content === 'string' ? result.content : JSON.stringify(result.content),
                  timestamp: new Date().toISOString()
                });

                // Envoyer le r√©sultat au client
                sendSSE({
                  type: 'tool_result',
                  toolCallId: toolCall.id,
                  toolName: toolCall.function.name,
                  success: result.success,
                  result: result.content,
                  timestamp: Date.now()
                });

                logger.dev(`[Stream Route] ‚úÖ Tool ${toolCall.function.name} ex√©cut√© (success: ${result.success})`);

              } catch (toolError) {
                logger.error(`[Stream Route] ‚ùå Erreur tool ${toolCall.function.name}:`, toolError);
                
                // Ajouter un r√©sultat d'erreur
                const errorContent = `Erreur: ${toolError instanceof Error ? toolError.message : String(toolError)}`;
                
                currentMessages.push({
                  role: 'tool',
                  tool_call_id: toolCall.id,
                  name: toolCall.function.name,
                  content: errorContent,
                  timestamp: new Date().toISOString()
                });
                
                // Envoyer l'erreur au client
                sendSSE({
                  type: 'tool_result',
                  toolCallId: toolCall.id,
                  toolName: toolCall.function.name,
                  success: false,
                  result: errorContent,
                  timestamp: Date.now()
                });
              }
            }

            // Continuer la boucle pour relancer le LLM avec les r√©sultats
            logger.dev(`[Stream Route] üîÑ Relance du LLM avec ${currentMessages.length} messages`);
          }

          // Envoyer un chunk de fin
          sendSSE({
            type: 'done',
            rounds: roundCount,
            timestamp: Date.now()
          });

          logger.info('[Stream Route] ‚úÖ Stream termin√© avec succ√®s');
          controller.close();

        } catch (error) {
          logger.error('[Stream Route] ‚ùå Erreur stream:', error);
          
          // Envoyer l'erreur au client
          const errorMessage = error instanceof Error ? error.message : String(error);
          const errorChunk = `data: ${JSON.stringify({ type: 'error', error: errorMessage })}\n\n`;
          controller.enqueue(encoder.encode(errorChunk));
          
          controller.close();
        }
      }
    });

    // Retourner la r√©ponse avec headers SSE
    return new Response(stream, {
      headers: {
        'Content-Type': 'text/event-stream',
        'Cache-Control': 'no-cache',
        'Connection': 'keep-alive'
      }
    });

  } catch (error) {
    logger.error('[Stream Route] ‚ùå Erreur globale:', error);
    
    return new Response(
      JSON.stringify({
        error: 'Erreur serveur',
        message: error instanceof Error ? error.message : String(error)
      }),
      {
        status: 500,
        headers: { 'Content-Type': 'application/json' }
      }
    );
  }
}

