import { NextRequest } from 'next/server';
import { logger, LogCategory } from '@/utils/logger';
import { parsePromptPlaceholders } from '@/utils/promptPlaceholders';
import { createClient } from '@supabase/supabase-js';
import type { SupabaseClient } from '@supabase/supabase-js';
import { GroqProvider } from '@/services/llm/providers/implementations/groq';
import type { ChatMessage } from '@/types/chat';
import { hasToolCalls } from '@/types/chat';
import { SERVER_ENV } from '@/config/env.server';
import type { OpenApiEndpoint } from '@/services/llm/executors/OpenApiToolExecutor';
import type { Tool, McpTool } from '@/services/llm/types/strictTypes';
import type { ToolCall } from '@/services/llm/types/strictTypes';
import { isMcpTool, isFunctionTool } from '@/services/llm/types/strictTypes';
import { llmStreamRequestSchema } from '../validation';
import { dynamicChatRateLimiter } from '@/services/dynamicRateLimiter';
import {
  validateAndExtractUserId,
  resolveAgent,
  validateAndNormalizeModel,
  normalizeLLMParams,
  extractTextFromContent
} from './helpers';
import { streamBroadcastService } from '@/services/streamBroadcastService';
import { metricsCollector } from '@/services/monitoring/MetricsCollector';

// Force Node.js runtime for streaming
export const runtime = 'nodejs';
export const dynamic = 'force-dynamic';

// Client Supabase admin
const supabase = createClient(
  SERVER_ENV.supabase.url,
  SERVER_ENV.supabase.serviceRoleKey
);

/**
 * ‚úÖ Route API Streaming pour LLM (Groq ou xAI)
 * Retourne un ReadableStream avec SSE
 * Provider s√©lectionn√© automatiquement selon la config agent
 */
export async function POST(request: NextRequest) {
  const startTime = Date.now();
  let success = false;
  let sessionId: string | undefined;
  let userToken: string | undefined;
  
  try {
    const body = await request.json();
    
    // ‚úÖ Validation Zod stricte
    const validation = llmStreamRequestSchema.safeParse(body);
    
    if (!validation.success) {
      logger.warn(LogCategory.API, '[Stream Route] ‚ùå Validation failed', {
        errors: validation.error.format()
      });
      return new Response(
        JSON.stringify({ 
          error: 'Validation failed', 
          details: validation.error.flatten().fieldErrors 
        }),
        { status: 400, headers: { 'Content-Type': 'application/json' } }
      );
    }
    
    const { message, context, history, agentConfig, skipAddingUserMessage } = validation.data;

    // üé® Extraire le noteId du contexte canva (si pr√©sent)
    const noteId = context.canva_context && typeof context.canva_context === 'object' && 'activeNote' in context.canva_context 
      ? (context.canva_context as { activeNote?: { note?: { id?: string } } }).activeNote?.note?.id 
      : null;

    // Extraire le token d'authentification
    const authHeader = request.headers.get('authorization');
    
    if (!authHeader || !authHeader.startsWith('Bearer ')) {
      return new Response(
        JSON.stringify({ error: 'Token d\'authentification manquant ou invalide' }),
        { status: 401, headers: { 'Content-Type': 'application/json' } }
      );
    }
    
    userToken = authHeader.replace('Bearer ', '');
    sessionId = context.sessionId;

    // ‚úÖ Valider le JWT et extraire userId
    const userIdResult = await validateAndExtractUserId(
      userToken,
      supabase as unknown as SupabaseClient<unknown, { PostgrestVersion: string }, never, never, { PostgrestVersion: string }>
    );
    
    if (!userIdResult.success) {
      return new Response(
        JSON.stringify({ error: userIdResult.error }),
        { status: 401, headers: { 'Content-Type': 'application/json' } }
      );
    }
    
    const userId = userIdResult.userId;

    // ‚úÖ S√âCURIT√â: Rate limiting par utilisateur (diff√©renci√© free/premium)
    const chatLimit = await dynamicChatRateLimiter.check(userId);
    
    if (!chatLimit.allowed) {
      const resetDate = new Date(chatLimit.resetTime);
      logger.warn(LogCategory.API, `[Stream Route] ‚õî Rate limit d√©pass√© pour userId`, {
        userId: userId.substring(0, 8) + '...',
        limit: chatLimit.limit,
        resetTime: chatLimit.resetTime
      });
      
      return new Response(
        JSON.stringify({
          error: 'Rate limit d√©pass√©',
          message: `Vous avez atteint la limite de ${chatLimit.limit} messages par minute. Veuillez r√©essayer dans quelques instants.`,
          remaining: chatLimit.remaining,
          resetTime: chatLimit.resetTime,
          resetDate: resetDate.toISOString()
        }),
        {
          status: 429,
          headers: {
            'Content-Type': 'application/json',
            'X-RateLimit-Limit': chatLimit.limit.toString(),
            'X-RateLimit-Remaining': chatLimit.remaining.toString(),
            'X-RateLimit-Reset': chatLimit.resetTime.toString(),
            'Retry-After': Math.ceil((chatLimit.resetTime - Date.now()) / 1000).toString()
          }
        }
      );
    }

    // ‚úÖ R√©cup√©rer l'agent comme la route classique (table 'agents')
    const agentId = context.agentId;
    const providerName = context.provider || 'xai';
    
    const finalAgentConfig = await resolveAgent(
      agentId,
      providerName,
      agentConfig,
      supabase as unknown as SupabaseClient<unknown, { PostgrestVersion: string }, never, never, { PostgrestVersion: string }>
    );

    // ‚úÖ S√©lectionner le provider selon la config agent (Groq ou xAI)
    let providerType = finalAgentConfig?.provider?.toLowerCase() || 'groq';
    let model = finalAgentConfig?.model || (providerType === 'xai' ? 'grok-4-1-fast-reasoning' : 'openai/gpt-oss-20b');
    
    logger.info(LogCategory.API, `[Stream Route] üîç Configuration initiale:`, {
      agentProvider: finalAgentConfig?.provider,
      agentModel: finalAgentConfig?.model,
      providerType,
      model
    });
    
    // üîç Auto-d√©tection du provider depuis le mod√®le (pour √©viter incoh√©rences)
    const { getModelInfo } = await import('@/constants/groqModels');
    const modelInfo = getModelInfo(model);
    
    // ‚úÖ D√©tection suppl√©mentaire pour DeepSeek si le mod√®le contient "deepseek"
    if (!modelInfo && (model.includes('deepseek') || model.startsWith('deepseek'))) {
      logger.warn(LogCategory.API, `[Stream Route] ‚ö†Ô∏è Mod√®le DeepSeek d√©tect√© mais non trouv√© dans getModelInfo, correction automatique`, {
        model,
        currentProvider: providerType
      });
      providerType = 'deepseek';
    } else if (modelInfo?.provider && modelInfo.provider !== providerType) {
      logger.warn(LogCategory.API, `[Stream Route] ‚ö†Ô∏è Correction automatique provider`, {
        from: providerType,
        to: modelInfo.provider,
        model,
        modelInfoId: modelInfo.id
      });
      providerType = modelInfo.provider;
    }
    
    // ‚úÖ Log final pour debug
    logger.info(LogCategory.API, `[Stream Route] üîç Provider s√©lectionn√©:`, {
      providerType,
      model,
      modelInfoFound: !!modelInfo,
      modelInfoProvider: modelInfo?.provider,
      modelInfoId: modelInfo?.id
    });
    
    // üîç Validation et normalisation du mod√®le
    model = validateAndNormalizeModel(providerType, model);
    
    // Validation et normalisation des param√®tres LLM
    const { temperature, topP, maxTokens } = normalizeLLMParams(finalAgentConfig);
    
    // ‚úÖ Variables pour param√®tres finaux (seront mises √† jour apr√®s override si n√©cessaire)
    let finalTemperature = temperature;
    let finalTopP = topP;
    let finalMaxTokens = maxTokens;

    // ‚úÖ Construire le contexte UI (SANS attachedNotes - g√©r√©es s√©par√©ment)
    const uiContext = {
      ...(context.uiContext || {})
      // Notes ne sont PLUS pass√©es ici (√©vite duplication tokens)
    };
    
    logger.debug(LogCategory.API, '[Stream Route] üïµÔ∏è‚Äç‚ôÇÔ∏è Contexte UI re√ßu', {
      hasUIContext: !!context.uiContext,
      uiContextKeys: context.uiContext ? Object.keys(context.uiContext) : [],
      contextType: context.type,
      contextId: context.id,
      hasAttachedNotes: !!(context.attachedNotes && context.attachedNotes.length > 0),
      attachedNotesCount: context.attachedNotes?.length || 0
    });

    // ‚úÖ Construire le system message (instructions agent + contexte UI via ContextInjectionService)
    const { SystemMessageBuilder } = await import('@/services/llm/SystemMessageBuilder');
    const { contextInjectionService } = await import('@/services/llm/context');
    const systemMessageBuilder = SystemMessageBuilder.getInstance();
    
    // Construire ExtendedLLMContext pour ContextInjectionService (pour context messages uniquement)
    // uiContext contient d√©j√† tous les champs requis de LLMContext
    const extendedContext: import('@/services/llm/context/types').ExtendedLLMContext = {
      ...uiContext,
      sessionId: sessionId ?? '',
      agentId: finalAgentConfig?.id,
      attachedNotes: context.attachedNotes,
      mentionedNotes: context.mentionedNotes,
      canvasSelections: context.canvasSelections
    } as import('@/services/llm/context/types').ExtendedLLMContext;
    
    // Construire le system message (instructions agent + contexte UI)
    // SystemMessageBuilder utilise d√©j√† ContextInjectionService pour le contexte UI
    const systemMessageResult = systemMessageBuilder.buildSystemMessage(
      finalAgentConfig || {},
      {
        type: context.type || 'chat_session',
        name: context.name || 'Chat',
        id: context.id ?? sessionId ?? 'unknown',
        sessionId: sessionId ?? '',
        provider: providerType,
        ...uiContext
      }
    );
    
    const systemMessage = systemMessageResult.content;
    
    // Injecter les context messages (notes, mentions) via ContextInjectionService
    // Note: SystemMessageBuilder a d√©j√† inject√© le contexte UI dans le system message
    // Ici on r√©cup√®re uniquement les MessageContextProviders (notes, mentions)
    const contextInjectionResult = contextInjectionService.injectContext(
      finalAgentConfig || {},
      extendedContext
    );
    
    logger.debug(LogCategory.API, '[Stream Route] üìù Messages construits:', {
      systemMessageLength: systemMessage.length,
      contextMessagesCount: contextInjectionResult.contextMessages.length,
      providersApplied: contextInjectionResult.metadata.providersApplied,
      agentName: finalAgentConfig?.name || 'default'
    });
    
    // ‚úÖ NOUVEAU : Remplacer prompts /slug par templates avant LLM
    // ‚ö†Ô∏è IMPORTANT: Garder le format original (string OU array multi-modal avec images)
    let processedMessage: string | Array<{ type: 'text' | 'image_url'; text?: string; image_url?: { url: string; detail?: string } }> = message || '';
    
    // Si message est multi-modal (array), extraire le texte pour traitement prompts
    const textForPrompts = typeof message === 'string' 
      ? message 
      : Array.isArray(message) 
        ? message.find((part): part is { type: 'text'; text: string } => part.type === 'text')?.text || ''
        : '';
    
    if (!skipAddingUserMessage && textForPrompts) {
      // R√©cup√©rer prompts depuis le dernier message user de l'historique
      const lastUserMessage = [...history].reverse().find(m => m.role === 'user') as import('@/types/chat').UserMessage | undefined;
      const contextPrompts = context.prompts || [];
      const historyPrompts = lastUserMessage?.prompts || [];
      const prompts = contextPrompts.length > 0 ? contextPrompts : historyPrompts;
      
    if (prompts.length > 0) {
      try {
        const promptIds = prompts.map((promptMeta: { id: string }) => promptMeta.id);
        const { data: promptsFromDB } = await supabase
          .from('editor_prompts')
          .select('id, slug, prompt_template')
          .in('id', promptIds);

        if (promptsFromDB && promptsFromDB.length > 0) {
          const templateMap = new Map<string, string>();
          promptsFromDB.forEach((promptRow) => {
            templateMap.set(promptRow.slug, promptRow.prompt_template);
          });

          let finalContent = textForPrompts;

          for (const promptMeta of prompts) {
            const pattern = `/${promptMeta.slug}`;
            if (!finalContent.includes(pattern)) {
              continue;
            }

            const template = templateMap.get(promptMeta.slug);
            if (!template || !template.trim()) {
              logger.warn(LogCategory.API, '[Stream Route] ‚ö†Ô∏è Prompt template manquant', {
                promptId: promptMeta.id,
                slug: promptMeta.slug
              });
              continue;
            }

            const placeholderValues = promptMeta.placeholderValues || {};
            let resolvedTemplate = template;

            for (const [key, value] of Object.entries(placeholderValues)) {
              const safeValue = typeof value === 'string' ? value.trim() : '';
              resolvedTemplate = resolvedTemplate.split(`{${key}}`).join(safeValue);
            }

            const remainingPlaceholders = parsePromptPlaceholders(resolvedTemplate);
            if (remainingPlaceholders.length > 0) {
              logger.warn(LogCategory.API, '[Stream Route] ‚ö†Ô∏è Placeholders non remplis d√©tect√©s', {
                slug: promptMeta.slug,
                missing: remainingPlaceholders.map((placeholder) => placeholder.name)
              });
            }

            finalContent = finalContent.replace(pattern, `${resolvedTemplate}\n\n`);
            logger.debug(LogCategory.API,'[Stream Route] ‚úÖ Prompt remplac√©', {
              slug: promptMeta.slug,
              name: promptMeta.name,
              hasValues: Object.keys(placeholderValues).length > 0
            });
          }

          // ‚úÖ Si message √©tait multi-modal (array), reconstruire avec texte modifi√©
          if (Array.isArray(message)) {
            processedMessage = message.map(part => 
              part.type === 'text' ? { ...part, text: finalContent } : part
            );
          } else {
            processedMessage = finalContent;
          }

          logger.info(LogCategory.API, '[Stream Route] üìù Prompts remplac√©s', {
            count: prompts.length,
            originalLength: processedMessage.length,
            finalLength: processedMessage.length
          });
        }
      } catch (promptError) {
        logger.error(LogCategory.API, '[Stream Route] ‚ùå Erreur remplacement prompts', {
          error: promptError instanceof Error ? promptError.message : String(promptError)
        }, promptError instanceof Error ? promptError : undefined);
      }
    }
    }
    
    // ‚úÖ Construire le tableau de messages avec contextes inject√©s AVANT user message
    // Conversion type-safe via mapper
    const sanitizedHistory = history.map((msg, index) => ({
      ...msg,
      id: msg.id ?? `history-${index}`,
      content: msg.content ?? '',
      timestamp: msg.timestamp ?? new Date().toISOString()
    })) as ChatMessage[];

    // ‚úÖ Extraire les images du format multi-modal si pr√©sent
    let userMessageImages: Array<{ url: string; fileName?: string }> | undefined;
    let userMessageText: string = '';
    
    if (!skipAddingUserMessage) {
      if (Array.isArray(processedMessage)) {
        // Format multi-modal : extraire texte et images
        const textPart = processedMessage.find((part): part is { type: 'text'; text: string } => part.type === 'text');
        userMessageText = textPart?.text || '';
        
        const imageParts = processedMessage.filter((part): part is { type: 'image_url'; image_url: { url: string; detail?: string } } => 
          part.type === 'image_url' && !!part.image_url?.url
        );
        
        if (imageParts.length > 0) {
          userMessageImages = imageParts.map(part => ({
            url: part.image_url.url,
            fileName: undefined // Pas de fileName dans le format multi-modal
          }));
          
          logger.debug(LogCategory.API,'[Stream Route] üñºÔ∏è Images extraites du format multi-modal:', {
            count: userMessageImages.length,
            urlPrefixes: userMessageImages.map(img => {
              const url = img.url;
              if (url.startsWith('data:')) {
                return `data:${url.substring(5, 20)}...`; // Afficher juste le type MIME
              } else if (url.startsWith('http')) {
                return url.substring(0, 50) + '...';
              }
              return url.substring(0, 30) + '...';
            })
          });
        }
      } else {
        // Format texte simple
        userMessageText = typeof processedMessage === 'string' ? processedMessage : '';
      }
    }

    // ‚úÖ CRITIQUE : D√©tection d'images APR√àS extraction compl√®te (pour override mod√®le)
    const hasImages = !!(userMessageImages && userMessageImages.length > 0);

    // ‚úÖ NOUVEAU : R√©solution override mod√®le/params (images + reasoning)
    // Maintenant qu'on a extrait les images, on peut faire la d√©tection correctement
    const { modelOverrideService } = await import('@/services/llm/modelOverride');
    const overrideContext: import('@/services/llm/modelOverride').ModelOverrideContext = {
      originalModel: model,
      provider: providerType,
      hasImages: hasImages,
      reasoningOverride: context.reasoningOverride || null,
      originalParams: { temperature, topP, maxTokens }
    };

    const overrideResult = modelOverrideService.resolveModelAndParams(overrideContext);
    model = overrideResult.model;
    // ‚úÖ Mettre √† jour les param√®tres finaux (d√©j√† d√©clar√©s plus haut)
    finalTemperature = overrideResult.params.temperature ?? temperature;
    finalTopP = overrideResult.params.topP ?? topP;
    finalMaxTokens = overrideResult.params.maxTokens ?? maxTokens;

    // ‚úÖ CRITIQUE : Utiliser le provider final du r√©sultat override (si d√©tect√©)
    // Si le mod√®le a chang√©, le provider peut aussi avoir chang√© (ex: liminality ‚Üí groq)
    if (overrideResult.finalProvider && overrideResult.finalProvider !== providerType) {
      logger.info(LogCategory.API, `[Stream Route] üîÑ Provider auto-corrig√© apr√®s override`, {
        from: providerType,
        to: overrideResult.finalProvider,
        model
      });
      providerType = overrideResult.finalProvider;
    }

    if (overrideResult.reasons.length > 0) {
      logger.info(LogCategory.API, '[Stream Route] üîÑ Model/Params override appliqu√©', {
        originalModel: overrideResult.originalModel,
        newModel: overrideResult.model,
        originalProvider: overrideContext.provider,
        finalProvider: providerType,
        originalParams: { temperature, topP, maxTokens },
        newParams: overrideResult.params,
        reasons: overrideResult.reasons
      });
    }

    // ‚úÖ CRITIQUE : Convertir les URLs S3 canoniques en presigned URLs pour les providers qui en ont besoin
    // Groq et xAI doivent pouvoir t√©l√©charger les images, donc on g√©n√®re des presigned URLs avec expiration longue
    if (userMessageImages && userMessageImages.length > 0 && (providerType === 'groq' || providerType === 'xai')) {
      const { convertS3UrlsToPresigned } = await import('@/services/s3/s3ImageUrlService');
      await convertS3UrlsToPresigned({
        images: userMessageImages,
        provider: providerType,
        expiresIn: 86400 // 24 heures
      });
    }

    // ‚úÖ CRITIQUE : Cr√©er le provider APR√àS l'override (pour utiliser les bons param√®tres)
    let provider;
    if (providerType === 'xai') {
      // ‚úÖ Utiliser XAINativeProvider pour support MCP complet
      const { XAINativeProvider } = await import('@/services/llm/providers/implementations/xai-native');
      provider = new XAINativeProvider({ model, temperature: finalTemperature, topP: finalTopP, maxTokens: finalMaxTokens });
    } else if (providerType === 'liminality') {
      const { LiminalityProvider } = await import('@/services/llm/providers/implementations/liminality');
      provider = new LiminalityProvider({ model, temperature: finalTemperature, topP: finalTopP, maxTokens: finalMaxTokens });
    } else if (providerType === 'cerebras') {
      const { CerebrasProvider } = await import('@/services/llm/providers/implementations/cerebras');
      provider = new CerebrasProvider({ model, temperature: finalTemperature, topP: finalTopP, maxTokens: finalMaxTokens });
    } else if (providerType === 'deepseek') {
      const { DeepSeekProvider } = await import('@/services/llm/providers/implementations/deepseek');
      provider = new DeepSeekProvider({ model, temperature: finalTemperature, topP: finalTopP, maxTokens: finalMaxTokens });
    } else {
      provider = new GroqProvider({ model, temperature: finalTemperature, topP: finalTopP, maxTokens: finalMaxTokens });
    }

    const messages: ChatMessage[] = ([
      {
        role: 'system',
        content: systemMessage,
        timestamp: new Date().toISOString()
      },
      ...sanitizedHistory,
      // Injecter context messages (notes, mentions) via ContextInjectionService
      ...contextInjectionResult.contextMessages,
      // N'ajouter le message user que si pas en mode skip (avec images extraites)
      ...(skipAddingUserMessage ? [] : [{
        role: 'user' as const,
        content: userMessageText,
        timestamp: new Date().toISOString(),
        ...(userMessageImages && userMessageImages.length > 0 && { attachedImages: userMessageImages })
      }])
    ]) as ChatMessage[];

    // ‚úÖ DEBUG : Logger les messages avant envoi au provider (surtout pour debug override)
    const lastUserMessage = messages.filter(m => m.role === 'user').pop();
    logger.info(LogCategory.API, '[Stream Route] üìã Messages construits pour le provider', {
      totalMessages: messages.length,
      historyLength: sanitizedHistory.length,
      hasUserMessage: !skipAddingUserMessage,
      userMessageText: userMessageText.substring(0, 100) + (userMessageText.length > 100 ? '...' : ''),
      userMessageHasImages: !!(userMessageImages && userMessageImages.length > 0),
      userMessageImageCount: userMessageImages?.length || 0,
      provider: providerType,
      model: model,
      messagesRoles: messages.map(m => m.role),
      lastMessageRole: messages[messages.length - 1]?.role,
      lastMessageHasImages: !!(messages[messages.length - 1] && 'attachedImages' in messages[messages.length - 1] && (messages[messages.length - 1] as { attachedImages?: unknown[] }).attachedImages?.length),
      // ‚úÖ CRITIQUE : V√©rifier si le dernier message user a bien attachedImages
      lastUserMessageHasAttachedImages: !!(lastUserMessage && 'attachedImages' in lastUserMessage && (lastUserMessage as { attachedImages?: unknown[] }).attachedImages?.length),
      lastUserMessageAttachedImagesCount: lastUserMessage && 'attachedImages' in lastUserMessage ? ((lastUserMessage as { attachedImages?: unknown[] }).attachedImages?.length || 0) : 0
    });

    // ‚úÖ Charger les tools (OpenAPI + MCP) ET les endpoints
    let tools: Tool[] = [];
    let openApiEndpoints = new Map<string, OpenApiEndpoint>();
    
    // üî• LOG CRITIQUE : V√©rifier si context.agentId existe
    logger.info(LogCategory.API, `[Stream Route] üî• MCP - Context`, {
      agentId: context.agentId || 'none'
    });
    
    if (context.agentId) {
      try {
        // 1. Charger les sch√©mas OpenAPI de l'agent
        const { data: agentSchemas } = await supabase
          .from('agent_openapi_schemas')
          .select('openapi_schema_id')
          .eq('agent_id', context.agentId);

        logger.info(LogCategory.API, `[Stream Route] üî• MCP - Sch√©mas OpenAPI`, {
          count: agentSchemas?.length || 0
        });

        let openApiTools: Tool[] = [];

        if (agentSchemas && agentSchemas.length > 0) {
          const { openApiSchemaService } = await import('@/services/llm/openApiSchemaService');
          
          const schemaIds = agentSchemas.map(s => s.openapi_schema_id);
          const { tools, endpoints } = await openApiSchemaService.getToolsAndEndpointsFromSchemas(schemaIds);
          
          openApiTools = tools;
          openApiEndpoints = endpoints;
          
          logger.info(LogCategory.API, `[Stream Route] üî• MCP - OpenAPI tools`, {
            count: openApiTools.length
          });
        } else {
          logger.warn(LogCategory.API, `[Stream Route] ‚ö†Ô∏è Aucun sch√©ma OpenAPI pour agent, mais on charge quand m√™me les MCP tools`, {
            agentId: context.agentId
          });
        }
        
        // 2. Charger les tools MCP de l'agent (TOUJOURS, m√™me sans sch√©mas OpenAPI)
        const { mcpConfigService } = await import('@/services/llm/mcpConfigService');
        
        logger.info(LogCategory.API, `[Stream Route] üî• MCP - Appel buildHybridTools`, {
          openApiToolsCount: openApiTools.length
        });
        
        // ‚úÖ Type-safe: buildHybridTools retourne Tool[] | McpServerConfig[]
        const hybridTools = await mcpConfigService.buildHybridTools(
          context.agentId,
          userToken,
          openApiTools
        );
        
        tools = hybridTools as Tool[];
        
        // ‚úÖ Charger les callables li√©s √† l'agent
        const { callableService } = await import('@/services/llm/callableService');
        const agentCallables = await callableService.getCallablesForAgent(context.agentId);
        const synesiaCallableIds = agentCallables.length > 0 ? agentCallables.map(c => c.id) : undefined;
        
        if (synesiaCallableIds && synesiaCallableIds.length > 0) {
          logger.info(LogCategory.API, `[Stream Route] üîó Callables trouv√©s pour l'agent`, {
            count: synesiaCallableIds.length
          });
          
          // ‚úÖ Pour Liminality : stocker les IDs pour utilisation native
          if (providerType === 'liminality') {
            (tools as Tool[] & { _synesiaCallables?: string[] })._synesiaCallables = synesiaCallableIds;
          } else {
            // ‚úÖ Pour les autres providers : convertir en FunctionTool
            const { CallableToolsAdapter } = await import('@/services/llm/providers/adapters/CallableToolsAdapter');
            const { tools: callableTools, mapping: callableMapping } = CallableToolsAdapter.convertToFunctionTools(agentCallables);
            
            if (callableTools.length > 0) {
              tools.push(...callableTools);
              
              // Stocker le mapping pour utilisation dans l'ex√©cution
              (tools as Tool[] & { _callableMapping?: Map<string, string> })._callableMapping = callableMapping;
              
              logger.info(LogCategory.API, `[Stream Route] ‚úÖ ${callableTools.length} callables convertis en tools pour provider ${providerType}`);
            }
          }
        }
        
        const mcpCount = tools.filter(isMcpTool).length;
        const functionTools = tools.filter(isFunctionTool);
        const openApiCount = functionTools.length;
        const callableMapping = (tools as Tool[] & { _callableMapping?: Map<string, string> })._callableMapping;
        const callableCount = callableMapping ? callableMapping.size : 0;
        
        logger.info(LogCategory.API, `[Stream Route] ‚úÖ MCP - Tools charg√©s`, {
          total: tools.length,
          mcpCount,
          openApiCount,
          callableCount,
          callables: agentCallables.length
        });
        
        logger.debug(LogCategory.API, `[Stream Route] ‚úÖ ${tools.length} tools charg√©s`, {
        mcpCount,
        openApiCount,
        callableCount,
        endpoints: openApiEndpoints.size,
        callables: agentCallables.length
      });
      } catch (toolsError) {
        logger.error(LogCategory.API, '[Stream Route] ‚ùå Erreur chargement tools', {
          error: toolsError instanceof Error ? toolsError.message : String(toolsError)
        }, toolsError instanceof Error ? toolsError : undefined);
        // Continue sans tools
      }
    } else {
      logger.warn(LogCategory.API, `[Stream Route] ‚ö†Ô∏è PAS de context.agentId ‚Üí 0 tools charg√©s`);
    }

    // ‚úÖ Cr√©er le ReadableStream pour SSE avec gestion tool calls
    const stream = new ReadableStream({
      async start(controller) {
        const encoder = new TextEncoder();
        const startTime = Date.now();
        const TIMEOUT_MS = 600000; // 600s (10 minutes) - permet encha√Ænements longs comme Cursor avec dizaines de tool calls
        
        // ‚úÖ V√©rifier timeout
        const checkTimeout = (context?: string) => {
          const elapsed = Date.now() - startTime;
          if (elapsed > TIMEOUT_MS) {
            const timeoutError = new Error(`Stream timeout apr√®s ${Math.round(elapsed / 1000)}s (limite: ${TIMEOUT_MS / 1000}s)`);
            (timeoutError as Error & { 
              isTimeout: boolean; 
              elapsed: number; 
              limit: number;
              context?: string;
            }).isTimeout = true;
            (timeoutError as Error & { elapsed: number }).elapsed = elapsed;
            (timeoutError as Error & { limit: number }).limit = TIMEOUT_MS;
            if (context) {
              (timeoutError as Error & { context: string }).context = context;
            }
            throw timeoutError;
          }
        };
        
        // ‚úÖ D√©clarer roundCount avant le try pour qu'il soit accessible dans le catch
        let roundCount = 0;
        
        try {
          logger.debug(LogCategory.API,'[Stream Route] üì° D√©marrage du stream SSE');
          
          // Helper pour envoyer un chunk SSE
          const sendSSE = (data: unknown) => {
            checkTimeout('sendSSE'); // V√©rifier avant chaque envoi
            const chunk = `data: ${JSON.stringify(data)}\n\n`;
            controller.enqueue(encoder.encode(chunk));
          };

          // Envoyer un chunk de d√©but avec info mod√®le (pour debug)
          const wasOverridden = overrideResult.model !== overrideResult.originalModel || overrideResult.reasons.length > 0;
          sendSSE({
            type: 'start',
            sessionId,
            timestamp: Date.now(),
            model: {
              original: overrideResult.originalModel,
              current: overrideResult.model,
              wasOverridden,
              reasons: overrideResult.reasons
            }
          });

          // ‚úÖ Boucle agentic en streaming (max 5 tours)
          const currentMessages = [...messages];
          const maxRounds = 20;
          let toolValidationRetryCount = 0; // ‚úÖ NOUVEAU: Compteur pour retry tool_use_failed
          const maxToolValidationRetries = 1; // ‚úÖ Max 1 retry automatique
          
          // ‚úÖ AUDIT : Tracker les tool calls d√©j√† ex√©cut√©s pour d√©tecter les doublons
          // ‚úÖ RECOVERY: Flag pour indiquer qu'on est dans un round final de recovery (sans tools)
          let forcedFinalRound = false;
          
          // ‚úÖ S√©parer les tools MCP (ex√©cut√©s par Groq nativement) des OpenAPI (ex√©cut√©s par nous)
          const mcpTools = tools.filter(isMcpTool);
          const openApiTools = tools.filter(isFunctionTool);
          
          // ‚úÖ Cr√©er une Map des tool names OpenAPI ‚Üí pour routing d'ex√©cution
          const openApiToolNames = new Set(openApiTools.map(t => t.function.name));
          
          // ‚úÖ R√©cup√©rer le mapping des callables si disponible
          const callableMapping = (tools as Tool[] & { _callableMapping?: Map<string, string> })._callableMapping;
          const callableToolNames = callableMapping ? new Set(callableMapping.keys()) : new Set<string>();
          
          logger.debug(LogCategory.API,`[Stream Route] üó∫Ô∏è Tools s√©par√©s:`, {
            totalTools: tools.length,
            mcpCount: mcpTools.length,
            openApiCount: openApiTools.length,
            callableCount: callableToolNames.size,
            mcpServers: mcpTools.map(t => (t as McpTool).server_label),
            openApiNames: Array.from(openApiToolNames),
            callableNames: Array.from(callableToolNames)
          });

          // ‚úÖ Helper: Extraire le texte d'un MessageContent (string ou array multi-modal)
          // Extrait dans helpers.ts

          while (roundCount < maxRounds) {
            roundCount++;
            logger.debug(LogCategory.API,`[Stream Route] üîÑ Round ${roundCount}/${maxRounds}`);

            // ‚úÖ AUDIT D√âTAILL√â : Logger les messages envoy√©s au LLM pour ce round
            const lastMessage = currentMessages[currentMessages.length - 1];
            const lastContent = lastMessage?.content ? extractTextFromContent(lastMessage.content) : '';
            
            logger.debug(LogCategory.API,`[Stream Route] üìã MESSAGES ENVOY√âS AU LLM - ROUND ${roundCount}:`, {
              messageCount: currentMessages.length,
              roles: currentMessages.map(m => m.role),
              hasToolCalls: currentMessages.some(m => hasToolCalls(m)),
              hasToolResults: currentMessages.some(m => m.role === 'assistant' && 'tool_results' in m && Array.isArray(m.tool_results) && m.tool_results.length > 0),
              lastMessageContent: lastContent.substring(0, 100) + (lastContent.length > 100 ? '...' : ''),
              isMultiModal: Array.isArray(lastMessage?.content)
            });
            
            // ‚úÖ AUDIT D√âTAILL√â : Logger les 5 derniers messages pour voir l'ordre
            if (roundCount > 1) {
              const last5 = currentMessages.slice(-5);
              logger.info(LogCategory.API, `[Stream Route] üîç DERNIERS 5 MESSAGES (Round ${roundCount}):`);
              last5.forEach((m, i) => {
                const toolCallId = m.role === 'tool' ? (m as { tool_call_id?: string }).tool_call_id : undefined;
                const toolCallsCount = m.role === 'assistant' && 'tool_calls' in m && Array.isArray(m.tool_calls) ? m.tool_calls.length : 0;
                logger.info(LogCategory.API, `  ${i+1}. ${m.role} - toolCalls:${toolCallsCount} - toolCallId:${toolCallId||'none'}`);
              });
            }

            // Accumuler tool calls et content du stream
            let accumulatedContent = '';
            const toolCallsMap = new Map<string, ToolCall>(); // Accumuler par ID pour g√©rer les chunks
            let finishReason: string | null = null;
            
            // ‚úÖ NOUVEAU : Stocker les mcp_calls pour les afficher dans la timeline
            let currentRoundMcpCalls: Array<{ server_label: string; name: string; arguments: Record<string, unknown>; output?: unknown }> = [];

            // ‚úÖ Stream depuis le provider avec gestion d'erreur
            try {
              // ‚úÖ CRITIQUE : Logger le mod√®le utilis√© et les images avant l'appel
              const lastUserMsg = currentMessages.filter(m => m.role === 'user').pop();
              logger.info(LogCategory.API, `[Stream Route] üöÄ Appel provider - Round ${roundCount}:`, {
                provider: providerType,
                model: model,
                hasImages: !!(lastUserMsg && 'attachedImages' in lastUserMsg && (lastUserMsg as { attachedImages?: unknown[] }).attachedImages?.length),
                imageCount: lastUserMsg && 'attachedImages' in lastUserMsg ? ((lastUserMsg as { attachedImages?: unknown[] }).attachedImages?.length || 0) : 0,
                messagesCount: currentMessages.length
              });
              
              // Extraire les callables si disponibles (pour Liminality uniquement)
              const synesiaCallables = (tools as Tool[] & { _synesiaCallables?: string[] })._synesiaCallables;
              
              // Appeler le provider (avec callables pour Liminality)
              const streamCall = providerType === 'liminality' && synesiaCallables
                ? (provider as { callWithMessagesStream: (messages: ChatMessage[], tools: Tool[], callables?: string[]) => AsyncGenerator<unknown> })
                    .callWithMessagesStream(currentMessages, tools, synesiaCallables)
                : provider.callWithMessagesStream(currentMessages, tools);
              
              for await (const chunk of streamCall) {
                // ‚úÖ V√©rifier si c'est un chunk d'erreur du provider
                if (chunk && typeof chunk === 'object' && 'type' in chunk && chunk.type === 'error') {
                  const errorChunk = chunk as { error?: string; errorCode?: string; provider?: string; model?: string };
                  sendSSE({
                    type: 'error',
                    error: errorChunk.error || 'Erreur inconnue du provider',
                    errorCode: errorChunk.errorCode,
                    provider: errorChunk.provider || providerType,
                    model: errorChunk.model || model,
                    roundCount,
                    timestamp: Date.now()
                  });
                  // Arr√™ter le stream en cas d'erreur
                  break;
                }
                
                // ‚úÖ Le chunk contient d√©j√† type: 'delta' (ajout√© par le provider)
                sendSSE(chunk);

                // üé® Broadcaster vers le canevas si actif
                if (noteId && chunk && typeof chunk === 'object' && 'content' in chunk && chunk.content) {
                  streamBroadcastService.broadcast(noteId, {
                    type: 'chunk',
                    data: chunk.content as string,
                    position: 'end', // Ajouter √† la fin
                    metadata: {
                      timestamp: Date.now()
                    }
                  });
                }

                // Accumuler content
                if (chunk && typeof chunk === 'object' && 'content' in chunk && chunk.content) {
                  accumulatedContent += chunk.content as string;
                }
                
                // ‚úÖ NOUVEAU : Extraire les mcp_calls si pr√©sents dans le chunk
                if (chunk && typeof chunk === 'object' && 'x_groq' in chunk && chunk.x_groq && typeof chunk.x_groq === 'object' && 'mcp_calls' in chunk.x_groq) {
                  const mcpCalls = (chunk.x_groq as { mcp_calls?: Array<{ server_label: string; name: string; arguments: Record<string, unknown>; output?: unknown }> }).mcp_calls;
                  if (mcpCalls && Array.isArray(mcpCalls)) {
                    currentRoundMcpCalls = mcpCalls;
                    logger.debug(LogCategory.API,`[Stream Route] üîß MCP calls d√©tect√©s dans chunk: ${mcpCalls.length}`);
                  }
                }
                
                // ‚úÖ Accumuler tool calls (peuvent venir en plusieurs chunks)
                if (chunk && typeof chunk === 'object' && 'tool_calls' in chunk && chunk.tool_calls && Array.isArray(chunk.tool_calls) && chunk.tool_calls.length > 0) {
                  for (const tc of chunk.tool_calls) {
                    // ‚úÖ VALIDATION: Filtrer les tool calls sans ID valide (chunks incomplets)
                    if (!tc.id || tc.id.trim().length === 0) {
                      logger.debug(LogCategory.API, `[Stream Route] ‚ö†Ô∏è SKIP tool call chunk sans ID valide (chunk incomplet, attendre prochain chunk)`, {
                        hasName: !!tc.function?.name,
                        hasArgs: !!tc.function?.arguments
                      });
                      continue; // ‚ö†Ô∏è Attendre le chunk suivant avec l'ID
                    }
                    
                    // Extension custom pour MCP tools (alreadyExecuted, result)
                    const mcpToolCall = tc as ToolCall & { alreadyExecuted?: boolean; result?: unknown };
                    const hasCustomProps = mcpToolCall.alreadyExecuted !== undefined || mcpToolCall.result !== undefined;
                    if (hasCustomProps) {
                      logger.debug(LogCategory.API,`[Stream Route] üîß Tool call avec props MCP:`, { 
                        id: tc.id, 
                        name: tc.function.name,
                        alreadyExecuted: mcpToolCall.alreadyExecuted,
                        hasResult: !!mcpToolCall.result
                      });
                    }
                    
                    if (!toolCallsMap.has(tc.id)) {
                      // ‚úÖ Cr√©er l'objet de base
                      const baseToolCall: ToolCall = {
                        id: tc.id,
                        type: 'function' as const,
                        function: {
                          name: tc.function?.name || '', // ‚ö†Ô∏è Peut √™tre vide dans le premier chunk
                          arguments: tc.function?.arguments || ''
                        }
                      };
                      
                      // ‚úÖ Copier TOUTES les propri√©t√©s custom (alreadyExecuted, result, etc.)
                      const fullToolCall = Object.assign(baseToolCall, tc);
                      toolCallsMap.set(tc.id, fullToolCall);
                    } else {
                      // Accumuler les arguments progressifs
                      const existing = toolCallsMap.get(tc.id);
                      if (!existing) {
                        logger.error(LogCategory.API, `[Stream Route] ‚ö†Ô∏è Tool call ${tc.id} not found in map`, { toolCallId: tc.id });
                        continue;
                      }
                      // ‚úÖ Mettre √† jour le nom si pr√©sent (peut arriver apr√®s l'ID dans le stream)
                      if (tc.function?.name && tc.function.name.trim().length > 0) {
                        existing.function.name = tc.function.name;
                      }
                      // ‚úÖ Accumuler les arguments (peuvent venir en plusieurs chunks)
                      if (tc.function?.arguments) {
                        existing.function.arguments += tc.function.arguments;
                      }
                    }
                  }
                }

                // ‚úÖ Capturer finish_reason
                if (chunk && typeof chunk === 'object' && 'finishReason' in chunk && chunk.finishReason) {
                  finishReason = chunk.finishReason as string;
                }
              }
            } catch (streamError) {
              // ‚úÖ ERREUR CRITIQUE : Le stream du provider a √©chou√©
              const errorMessage = streamError instanceof Error ? streamError.message : String(streamError);
              const errorStack = streamError instanceof Error ? streamError.stack : undefined;
              
              // ‚úÖ Extraire les m√©tadonn√©es enrichies attach√©es par le provider (si pr√©sentes)
              const enrichedError = streamError as Error & { 
                statusCode?: number; 
                provider?: string; 
                errorCode?: string; 
              };
              
              let statusCode = enrichedError.statusCode;
              let errorCode = enrichedError.errorCode;
              let providerFromError = enrichedError.provider;
              let errorDetails = errorMessage;
              
              // ‚úÖ Fallback: Parser le message pour extraire statusCode si non pr√©sent
              if (!statusCode) {
                const httpErrorMatch = errorMessage.match(/(?:error|status):\s*(\d{3})/i);
                if (httpErrorMatch) {
                  statusCode = parseInt(httpErrorMatch[1], 10);
                }
              }
              
              // ‚úÖ Fallback: Parser le message pour extraire errorCode si non pr√©sent
              if (!errorCode) {
                const errorCodeMatch = errorMessage.match(/code[:\s]+["']?([a-z_]+)["']?/i);
                if (errorCodeMatch) {
                  errorCode = errorCodeMatch[1];
                }
              }
              
              logger.error(LogCategory.API, `[Stream Route] ‚ùå ERREUR STREAMING PROVIDER (Round ${roundCount}):`, {
                provider: providerFromError || providerType,
                model,
                statusCode,
                errorCode,
                errorMessage,
                errorStack,
                roundCount,
                sessionId,
                messagesCount: currentMessages.length
              });
              
              // ‚úÖ RETRY AUTOMATIQUE pour tool_use_failed (1 fois max)
              if (errorCode === 'tool_use_failed' && toolValidationRetryCount < maxToolValidationRetries) {
                toolValidationRetryCount++;
                
                logger.warn(LogCategory.API, `[Stream Route] üîÑ Retry automatique pour tool_use_failed (${toolValidationRetryCount}/${maxToolValidationRetries})`);
                
                // Envoyer un SSE pour informer le client du retry
                sendSSE({
                  type: 'assistant_round_complete',
                  finishReason: 'error_retry',
                  content: `‚ö†Ô∏è Erreur de validation tool call d√©tect√©e. Retry automatique en cours...`
                });
                
                // Ajouter un message syst√®me pour que le LLM corrige
                currentMessages.push({
                  role: 'system',
                  content: `‚ùå Tool call validation error: ${errorDetails}\n\nThe tool you tried to call is not available or the parameters are invalid. Please:\n1. Check the available tools list\n2. Use only the tools that are actually provided\n3. Ensure all parameters match the expected schema\n\nIf you cannot complete the task with available tools, inform the user clearly.`
                });
                
                // Continuer la boucle pour r√©essayer
                continue;
              }
              
              // ‚úÖ Si retry √©puis√© ou erreur non-recoverable ‚Üí Envoyer erreur au client
              sendSSE({
                type: 'error',
                error: errorDetails,
                errorCode, // ‚úÖ NOUVEAU: Code d'erreur sp√©cifique (ex: "tool_use_failed")
                provider: providerFromError || providerType,
                model,
                statusCode,
                roundCount,
                timestamp: Date.now(),
                recoverable: (statusCode === 400 || statusCode === 429 || errorCode === 'tool_use_failed') && toolValidationRetryCount >= maxToolValidationRetries // ‚úÖ Recoverable si retry disponible
              });
              
              // Arr√™ter la boucle des rounds
              break;
            }

            // ‚úÖ AUDIT D√âTAILL√â : Logger la d√©cision de fin de round
            logger.debug(LogCategory.API,`[Stream Route] üéØ D√âCISION ROUND ${roundCount}:`, {
              finishReason,
              toolCallsCount: toolCallsMap.size,
              accumulatedContentLength: accumulatedContent.length,
              willContinue: finishReason === 'tool_calls' && toolCallsMap.size > 0
            });

            // ‚úÖ RECOVERY: Si on est dans un round final forc√©, sortir imm√©diatement apr√®s la r√©ponse
            if (forcedFinalRound) {
              logger.info(LogCategory.API, '[Stream Route] ‚úÖ Round final de recovery termin√© - sortie de la boucle');
              break;
            }

            // ‚úÖ D√©cision bas√©e sur finish_reason
            // ‚ö†Ô∏è CRITICAL: Si finishReason === 'stop' MAIS on a des tool calls MCP, on doit les afficher AVANT de sortir
            if (finishReason === 'tool_calls' && toolCallsMap.size > 0) {
              logger.debug(LogCategory.API,`[Stream Route] üîß Tool calls d√©tect√©s (${toolCallsMap.size}), ex√©cution...`);
            } else if (finishReason === 'stop') {
              // ‚úÖ CRITICAL FIX: Si on a des tool calls MCP (d√©j√† ex√©cut√©s), on doit les afficher AVANT de sortir
              if (toolCallsMap.size > 0) {
                logger.debug(LogCategory.API,`[Stream Route] üîß finishReason='stop' mais ${toolCallsMap.size} tool call(s) MCP √† afficher - traitement avant sortie`);
                // On continue pour traiter les tool calls MCP (lignes suivantes)
              } else {
                logger.debug(LogCategory.API,'[Stream Route] ‚úÖ R√©ponse finale (stop), fin du stream');
                break;
              }
            } else if (finishReason === 'length') {
              logger.warn(LogCategory.API, '[Stream Route] ‚ö†Ô∏è Token limit atteint');
              break;
            } else {
              logger.debug(LogCategory.API,'[Stream Route] ‚úÖ Pas de tool calls, fin du stream');
              break;
            }

            const accumulatedToolCalls = Array.from(toolCallsMap.values());

            // ‚úÖ VALIDATION: Filtrer les tool calls invalides (id vide, name vide)
            const validToolCalls = accumulatedToolCalls.filter((tc) => {
              const hasValidId = tc.id && tc.id.trim().length > 0;
              const hasValidName = tc.function?.name && tc.function.name.trim().length > 0;
              
              if (!hasValidId || !hasValidName) {
                logger.warn(LogCategory.API, `[Stream Route] ‚ö†Ô∏è SKIP tool call invalide:`, {
                  id: tc.id || '(vide)',
                  name: tc.function?.name || '(vide)',
                  hasValidId,
                  hasValidName
                });
                return false;
              }
              return true;
            });

            // ‚úÖ S√©parer les tool calls : MCP x.ai (d√©j√† ex√©cut√©s) vs autres (√† ex√©cuter)
            const alreadyExecutedTools: ToolCall[] = [];
            const toolsToExecute: ToolCall[] = [];
            
            validToolCalls.forEach((tc) => {
              if (tc.alreadyExecuted === true) {
                alreadyExecutedTools.push(tc);
              } else {
                toolsToExecute.push(tc);
              }
            });

            logger.debug(LogCategory.API,`[Stream Route] üîß Tool calls: ${alreadyExecutedTools.length} d√©j√† ex√©cut√©s (MCP x.ai), ${toolsToExecute.length} √† ex√©cuter (${accumulatedToolCalls.length - validToolCalls.length} invalides filtr√©s)`);

            // ‚úÖ D√âDUPLICATION SIMPLE: Utiliser uniquement l'ID (les IDs sont uniques par d√©finition)
            // ‚ö†Ô∏è IMPORTANT: On ne bloque PAS les tool calls entre les rounds - c'est normal qu'un tool soit appel√© plusieurs fois dans une conversation
            const uniqueToolCalls: ToolCall[] = [];
            const seenToolCallIds = new Set<string>(); // ‚úÖ IDs d√©j√† vus dans ce round uniquement
            
            toolsToExecute.forEach((tc, index) => {
              // ‚úÖ Validation
              if (!tc.id || tc.id.trim().length === 0) {
                logger.warn(LogCategory.API, `[Stream Route] ‚ö†Ô∏è SKIP tool call sans ID valide`);
                return;
              }
              
              if (!tc.function?.name || tc.function.name.trim().length === 0) {
                logger.warn(LogCategory.API, `[Stream Route] ‚ö†Ô∏è SKIP tool call sans nom de fonction`);
                return;
              }

              // ‚úÖ V√©rifier uniquement si l'ID a d√©j√† √©t√© vu dans CE round (vrai doublon)
              if (seenToolCallIds.has(tc.id)) {
                logger.warn(LogCategory.API, `[Stream Route] ‚ö†Ô∏è DOUBLON D√âTECT√â (m√™me ID dans ce round) - SKIP ${tc.function.name}`, {
                  id: tc.id,
                  round: roundCount
                });
                return;
              }

              logger.info(LogCategory.API, `[Stream Route] üîß TOOL CALL ${index + 1}:`, {
                id: tc.id,
                functionName: tc.function.name,
                args: (tc.function.arguments || '').substring(0, 100),
                round: roundCount
              });

              // ‚úÖ Ajouter l'ID √† la liste des IDs vus dans ce round
              seenToolCallIds.add(tc.id);
              uniqueToolCalls.push(tc);
            });

            const dedupedCount = toolsToExecute.length - uniqueToolCalls.length;

            // ‚úÖ NOUVEAU : Persister le message de ce round (outil d√©dupliqu√©)
            // Combiner MCP tools (d√©j√† ex√©cut√©s) + tools √† ex√©cuter pour la timeline
            const allToolsForTimeline = [...alreadyExecutedTools, ...uniqueToolCalls];
            
            if (accumulatedContent || allToolsForTimeline.length > 0) {
              logger.debug(LogCategory.API,`[Stream Route] üì§ Envoi assistant_round_complete:`, {
                toolCallsCount: allToolsForTimeline.length,
                mcpCount: alreadyExecutedTools.length,
                openApiCount: uniqueToolCalls.length,
                toolNames: allToolsForTimeline.map(tc => tc.function.name)
              });
              
              sendSSE({
                type: 'assistant_round_complete',
                content: accumulatedContent,
                tool_calls: allToolsForTimeline,
                finishReason: finishReason,
                timestamp: Date.now()
              });
            }

            if (dedupedCount > 0) {
              sendSSE({
                type: 'tool_dedup',
                skipped: dedupedCount,
                timestamp: Date.now()
              });
            }

            // ‚úÖ CRITICAL FIX: Si on a seulement des MCP tools d√©j√† ex√©cut√©s ET du contenu, c'est la fin
            // xAI a d√©j√† g√©n√©r√© la r√©ponse finale apr√®s avoir ex√©cut√© le MCP call
            // ‚ö†Ô∏è MAIS: On doit envoyer assistant_round_complete et tool_result AVANT de sortir
            // On continue pour traiter les tool calls MCP (lignes suivantes)
            // Le break sera apr√®s l'envoi des tool_result (voir ligne ~950)
            if (uniqueToolCalls.length === 0 && alreadyExecutedTools.length > 0 && accumulatedContent.length > 0) {
              logger.info(LogCategory.API, '[Stream Route] ‚úÖ MCP tools d√©j√† ex√©cut√©s + contenu re√ßu - r√©ponse finale de xAI, traitement puis fin du round');
              // On continue pour envoyer assistant_round_complete et tool_result
            }

            // ‚úÖ CRITICAL FIX: Si tous les tool calls sont des doublons, forcer un dernier round SANS tools
            // pour que le LLM explique la situation √† l'utilisateur au lieu d'un arr√™t silencieux
            // ‚ö†Ô∏è MAIS: Si on a des MCP tools d√©j√† ex√©cut√©s, PAS besoin de forcer un round
            if (uniqueToolCalls.length === 0 && toolsToExecute.length > 0 && alreadyExecutedTools.length === 0) {
              logger.warn(LogCategory.API, '[Stream Route] ‚ö†Ô∏è Tous les tool calls √©taient des doublons - for√ßage dernier round SANS tools');
              
              // Ajouter un message syst√®me expliquant la situation
              currentMessages.push({
                role: 'system',
                content: `‚ö†Ô∏è ATTENTION: Tous vos tool calls pr√©c√©dents √©taient des doublons d'appels d√©j√† effectu√©s. Pour √©viter une boucle infinie, les tools ont √©t√© d√©sactiv√©s pour ce round. 

Vous DEVEZ maintenant r√©pondre directement √† l'utilisateur pour :
1. Expliquer ce qui s'est pass√© (quelles erreurs ont √©t√© rencontr√©es)
2. Dire pourquoi vous n'avez pas pu compl√©ter la t√¢che
3. Proposer des alternatives ou demander des clarifications

NE TENTEZ PAS de refaire les m√™mes tool calls. R√©pondez en texte.`,
                timestamp: new Date().toISOString()
              });
              
              // Envoyer un √©v√©nement SSE pour informer l'utilisateur
              sendSSE({
                type: 'system_notice',
                message: 'D√©tection de doublons : relance du LLM sans tools pour explication',
                timestamp: Date.now()
              });
              
              // ‚úÖ Forcer tools = [] et activer le flag de recovery
              tools = [];
              forcedFinalRound = true;
              // On continue la boucle pour que le LLM r√©ponde
              continue;
            }

            // ‚úÖ Ajouter le message assistant avec TOUS les tool calls (MCP + OpenAPI)
            // Les MCP tools doivent aussi √™tre dans l'historique pour √©viter d'√™tre trait√©s comme doublons
            if (allToolsForTimeline.length > 0) {
              currentMessages.push({
                role: 'assistant',
                content: accumulatedContent || '',
                tool_calls: allToolsForTimeline, // ‚úÖ MCP + OpenAPI
                timestamp: new Date().toISOString()
              });
            }

            // ‚úÖ Ex√©cuter les tool calls (uniques uniquement)
            // ‚ö†Ô∏è Les MCP tools x.ai sont d√©j√† ex√©cut√©s c√¥t√© serveur, on ajoute juste leur r√©sultat
            if (alreadyExecutedTools.length > 0) {
              logger.info(LogCategory.API, `[Stream Route] ‚úÖ ${alreadyExecutedTools.length} MCP tool(s) d√©j√† ex√©cut√©(s) par x.ai - ajout r√©sultats`);
              
              // Ajouter les r√©sultats MCP dans l'historique pour le prochain round
              for (const mcpTool of alreadyExecutedTools) {
                // Extension custom pour MCP tools (result)
                const mcpToolWithResult = mcpTool as ToolCall & { result?: unknown };
                const result = mcpToolWithResult.result || 'Executed by x.ai (MCP)';
                
                currentMessages.push({
                  role: 'tool',
                  tool_call_id: mcpTool.id,
                  name: mcpTool.function.name, // ‚úÖ Required by ToolMessage
                  content: typeof result === 'string' ? result : JSON.stringify(result),
                  timestamp: new Date().toISOString()
                });
                
                // Envoyer dans la timeline UI
                sendSSE({
                  type: 'tool_result',
                  toolCallId: mcpTool.id,
                  toolName: mcpTool.function.name,
                  success: true,
                  result: result,
                  timestamp: Date.now(),
                  isMcp: true // ‚úÖ Flag pour diff√©rencier dans l'UI
                });
              }
              
              // ‚úÖ CRITICAL FIX: Si c'√©tait la fin (finishReason === 'stop'), sortir APR√àS avoir envoy√© les tool_result
              if (finishReason === 'stop' && uniqueToolCalls.length === 0) {
                logger.info(LogCategory.API, '[Stream Route] ‚úÖ Tool_result MCP envoy√©s, fin du stream (finishReason=stop)');
                break;
              }
            }
            
            logger.debug(LogCategory.API,`[Stream Route] üîß Ex√©cution de ${uniqueToolCalls.length} tool calls OpenAPI (apr√®s d√©duplication)`);
            
            // Envoyer un √©v√©nement d'ex√©cution de tools (seulement pour ceux √† ex√©cuter)
            if (uniqueToolCalls.length > 0) {
              sendSSE({
                type: 'tool_execution',
                toolCount: uniqueToolCalls.length,
                timestamp: Date.now()
              });
            }

            if (!userToken) {
              throw new Error('[Stream Route] Missing user token for OpenAPI tool execution');
            }

            // ‚úÖ Cr√©er l'executor OpenAPI (les tools MCP sont g√©r√©s nativement par Groq)
            const { OpenApiToolExecutor } = await import('@/services/llm/executors/OpenApiToolExecutor');
            const openApiExecutor = new OpenApiToolExecutor('', openApiEndpoints);
            
            // ‚úÖ Ex√©cuter chaque tool call
            for (const toolCall of uniqueToolCalls) {
              checkTimeout(`tool_execution:${toolCall.function.name}`); // V√©rifier timeout avant chaque tool
              try {
                logger.debug(LogCategory.API,`[Stream Route] üîß Ex√©cution tool: ${toolCall.function.name}`);
                
                // ‚úÖ V√©rifier si c'est un tool OpenAPI (ex√©cut√© par nous)
                // Les tools MCP sont ex√©cut√©s nativement par Groq, on ne les touche pas
                const isOpenApiTool = openApiToolNames.has(toolCall.function.name);
                const isCallableTool = callableToolNames.has(toolCall.function.name);
                
                if (isCallableTool) {
                  // ‚úÖ Tool Callable : Ex√©cuter via CallableToolExecutor
                  logger.debug(LogCategory.API,`[Stream Route] üîß Callable tool d√©tect√©: ${toolCall.function.name}`);
                  
                  if (!callableMapping) {
                    throw new Error(`Mapping callable manquant pour ${toolCall.function.name}`);
                  }
                  
                  const { CallableToolExecutor } = await import('@/services/llm/executors/CallableToolExecutor');
                  const callableExecutor = new CallableToolExecutor(callableMapping);
                  const result = await callableExecutor.executeToolCall(toolCall, userToken);
                  
                  // ‚úÖ AUDIT D√âTAILL√â : Logger apr√®s ex√©cution
                  logger.debug(LogCategory.API,`[Stream Route] ‚úÖ APR√àS EX√âCUTION CALLABLE:`, {
                    toolName: toolCall.function.name,
                    success: result.success,
                    resultLength: typeof result.content === 'string' ? result.content.length : 'object',
                    resultPreview: typeof result.content === 'string' ? result.content.substring(0, 100) + '...' : 'object'
                  });

                  // Ajouter le r√©sultat aux messages
                  currentMessages.push({
                    role: 'tool',
                    tool_call_id: toolCall.id,
                    name: toolCall.function.name,
                    content: result.content,
                    timestamp: new Date().toISOString()
                  });

                  // Envoyer dans la timeline UI
                  let parsedResult: unknown;
                  try {
                    parsedResult = JSON.parse(result.content);
                  } catch (parseError) {
                    logger.warn(LogCategory.API, `[Stream Route] ‚ö†Ô∏è Erreur parsing r√©sultat callable, utilisation du contenu brut`, {
                      error: parseError instanceof Error ? parseError.message : String(parseError)
                    });
                    parsedResult = result.content;
                  }
                  
                  sendSSE({
                    type: 'tool_result',
                    toolCallId: toolCall.id,
                    toolName: toolCall.function.name,
                    success: result.success,
                    result: parsedResult,
                    timestamp: Date.now(),
                    isCallable: true // ‚úÖ Flag pour diff√©rencier les callable tools dans l'UI
                  });
                  
                  logger.debug(LogCategory.API,`[Stream Route] ‚úÖ Callable tool ${toolCall.function.name} ex√©cut√© et r√©sultat envoy√©`);
                  continue;
                }
                
                if (!isOpenApiTool) {
                  // ‚úÖ Tool MCP : Groq l'a d√©j√† ex√©cut√©, afficher dans la timeline
                  logger.debug(LogCategory.API,`[Stream Route] üîß MCP tool d√©tect√© (g√©r√© par Groq): ${toolCall.function.name}`);
                  
                  // ‚úÖ Chercher le r√©sultat MCP correspondant
                  let mcpOutput: string | unknown = 'MCP tool executed by Groq';
                  
                  if (currentRoundMcpCalls.length > 0) {
                    const mcpCall = currentRoundMcpCalls.find(call => 
                      toolCall.function.name.includes(call.name) || toolCall.function.name.includes(call.server_label)
                    );
                    if (mcpCall?.output) {
                      mcpOutput = mcpCall.output;
                    }
                  }
                  
                  // ‚úÖ Envoyer l'√©v√©nement timeline pour affichage
                  sendSSE({
                    type: 'tool_result',
                    toolCallId: toolCall.id,
                    toolName: toolCall.function.name,
                    success: true,
                    result: typeof mcpOutput === 'string' ? mcpOutput : JSON.stringify(mcpOutput),
                    timestamp: Date.now(),
                    isMcp: true // ‚úÖ Flag pour diff√©rencier les MCP tools dans l'UI
                  });
                  
                  logger.debug(LogCategory.API,`[Stream Route] ‚úÖ MCP tool ${toolCall.function.name} affich√© dans timeline`);
                  continue;
                }
                
                // ‚úÖ Ex√©cuter le tool OpenAPI
                const result = await openApiExecutor.executeToolCall(toolCall, userToken);

                // ‚úÖ AUDIT D√âTAILL√â : Logger apr√®s ex√©cution
                logger.debug(LogCategory.API,`[Stream Route] ‚úÖ APR√àS EX√âCUTION TOOL:`, {
                  toolName: toolCall.function.name,
                  success: result.success,
                  resultLength: typeof result.content === 'string' ? result.content.length : 'object',
                  resultPreview: typeof result.content === 'string' ? result.content.substring(0, 100) + '...' : 'object'
                });

                // Ajouter le r√©sultat aux messages
                currentMessages.push({
                  role: 'tool',
                  tool_call_id: toolCall.id,
                  name: toolCall.function.name,
                  content: typeof result.content === 'string' ? result.content : JSON.stringify(result.content),
                  timestamp: new Date().toISOString()
                });

                // Envoyer le r√©sultat au client
                sendSSE({
                  type: 'tool_result',
                  toolCallId: toolCall.id,
                  toolName: toolCall.function.name,
                  success: result.success,
                  result: result.content,
                  timestamp: Date.now()
                });

                logger.debug(LogCategory.API,`[Stream Route] ‚úÖ Tool ${toolCall.function.name} ex√©cut√© (success: ${result.success})`);

              } catch (toolError) {
                logger.error(LogCategory.API, `[Stream Route] ‚ùå Erreur tool ${toolCall.function.name}:`, undefined, toolError instanceof Error ? toolError : undefined);
                
                // Ajouter un r√©sultat d'erreur
                const errorContent = `Erreur: ${toolError instanceof Error ? toolError.message : String(toolError)}`;
                
                currentMessages.push({
                  role: 'tool',
                  tool_call_id: toolCall.id,
                  name: toolCall.function.name,
                  content: errorContent,
                  timestamp: new Date().toISOString()
                });
                
                // Envoyer l'erreur au client
                sendSSE({
                  type: 'tool_result',
                  toolCallId: toolCall.id,
                  toolName: toolCall.function.name,
                  success: false,
                  result: errorContent,
                  timestamp: Date.now()
                });
              }
            }

            const hasReachedRoundLimit = roundCount >= maxRounds;

            if (hasReachedRoundLimit) {
              logger.warn(LogCategory.API, `[Stream Route] ‚ö†Ô∏è Limite de ${maxRounds} rounds atteinte, relance finale forc√©e sans nouveaux tool calls`);
              
              try {
                // Pas de callables dans le round final (forcer r√©ponse)
                const finalResponse = providerType === 'liminality'
                  ? await (provider as { callWithMessages: (messages: ChatMessage[], tools: Tool[], callables?: string[]) => Promise<unknown> })
                      .callWithMessages(currentMessages, [], undefined)
                  : await provider.callWithMessages(currentMessages, []);

                // Type guard pour finalResponse
                if (finalResponse && typeof finalResponse === 'object') {
                  const response = finalResponse as { tool_calls?: unknown[]; content?: string; reasoning?: string };
                  
                  if ('tool_calls' in response && response.tool_calls && Array.isArray(response.tool_calls) && response.tool_calls.length > 0) {
                    logger.warn(LogCategory.API, '[Stream Route] ‚ö†Ô∏è R√©ponse finale forc√©e contient encore des tool calls, ils seront ignor√©s', {
                      requestedToolCalls: response.tool_calls.length
                    });
                  }

                  if (response.content) {
                    sendSSE({
                      type: 'delta',
                      content: response.content,
                      reasoning: response.reasoning
                    });

                    sendSSE({
                      type: 'assistant_round_complete',
                      content: response.content,
                      tool_calls: [],
                      finishReason: 'stop',
                      forced: true,
                      timestamp: Date.now()
                    });

                    currentMessages.push({
                      role: 'assistant',
                      content: response.content,
                      timestamp: new Date().toISOString()
                    });
                  } else {
                    logger.error(LogCategory.API, '[Stream Route] ‚ùå R√©ponse finale forc√©e vide, envoi d\'une erreur au client');
                    sendSSE({
                      type: 'error',
                      error: 'R√©ponse finale indisponible apr√®s la limite de tool calls'
                    });
                  }
                } else {
                  logger.error(LogCategory.API, '[Stream Route] ‚ùå R√©ponse finale invalide, envoi d\'une erreur au client');
                  sendSSE({
                    type: 'error',
                    error: 'R√©ponse finale invalide apr√®s la limite de tool calls'
                  });
                }
              } catch (finalError) {
                logger.error(LogCategory.API, '[Stream Route] ‚ùå Erreur lors de la relance finale forc√©e', undefined, finalError instanceof Error ? finalError : undefined);
                sendSSE({
                  type: 'error',
                  error: 'Erreur lors de la relance finale forc√©e'
                });
              }

              break;
            }

            // Continuer la boucle pour relancer le LLM avec les r√©sultats
            logger.debug(LogCategory.API,`[Stream Route] üîÑ Relance du LLM avec ${currentMessages.length} messages`);
          }

          // Envoyer un chunk de fin
          sendSSE({
            type: 'done',
            rounds: roundCount,
            timestamp: Date.now()
          });

          // üé® Signaler la fin du streaming au canevas
          if (noteId) {
            streamBroadcastService.broadcast(noteId, {
              type: 'end'
            });
          }

          logger.info(LogCategory.API, '[Stream Route] ‚úÖ Stream termin√© avec succ√®s');
          controller.close();

        } catch (error) {
          // ‚úÖ D√©tecter si c'est un timeout
          const isTimeout = error instanceof Error && 'isTimeout' in error && (error as Error & { isTimeout: boolean }).isTimeout;
          const elapsed = error instanceof Error && 'elapsed' in error ? (error as Error & { elapsed: number }).elapsed : undefined;
          const limit = error instanceof Error && 'limit' in error ? (error as Error & { limit: number }).limit : TIMEOUT_MS;
          const context = error instanceof Error && 'context' in error ? (error as Error & { context?: string }).context : undefined;
          
          const errorMessage = error instanceof Error ? error.message : String(error);
          
          logger.error(LogCategory.API, '[Stream Route] ‚ùå Erreur stream:', {
            error: errorMessage,
            isTimeout,
            elapsed: elapsed ? `${Math.round(elapsed / 1000)}s` : undefined,
            limit: `${limit / 1000}s`,
            context,
            roundCount,
            sessionId,
            provider: providerType,
            model
          });
          
          // ‚úÖ Envoyer l'erreur au client avec m√©tadonn√©es enrichies
          const errorChunk = {
            type: 'error',
            error: errorMessage,
            errorCode: isTimeout ? 'timeout' : 'stream_error',
            provider: providerType,
            model,
            roundCount,
            timestamp: Date.now(),
            ...(isTimeout && {
              timeout: {
                elapsed: elapsed ? Math.round(elapsed / 1000) : undefined,
                limit: Math.round(limit / 1000),
                context
              }
            })
          };
          
          controller.enqueue(encoder.encode(`data: ${JSON.stringify(errorChunk)}\n\n`));
          
          controller.close();
        }
      }
    });

    // Retourner la r√©ponse avec headers SSE
    success = true;
    return new Response(stream, {
      headers: {
        'Content-Type': 'text/event-stream',
        'Cache-Control': 'no-cache',
        'Connection': 'keep-alive'
      }
    });

  } catch (error) {
    const errorType = error instanceof Error && error.message.includes('Validation') 
      ? 'validation_error' 
      : error instanceof Error && error.message.includes('Rate limit')
      ? 'rate_limit_error'
      : 'server_error';
    
    metricsCollector.recordError('chat/llm/stream', errorType, error instanceof Error ? error : new Error(String(error)));
    
    logger.error(LogCategory.API, '[Stream Route] ‚ùå Erreur globale:', undefined, error instanceof Error ? error : undefined);
    
    return new Response(
      JSON.stringify({
        error: 'Erreur serveur',
        message: error instanceof Error ? error.message : String(error)
      }),
      {
        status: 500,
        headers: { 'Content-Type': 'application/json' }
      }
    );
  } finally {
    const latency = Date.now() - startTime;
    metricsCollector.recordLatency('chat/llm/stream', latency, success);
    metricsCollector.recordThroughput('chat/llm/stream');
  }
}

