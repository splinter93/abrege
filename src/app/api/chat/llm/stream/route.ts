import { NextRequest } from 'next/server';
import { simpleLogger as logger } from '@/utils/logger';
import { parsePromptPlaceholders } from '@/utils/promptPlaceholders';
import { createClient } from '@supabase/supabase-js';
import type { SupabaseClient } from '@supabase/supabase-js';
import { XAIProvider } from '@/services/llm/providers/implementations/xai';
import { GroqProvider } from '@/services/llm/providers/implementations/groq';
import type { ChatMessage } from '@/types/chat';
import { hasToolCalls } from '@/types/chat';
import { SERVER_ENV } from '@/config/env.server';
import type { OpenApiEndpoint } from '@/services/llm/executors/OpenApiToolExecutor';
import type { Tool, McpTool } from '@/services/llm/types/strictTypes';
import type { ToolCall } from '@/services/llm/types/strictTypes';
import { isMcpTool, isFunctionTool } from '@/services/llm/types/strictTypes';
import { llmStreamRequestSchema } from '../validation';
import { chatRateLimiter } from '@/services/rateLimiter';
import {
  validateAndExtractUserId,
  resolveAgent,
  validateAndNormalizeModel,
  normalizeLLMParams,
  extractTextFromContent
} from './helpers';

// Force Node.js runtime for streaming
export const runtime = 'nodejs';
export const dynamic = 'force-dynamic';

// Client Supabase admin
const supabase = createClient(
  SERVER_ENV.supabase.url,
  SERVER_ENV.supabase.serviceRoleKey
);

/**
 * ‚úÖ Route API Streaming pour LLM (Groq ou xAI)
 * Retourne un ReadableStream avec SSE
 * Provider s√©lectionn√© automatiquement selon la config agent
 */
export async function POST(request: NextRequest) {
  let sessionId: string | undefined;
  let userToken: string | undefined;
  
  try {
    const body = await request.json();
    
    // ‚úÖ Validation Zod stricte
    const validation = llmStreamRequestSchema.safeParse(body);
    
    if (!validation.success) {
      logger.warn('[Stream Route] ‚ùå Validation failed:', validation.error.format());
      return new Response(
        JSON.stringify({ 
          error: 'Validation failed', 
          details: validation.error.flatten().fieldErrors 
        }),
        { status: 400, headers: { 'Content-Type': 'application/json' } }
      );
    }
    
    const { message, context, history, agentConfig, skipAddingUserMessage } = validation.data;

    // Extraire le token d'authentification
    const authHeader = request.headers.get('authorization');
    
    if (!authHeader || !authHeader.startsWith('Bearer ')) {
      return new Response(
        JSON.stringify({ error: 'Token d\'authentification manquant ou invalide' }),
        { status: 401, headers: { 'Content-Type': 'application/json' } }
      );
    }
    
    userToken = authHeader.replace('Bearer ', '');
    sessionId = context.sessionId;
    
    logger.info(`[Stream Route] üåä D√©marrage streaming pour session ${sessionId}`);

    // ‚úÖ Valider le JWT et extraire userId
    const userIdResult = await validateAndExtractUserId(
      userToken,
      supabase as unknown as SupabaseClient<unknown, { PostgrestVersion: string }, never, never, { PostgrestVersion: string }>
    );
    
    if (!userIdResult.success) {
      return new Response(
        JSON.stringify({ error: userIdResult.error }),
        { status: 401, headers: { 'Content-Type': 'application/json' } }
      );
    }
    
    const userId = userIdResult.userId;

    // ‚úÖ S√âCURIT√â: Rate limiting par utilisateur
    const chatLimit = await chatRateLimiter.check(userId);
    
    if (!chatLimit.allowed) {
      const resetDate = new Date(chatLimit.resetTime);
      logger.warn(`[Stream Route] ‚õî Rate limit d√©pass√© pour userId ${userId.substring(0, 8)}...`);
      
      return new Response(
        JSON.stringify({
          error: 'Rate limit d√©pass√©',
          message: `Vous avez atteint la limite de ${chatLimit.limit} messages par minute. Veuillez r√©essayer dans quelques instants.`,
          remaining: chatLimit.remaining,
          resetTime: chatLimit.resetTime,
          resetDate: resetDate.toISOString()
        }),
        {
          status: 429,
          headers: {
            'Content-Type': 'application/json',
            'X-RateLimit-Limit': chatLimit.limit.toString(),
            'X-RateLimit-Remaining': chatLimit.remaining.toString(),
            'X-RateLimit-Reset': chatLimit.resetTime.toString(),
            'Retry-After': Math.ceil((chatLimit.resetTime - Date.now()) / 1000).toString()
          }
        }
      );
    }

    // ‚úÖ R√©cup√©rer l'agent comme la route classique (table 'agents')
    const agentId = context.agentId;
    const providerName = context.provider || 'xai';
    
    const finalAgentConfig = await resolveAgent(
      agentId,
      providerName,
      agentConfig,
      supabase as unknown as SupabaseClient<unknown, { PostgrestVersion: string }, never, never, { PostgrestVersion: string }>
    );

    // ‚úÖ S√©lectionner le provider selon la config agent (Groq ou xAI)
    const providerType = finalAgentConfig?.provider?.toLowerCase() || 'groq';
    let model = finalAgentConfig?.model || (providerType === 'xai' ? 'grok-4-1-fast-reasoning' : 'openai/gpt-oss-20b');
    
    // üîç Validation et normalisation du mod√®le
    model = validateAndNormalizeModel(providerType, model);
    
    // Validation et normalisation des param√®tres LLM
    const { temperature, topP, maxTokens } = normalizeLLMParams(finalAgentConfig);

    // üîç DEBUG: Log d√©taill√© de la s√©lection
    logger.info(`[Stream Route] üîÑ Configuration LLM:`, {
      agentId: finalAgentConfig?.id,
      agentName: finalAgentConfig?.name,
      provider: providerType,
      model: model,
      temperature,
      topP,
      maxTokens,
      originalModel: finalAgentConfig?.model,
      corrected: finalAgentConfig?.model !== model
    });

    // Cr√©er le provider appropri√©
    const provider = providerType === 'xai'
      ? new XAIProvider({ model, temperature, topP, maxTokens })
      : new GroqProvider({ model, temperature, topP, maxTokens });
    
    logger.info(`[Stream Route] ‚úÖ Provider ${providerType.toUpperCase()} cr√©√© avec mod√®le: ${model}`);

    // ‚úÖ Construire le contexte UI (SANS attachedNotes - g√©r√©es s√©par√©ment)
    const uiContext = {
      ...(context.uiContext || {})
      // Notes ne sont PLUS pass√©es ici (√©vite duplication tokens)
    };
    
    logger.dev('[Stream Route] üïµÔ∏è‚Äç‚ôÇÔ∏è Contexte UI re√ßu:', {
      hasUIContext: !!context.uiContext,
      uiContextKeys: context.uiContext ? Object.keys(context.uiContext) : [],
      contextType: context.type,
      contextId: context.id,
      hasAttachedNotes: !!(context.attachedNotes && context.attachedNotes.length > 0),
      attachedNotesCount: context.attachedNotes?.length || 0
    });

    // ‚úÖ Construire le system message SANS notes (instructions agent uniquement)
    const { SystemMessageBuilder } = await import('@/services/llm/SystemMessageBuilder');
    const systemMessageBuilder = SystemMessageBuilder.getInstance();
    
    const systemMessageResult = systemMessageBuilder.buildSystemMessage(
      finalAgentConfig || {},
      {
        type: context.type || 'chat_session',
        name: context.name || 'Chat',
        id: context.id ?? sessionId ?? 'unknown',
        sessionId: sessionId ?? '', // ‚úÖ CRITIQUE : Injecter sessionId explicitement pour tous les LLM
        provider: providerType,
        ...uiContext  // Sans attachedNotes
      }
    );
    
    const systemMessage = systemMessageResult.content;
    
    logger.dev('[Stream Route] üìù System message construit:', {
      length: systemMessage.length,
      hasContext: systemMessage.includes('Contexte actuel'),
      agentName: finalAgentConfig?.name || 'default'
    });

    // ‚úÖ NOUVEAU: Construire message contexte s√©par√© style Cursor si notes pr√©sentes
    const { attachedNotesFormatter } = await import('@/services/llm/AttachedNotesFormatter');
    const { mentionedNotesFormatter } = await import('@/services/llm/MentionedNotesFormatter');
    let contextMessage: ChatMessage | null = null;
    let mentionsMessage: ChatMessage | null = null;
    
    // üìé NOTES √âPINGL√âES (chargement complet)
    if (context.attachedNotes && context.attachedNotes.length > 0) {
      try {
        const contextContent = attachedNotesFormatter.buildContextMessage(context.attachedNotes);
        
        if (contextContent) {
          contextMessage = {
            // Role 'user' choisi pour compatibilit√© maximale tous providers
            // Alternatives √©valu√©es :
            // - 'system' : Plus s√©mantique mais peut √™tre mal g√©r√© par certains providers
            // - 'developer' : Utilis√© par Cursor mais pas support√© par Groq/XAI
            // - 'user' : ‚úÖ Support√© partout, trait√© comme contexte par LLM
            role: 'user',
            content: contextContent,
            timestamp: new Date().toISOString()
          };
          
          logger.info('[Stream Route] üìé Contexte notes √©pingl√©es construit (full content):', {
            count: context.attachedNotes.length,
            contentLength: contextContent.length,
            totalLines: context.attachedNotes.reduce((sum: number, n: { markdown_content?: string }) => 
              sum + (n.markdown_content?.split('\n').length || 0), 0
            ),
            titles: context.attachedNotes.map((n: { title: string }) => n.title)
          });
        }
      } catch (error) {
        logger.error('[Stream Route] ‚ùå Erreur construction contexte notes:', error);
        // Continue sans notes (fallback gracieux)
      }
    }
    
    // @ MENTIONS L√âG√àRES (m√©tadonn√©es uniquement)
    if (context.mentionedNotes && context.mentionedNotes.length > 0) {
      try {
        const mentionsContent = mentionedNotesFormatter.buildContextMessage(context.mentionedNotes);
        
        if (mentionsContent) {
          mentionsMessage = {
            role: 'user',
            content: mentionsContent,
            timestamp: new Date().toISOString()
          };
          
          logger.info('[Stream Route] @ Contexte mentions l√©g√®res construit (metadata only):', {
            count: context.mentionedNotes.length,
            contentLength: mentionsContent.length,
            tokensEstimate: Math.ceil(mentionsContent.length / 4),
            slugs: context.mentionedNotes.map((m: { slug: string }) => m.slug)
          });
        }
      } catch (error) {
        logger.error('[Stream Route] ‚ùå Erreur construction contexte mentions:', error);
        // Continue sans mentions (fallback gracieux)
      }
    }
    
    // ‚úÖ NOUVEAU : Remplacer prompts /slug par templates avant LLM
    let processedMessage: string = typeof message === 'string' ? message : '';
    if (!skipAddingUserMessage && processedMessage) {
      // R√©cup√©rer prompts depuis le dernier message user de l'historique
      const lastUserMessage = [...history].reverse().find(m => m.role === 'user') as import('@/types/chat').UserMessage | undefined;
      const contextPrompts = context.prompts || [];
      const historyPrompts = lastUserMessage?.prompts || [];
      const prompts = contextPrompts.length > 0 ? contextPrompts : historyPrompts;
      
    if (prompts.length > 0) {
      try {
        const promptIds = prompts.map((promptMeta: { id: string }) => promptMeta.id);
        const { data: promptsFromDB } = await supabase
          .from('editor_prompts')
          .select('id, slug, prompt_template')
          .in('id', promptIds);

        if (promptsFromDB && promptsFromDB.length > 0) {
          const templateMap = new Map<string, string>();
          promptsFromDB.forEach((promptRow) => {
            templateMap.set(promptRow.slug, promptRow.prompt_template);
          });

          let finalContent = processedMessage ?? '';

          for (const promptMeta of prompts) {
            const pattern = `/${promptMeta.slug}`;
            if (!finalContent.includes(pattern)) {
              continue;
            }

            const template = templateMap.get(promptMeta.slug);
            if (!template || !template.trim()) {
              logger.warn('[Stream Route] ‚ö†Ô∏è Prompt template manquant', {
                promptId: promptMeta.id,
                slug: promptMeta.slug
              });
              continue;
            }

            const placeholderValues = promptMeta.placeholderValues || {};
            let resolvedTemplate = template;

            for (const [key, value] of Object.entries(placeholderValues)) {
              const safeValue = typeof value === 'string' ? value.trim() : '';
              resolvedTemplate = resolvedTemplate.split(`{${key}}`).join(safeValue);
            }

            const remainingPlaceholders = parsePromptPlaceholders(resolvedTemplate);
            if (remainingPlaceholders.length > 0) {
              logger.warn('[Stream Route] ‚ö†Ô∏è Placeholders non remplis d√©tect√©s', {
                slug: promptMeta.slug,
                missing: remainingPlaceholders.map((placeholder) => placeholder.name)
              });
            }

            finalContent = finalContent.replace(pattern, `${resolvedTemplate}\n\n`);
            logger.dev('[Stream Route] ‚úÖ Prompt remplac√©', {
              slug: promptMeta.slug,
              name: promptMeta.name,
              hasValues: Object.keys(placeholderValues).length > 0
            });
          }

          processedMessage = finalContent;

          logger.info('[Stream Route] üìù Prompts remplac√©s', {
            count: prompts.length,
            originalLength: processedMessage.length,
            finalLength: processedMessage.length
          });
        }
      } catch (promptError) {
        logger.error('[Stream Route] ‚ùå Erreur remplacement prompts:', promptError);
      }
    }
    }
    
    // ‚úÖ Construire le tableau de messages avec contextes inject√©s AVANT user message
    // Conversion type-safe via mapper
    const sanitizedHistory = history.map((msg, index) => ({
      ...msg,
      id: msg.id ?? `history-${index}`,
      content: msg.content ?? '',
      timestamp: msg.timestamp ?? new Date().toISOString()
    })) as ChatMessage[];

    const messages: ChatMessage[] = ([
      {
        role: 'system',
        content: systemMessage,
        timestamp: new Date().toISOString()
      },
      ...sanitizedHistory,
      // Injecter contexte notes √©pingl√©es (full content)
      ...(contextMessage ? [contextMessage] : []),
      // Injecter contexte mentions l√©g√®res (metadata only)
      ...(mentionsMessage ? [mentionsMessage] : []),
      // N'ajouter le message user que si pas en mode skip (avec prompts remplac√©s)
      ...(skipAddingUserMessage ? [] : [{
        role: 'user' as const,
        content: processedMessage,
        timestamp: new Date().toISOString()
      }])
    ]) as ChatMessage[];

    // ‚úÖ Charger les tools (OpenAPI + MCP) ET les endpoints
    let tools: Tool[] = [];
    let openApiEndpoints = new Map<string, OpenApiEndpoint>();
    
    if (context.agentId) {
      try {
        // 1. Charger les sch√©mas OpenAPI de l'agent
        const { data: agentSchemas } = await supabase
          .from('agent_openapi_schemas')
          .select('openapi_schema_id')
          .eq('agent_id', context.agentId);

        if (agentSchemas && agentSchemas.length > 0) {
          const { openApiSchemaService } = await import('@/services/llm/openApiSchemaService');
          
          const schemaIds = agentSchemas.map(s => s.openapi_schema_id);
          const { tools: openApiTools, endpoints } = await openApiSchemaService.getToolsAndEndpointsFromSchemas(schemaIds);
          
          // ‚úÖ Garder les endpoints pour OpenApiToolExecutor
          openApiEndpoints = endpoints;
          
          // 2. Charger les tools MCP de l'agent
          const { mcpConfigService } = await import('@/services/llm/mcpConfigService');
          // ‚úÖ Type-safe: buildHybridTools retourne Tool[] | McpServerConfig[]
          const hybridTools = await mcpConfigService.buildHybridTools(
            context.agentId,
            userToken,
            openApiTools
          );
          
          tools = hybridTools as Tool[];
          
          const mcpCount = tools.filter(isMcpTool).length;
          const openApiCount = tools.length - mcpCount;
          
          logger.dev(`[Stream Route] ‚úÖ ${tools.length} tools charg√©s (${mcpCount} MCP + ${openApiCount} OpenAPI), ${openApiEndpoints.size} endpoints`);
        }
      } catch (toolsError) {
        logger.warn('[Stream Route] ‚ö†Ô∏è Erreur chargement tools:', toolsError);
        // Continue sans tools
      }
    }

    // ‚úÖ Cr√©er le ReadableStream pour SSE avec gestion tool calls
    const stream = new ReadableStream({
      async start(controller) {
        const encoder = new TextEncoder();
        const startTime = Date.now();
        const TIMEOUT_MS = 60000; // 60s timeout
        
        // ‚úÖ V√©rifier timeout
        const checkTimeout = () => {
          if (Date.now() - startTime > TIMEOUT_MS) {
            throw new Error('Stream timeout (60s)');
          }
        };
        
        try {
          logger.dev('[Stream Route] üì° D√©marrage du stream SSE');
          
          // Helper pour envoyer un chunk SSE
          const sendSSE = (data: unknown) => {
            checkTimeout(); // V√©rifier avant chaque envoi
            const chunk = `data: ${JSON.stringify(data)}\n\n`;
            controller.enqueue(encoder.encode(chunk));
          };

          // Envoyer un chunk de d√©but
          sendSSE({
            type: 'start',
            sessionId,
            timestamp: Date.now()
          });

          // ‚úÖ Boucle agentic en streaming (max 5 tours)
          const currentMessages = [...messages];
          let roundCount = 0;
          const maxRounds = 20;
          
          // ‚úÖ AUDIT : Tracker les tool calls d√©j√† ex√©cut√©s pour d√©tecter les doublons
          const executedToolCallsSignatures = new Set<string>();
          
          // ‚úÖ S√©parer les tools MCP (ex√©cut√©s par Groq nativement) des OpenAPI (ex√©cut√©s par nous)
          const mcpTools = tools.filter(isMcpTool);
          const openApiTools = tools.filter(isFunctionTool);
          
          // ‚úÖ Cr√©er une Map des tool names OpenAPI ‚Üí pour routing d'ex√©cution
          const openApiToolNames = new Set(openApiTools.map(t => t.function.name));
          
          logger.dev(`[Stream Route] üó∫Ô∏è Tools s√©par√©s:`, {
            totalTools: tools.length,
            mcpCount: mcpTools.length,
            openApiCount: openApiTools.length,
            mcpServers: mcpTools.map(t => (t as McpTool).server_label),
            openApiNames: Array.from(openApiToolNames)
          });

          // ‚úÖ Helper: Extraire le texte d'un MessageContent (string ou array multi-modal)
          // Extrait dans helpers.ts

          while (roundCount < maxRounds) {
            roundCount++;
            logger.dev(`[Stream Route] üîÑ Round ${roundCount}/${maxRounds}`);

            // ‚úÖ AUDIT D√âTAILL√â : Logger les messages envoy√©s au LLM pour ce round
            const lastMessage = currentMessages[currentMessages.length - 1];
            const lastContent = lastMessage?.content ? extractTextFromContent(lastMessage.content) : '';
            
            logger.dev(`[Stream Route] üìã MESSAGES ENVOY√âS AU LLM - ROUND ${roundCount}:`, {
              messageCount: currentMessages.length,
              roles: currentMessages.map(m => m.role),
              hasToolCalls: currentMessages.some(m => hasToolCalls(m)),
              hasToolResults: currentMessages.some(m => m.role === 'assistant' && 'tool_results' in m && Array.isArray(m.tool_results) && m.tool_results.length > 0),
              lastMessageContent: lastContent.substring(0, 100) + (lastContent.length > 100 ? '...' : ''),
              isMultiModal: Array.isArray(lastMessage?.content)
            });
            
            // ‚úÖ AUDIT D√âTAILL√â : Logger les 5 derniers messages pour voir l'ordre
            if (roundCount > 1) {
              const last5 = currentMessages.slice(-5);
              logger.info(`[Stream Route] üîç DERNIERS 5 MESSAGES (Round ${roundCount}):`);
              last5.forEach((m, i) => {
                const toolCallId = m.role === 'tool' ? (m as { tool_call_id?: string }).tool_call_id : undefined;
                const toolCallsCount = m.role === 'assistant' && 'tool_calls' in m && Array.isArray(m.tool_calls) ? m.tool_calls.length : 0;
                logger.info(`  ${i+1}. ${m.role} - toolCalls:${toolCallsCount} - toolCallId:${toolCallId||'none'}`);
              });
            }

            // Accumuler tool calls et content du stream
            let accumulatedContent = '';
            const toolCallsMap = new Map<string, ToolCall>(); // Accumuler par ID pour g√©rer les chunks
            let finishReason: string | null = null;

            // ‚úÖ Stream depuis le provider
            for await (const chunk of provider.callWithMessagesStream(currentMessages, tools)) {
              // ‚úÖ Le chunk contient d√©j√† type: 'delta' (ajout√© par le provider)
              sendSSE(chunk);

              // Accumuler content
              if (chunk.content) {
                accumulatedContent += chunk.content;
              }
              
              // ‚úÖ Accumuler tool calls (peuvent venir en plusieurs chunks)
              if (chunk.tool_calls && chunk.tool_calls.length > 0) {
                for (const tc of chunk.tool_calls) {
                  if (!toolCallsMap.has(tc.id)) {
                    toolCallsMap.set(tc.id, {
                      id: tc.id,
                      type: 'function' as const,
                      function: {
                        name: tc.function.name || '',
                        arguments: tc.function.arguments || ''
                      }
                    });
                  } else {
                    // Accumuler les arguments progressifs
                    const existing = toolCallsMap.get(tc.id);
                    if (!existing) {
                      logger.error(`[Stream Route] ‚ö†Ô∏è Tool call ${tc.id} not found in map`, { toolCallId: tc.id });
                      continue;
                    }
                    if (tc.function.name) existing.function.name = tc.function.name;
                    if (tc.function.arguments) existing.function.arguments += tc.function.arguments;
                  }
                }
              }

              // ‚úÖ Capturer finish_reason
              if (chunk.finishReason) {
                finishReason = chunk.finishReason;
              }
            }

            // ‚úÖ AUDIT D√âTAILL√â : Logger la d√©cision de fin de round
            logger.dev(`[Stream Route] üéØ D√âCISION ROUND ${roundCount}:`, {
              finishReason,
              toolCallsCount: toolCallsMap.size,
              accumulatedContentLength: accumulatedContent.length,
              willContinue: finishReason === 'tool_calls' && toolCallsMap.size > 0
            });

            // ‚úÖ D√©cision bas√©e sur finish_reason
            if (finishReason === 'tool_calls' && toolCallsMap.size > 0) {
              logger.dev(`[Stream Route] üîß Tool calls d√©tect√©s (${toolCallsMap.size}), ex√©cution...`);
            } else if (finishReason === 'stop') {
              logger.dev('[Stream Route] ‚úÖ R√©ponse finale (stop), fin du stream');
              break;
            } else if (finishReason === 'length') {
              logger.warn('[Stream Route] ‚ö†Ô∏è Token limit atteint');
              break;
            } else {
              logger.dev('[Stream Route] ‚úÖ Pas de tool calls, fin du stream');
              break;
            }

            const accumulatedToolCalls = Array.from(toolCallsMap.values());

            // ‚úÖ D√©duplication forte : ne pas ex√©cuter deux fois le m√™me tool (nom + args)
            const uniqueToolCalls: ToolCall[] = [];
            accumulatedToolCalls.forEach((tc, index) => {
              const signature = `${tc.function.name}:${tc.function.arguments}`;
              const isDuplicate = executedToolCallsSignatures.has(signature);

              logger.info(`[Stream Route] üîß TOOL CALL ${index + 1}:`, {
                id: tc.id,
                functionName: tc.function.name,
                args: tc.function.arguments.substring(0, 100),
                isDuplicate
              });

              if (isDuplicate) {
                logger.warn(`[Stream Route] ‚ö†Ô∏è DOUBLON D√âTECT√â - SKIP ${tc.function.name}`);
                return;
              }

              executedToolCallsSignatures.add(signature);
              uniqueToolCalls.push(tc);
            });

            const dedupedCount = accumulatedToolCalls.length - uniqueToolCalls.length;

            // ‚úÖ NOUVEAU : Persister le message de ce round (outil d√©dupliqu√©)
            if (accumulatedContent || uniqueToolCalls.length > 0) {
              sendSSE({
                type: 'assistant_round_complete',
                content: accumulatedContent,
                tool_calls: uniqueToolCalls,
                finishReason: finishReason,
                timestamp: Date.now()
              });
            }

            if (dedupedCount > 0) {
              sendSSE({
                type: 'tool_dedup',
                skipped: dedupedCount,
                timestamp: Date.now()
              });
            }

            // Si tous les tool calls sont des doublons, on arr√™te pour √©viter la boucle infinie
            if (uniqueToolCalls.length === 0 && accumulatedToolCalls.length > 0) {
              logger.warn('[Stream Route] ‚ö†Ô∏è Tous les tool calls de ce round √©taient des doublons - arr√™t de l‚Äôex√©cution');
              break;
            }

            // ‚úÖ Ex√©cuter les tool calls (uniques uniquement)
            logger.dev(`[Stream Route] üîß Ex√©cution de ${uniqueToolCalls.length} tool calls (apr√®s d√©duplication)`);
            
            // Envoyer un √©v√©nement d'ex√©cution de tools
            sendSSE({
              type: 'tool_execution',
              toolCount: uniqueToolCalls.length,
              timestamp: Date.now()
            });

            // Ajouter le message assistant avec tool calls d√©dupliqu√©s
            currentMessages.push({
              role: 'assistant',
              content: accumulatedContent || '',
              tool_calls: uniqueToolCalls,
              timestamp: new Date().toISOString()
            });

            if (!userToken) {
              throw new Error('[Stream Route] Missing user token for OpenAPI tool execution');
            }

            // ‚úÖ Cr√©er l'executor OpenAPI (les tools MCP sont g√©r√©s nativement par Groq)
            const { OpenApiToolExecutor } = await import('@/services/llm/executors/OpenApiToolExecutor');
            const openApiExecutor = new OpenApiToolExecutor('', openApiEndpoints);
            
            // ‚úÖ Ex√©cuter chaque tool call
            for (const toolCall of uniqueToolCalls) {
              checkTimeout(); // V√©rifier timeout avant chaque tool
              try {
                logger.dev(`[Stream Route] üîß Ex√©cution tool: ${toolCall.function.name}`);
                
                // ‚úÖ V√©rifier si c'est un tool OpenAPI (ex√©cut√© par nous)
                // Les tools MCP sont ex√©cut√©s nativement par Groq, on ne les touche pas
                const isOpenApiTool = openApiToolNames.has(toolCall.function.name);
                
                if (!isOpenApiTool) {
                  // Tool MCP : d√©j√† ex√©cut√© par Groq, on skip
                  logger.dev(`[Stream Route] ‚è≠Ô∏è Tool MCP skip (g√©r√© par Groq): ${toolCall.function.name}`);
                  continue;
                }
                
                // ‚úÖ Ex√©cuter le tool OpenAPI
                const result = await openApiExecutor.executeToolCall(toolCall, userToken);

                // ‚úÖ AUDIT D√âTAILL√â : Logger apr√®s ex√©cution
                logger.dev(`[Stream Route] ‚úÖ APR√àS EX√âCUTION TOOL:`, {
                  toolName: toolCall.function.name,
                  success: result.success,
                  resultLength: typeof result.content === 'string' ? result.content.length : 'object',
                  resultPreview: typeof result.content === 'string' ? result.content.substring(0, 100) + '...' : 'object'
                });

                // Ajouter le r√©sultat aux messages
                currentMessages.push({
                  role: 'tool',
                  tool_call_id: toolCall.id,
                  name: toolCall.function.name,
                  content: typeof result.content === 'string' ? result.content : JSON.stringify(result.content),
                  timestamp: new Date().toISOString()
                });

                // Envoyer le r√©sultat au client
                sendSSE({
                  type: 'tool_result',
                  toolCallId: toolCall.id,
                  toolName: toolCall.function.name,
                  success: result.success,
                  result: result.content,
                  timestamp: Date.now()
                });

                logger.dev(`[Stream Route] ‚úÖ Tool ${toolCall.function.name} ex√©cut√© (success: ${result.success})`);

              } catch (toolError) {
                logger.error(`[Stream Route] ‚ùå Erreur tool ${toolCall.function.name}:`, toolError);
                
                // Ajouter un r√©sultat d'erreur
                const errorContent = `Erreur: ${toolError instanceof Error ? toolError.message : String(toolError)}`;
                
                currentMessages.push({
                  role: 'tool',
                  tool_call_id: toolCall.id,
                  name: toolCall.function.name,
                  content: errorContent,
                  timestamp: new Date().toISOString()
                });
                
                // Envoyer l'erreur au client
                sendSSE({
                  type: 'tool_result',
                  toolCallId: toolCall.id,
                  toolName: toolCall.function.name,
                  success: false,
                  result: errorContent,
                  timestamp: Date.now()
                });
              }
            }

            const hasReachedRoundLimit = roundCount >= maxRounds;

            if (hasReachedRoundLimit) {
              logger.warn(`[Stream Route] ‚ö†Ô∏è Limite de ${maxRounds} rounds atteinte, relance finale forc√©e sans nouveaux tool calls`);
              
              try {
                const finalResponse = await provider.callWithMessages(currentMessages, []);

                if (finalResponse.tool_calls && finalResponse.tool_calls.length > 0) {
                  logger.warn('[Stream Route] ‚ö†Ô∏è R√©ponse finale forc√©e contient encore des tool calls, ils seront ignor√©s', {
                    requestedToolCalls: finalResponse.tool_calls.length
                  });
                }

                if (finalResponse.content) {
                  sendSSE({
                    type: 'delta',
                    content: finalResponse.content,
                    reasoning: finalResponse.reasoning
                  });

                  sendSSE({
                    type: 'assistant_round_complete',
                    content: finalResponse.content,
                    tool_calls: [],
                    finishReason: 'stop',
                    forced: true,
                    timestamp: Date.now()
                  });

                  currentMessages.push({
                    role: 'assistant',
                    content: finalResponse.content,
                    timestamp: new Date().toISOString()
                  });
                } else {
                  logger.error('[Stream Route] ‚ùå R√©ponse finale forc√©e vide, envoi d‚Äôune erreur au client');
                  sendSSE({
                    type: 'error',
                    error: 'R√©ponse finale indisponible apr√®s la limite de tool calls'
                  });
                }
              } catch (finalError) {
                logger.error('[Stream Route] ‚ùå Erreur lors de la relance finale forc√©e', finalError);
                sendSSE({
                  type: 'error',
                  error: 'Erreur lors de la relance finale forc√©e'
                });
              }

              break;
            }

            // Continuer la boucle pour relancer le LLM avec les r√©sultats
            logger.dev(`[Stream Route] üîÑ Relance du LLM avec ${currentMessages.length} messages`);
          }

          // Envoyer un chunk de fin
          sendSSE({
            type: 'done',
            rounds: roundCount,
            timestamp: Date.now()
          });

          logger.info('[Stream Route] ‚úÖ Stream termin√© avec succ√®s');
          controller.close();

        } catch (error) {
          logger.error('[Stream Route] ‚ùå Erreur stream:', error);
          
          // Envoyer l'erreur au client
          const errorMessage = error instanceof Error ? error.message : String(error);
          const errorChunk = `data: ${JSON.stringify({ type: 'error', error: errorMessage })}\n\n`;
          controller.enqueue(encoder.encode(errorChunk));
          
          controller.close();
        }
      }
    });

    // Retourner la r√©ponse avec headers SSE
    return new Response(stream, {
      headers: {
        'Content-Type': 'text/event-stream',
        'Cache-Control': 'no-cache',
        'Connection': 'keep-alive'
      }
    });

  } catch (error) {
    logger.error('[Stream Route] ‚ùå Erreur globale:', error);
    
    return new Response(
      JSON.stringify({
        error: 'Erreur serveur',
        message: error instanceof Error ? error.message : String(error)
      }),
      {
        status: 500,
        headers: { 'Content-Type': 'application/json' }
      }
    );
  }
}

