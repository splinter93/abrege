import { useState, useCallback } from 'react';
import { simpleLogger as logger } from '@/utils/logger';

interface UseChatResponseOptions {
  onComplete?: (
    fullContent: string, 
    fullReasoning: string, 
    toolCalls?: unknown[], 
    toolResults?: unknown[]
  ) => void;
  onError?: (error: string) => void;
  onToolCalls?: (toolCalls: Array<{ id: string; name: string; arguments: Record<string, unknown> }>, toolName: string) => void;
  onToolResult?: (toolName: string, result: unknown, success: boolean, toolCallId?: string) => void;
  onToolExecutionComplete?: (toolResults: Array<{ name: string; result: unknown; success: boolean; tool_call_id: string }>) => void;
  // ‚úÖ NOUVEAU : Callbacks pour streaming
  onStreamChunk?: (content: string) => void;
  onStreamStart?: () => void;
  onStreamEnd?: () => void;
  useStreaming?: boolean; // Activer/d√©sactiver le streaming
}

interface UseChatResponseReturn {
  isProcessing: boolean;
  sendMessage: (message: string, sessionId: string, context?: Record<string, unknown>, history?: unknown[], token?: string) => Promise<void>;
  reset: () => void;
}

export function useChatResponse(options: UseChatResponseOptions = {}): UseChatResponseReturn {
  const [isProcessing, setIsProcessing] = useState(false);
  const [pendingToolCalls, setPendingToolCalls] = useState<Set<string>>(new Set());

  const { 
    onComplete, 
    onError, 
    onToolCalls, 
    onToolResult, 
    onToolExecutionComplete,
    onStreamChunk,
    onStreamStart,
    onStreamEnd,
    useStreaming = false // ‚úÖ D√©sactiv√© par d√©faut pour compatibilit√©
  } = options;

  const sendMessage = useCallback(async (message: string, sessionId: string, context?: Record<string, unknown>, history?: unknown[], token?: string) => {
    try {
      logger.dev('[useChatResponse] üéØ sendMessage appel√©:', {
        message: message.substring(0, 50) + '...',
        sessionId,
        hasContext: !!context,
        historyLength: history?.length || 0,
        hasToken: !!token,
        useStreaming
      });

      setIsProcessing(true);

      const headers: Record<string, string> = { 'Content-Type': 'application/json' };
      
      // Ajouter le token d'authentification si fourni
      if (token) {
        headers['Authorization'] = `Bearer ${token}`;
      }
      
      // ‚úÖ NOUVEAU : Router vers l'endpoint streaming si activ√©
      if (useStreaming) {
        logger.dev('[useChatResponse] üåä Mode streaming activ√©');
        onStreamStart?.();
        
        const response = await fetch('/api/chat/llm/stream', {
          method: 'POST',
          headers,
          body: JSON.stringify({
            message,
            context: context || { sessionId }, 
            history: history || [],
            sessionId
          })
        });

        if (!response.ok) {
          const errorText = await response.text();
          throw new Error(`HTTP ${response.status}: ${errorText}`);
        }

        if (!response.body) {
          throw new Error('Response body is null');
        }

        // Consommer le stream SSE
        const reader = response.body.getReader();
        const decoder = new TextDecoder();
        let buffer = '';
        let fullContent = '';
        let fullReasoning = '';
        const accumulatedToolCalls: unknown[] = [];

        while (true) {
          const { done, value } = await reader.read();
          
          if (done) {
            logger.dev('[useChatResponse] ‚úÖ Stream termin√©');
            break;
          }

          // D√©coder le chunk
          buffer += decoder.decode(value, { stream: true });
          const lines = buffer.split('\n');
          buffer = lines.pop() || '';

          for (const line of lines) {
            const trimmed = line.trim();
            
            if (!trimmed || !trimmed.startsWith('data: ')) {
              continue;
            }

            const data = trimmed.slice(6);
            
            try {
              const chunk = JSON.parse(data);
              
              // G√©rer les diff√©rents types de chunks
              if (chunk.type === 'start') {
                logger.dev('[useChatResponse] üöÄ Stream d√©marr√©');
                continue;
              }

              if (chunk.type === 'delta') {
                // Content progressif
                if (chunk.content) {
                  fullContent += chunk.content;
                  onStreamChunk?.(chunk.content);
                }

                // Reasoning
                if (chunk.reasoning) {
                  fullReasoning += chunk.reasoning;
                }

                // Tool calls
                if (chunk.tool_calls) {
                  accumulatedToolCalls.push(...chunk.tool_calls);
                  onToolCalls?.(chunk.tool_calls, 'stream');
                }
              }

              if (chunk.type === 'done') {
                logger.dev('[useChatResponse] üèÅ Stream [DONE]');
                onStreamEnd?.();
                onComplete?.(fullContent, fullReasoning, accumulatedToolCalls, []);
              }

              if (chunk.type === 'error') {
                throw new Error(chunk.error || 'Erreur stream');
              }

            } catch (parseError) {
              logger.warn('[useChatResponse] ‚ö†Ô∏è Erreur parsing chunk:', parseError);
              continue;
            }
          }
        }

        return;
      }
      
      // ‚úÖ MODE CLASSIQUE (sans streaming)
      logger.dev('[useChatResponse] üöÄ Envoi de la requ√™te √† l\'API LLM (mode classique)');
      
      const response = await fetch('/api/chat/llm', {
        method: 'POST',
        headers,
        body: JSON.stringify({
          message,
          context: context || { sessionId }, 
          history: history || [],
          sessionId
        })
      });

      logger.dev('[useChatResponse] ‚úÖ Fetch termin√©, traitement de la r√©ponse...');

      logger.dev('[useChatResponse] üì• R√©ponse HTTP re√ßue:', {
        status: response.status,
        ok: response.ok,
        statusText: response.statusText,
        headers: Object.fromEntries(response.headers.entries())
      });

      if (!response.ok) {
        const errorText = await response.text();
        let errorData;
        try {
          errorData = JSON.parse(errorText);
        } catch {
          errorData = { error: `HTTP ${response.status}: ${response.statusText}` };
        }
        
        logger.dev('[useChatResponse] ‚ùå R√©ponse HTTP non-OK:', {
          status: response.status,
          statusText: response.statusText,
          errorText: errorText.substring(0, 500),
          errorData: errorData
        });
        
        throw new Error(errorData.error || `HTTP ${response.status}: ${response.statusText}`);
      }

      logger.dev('[useChatResponse] üîÑ D√©but du parsing JSON...');
      
      let data;
      try {
        data = await response.json();
        logger.dev('[useChatResponse] ‚úÖ JSON pars√© avec succ√®s');
        logger.dev('[useChatResponse] üîç R√©ponse brute re√ßue:', {
          status: response.status,
          ok: response.ok,
          data: data,
          dataType: typeof data,
          hasSuccess: 'success' in data,
          success: data?.success,
          hasContent: 'content' in data,
          content: data?.content?.substring(0, 100) + '...',
          contentLength: data?.content?.length || 0
        });
      } catch (parseError) {
        logger.dev('[useChatResponse] ‚ùå Erreur parsing JSON:', {
          error: parseError instanceof Error ? parseError.message : String(parseError)
        });
        const textResponse = await response.text();
        logger.dev('[useChatResponse] ‚ùå R√©ponse texte brute:', {
          response: textResponse.substring(0, 500)
        });
        throw new Error('Erreur parsing JSON de la r√©ponse');
      }

      // üîß AM√âLIORATION: Validation de base de la r√©ponse
      if (!data) {
        throw new Error('R√©ponse vide du serveur');
      }

      // ‚úÖ NOUVELLE LOGIQUE CLAIRE ET ROBUSTE
      if (data.success) {
        logger.dev('[useChatResponse] üîç Structure de la r√©ponse:', {
          success: data.success,
          is_relance: data.is_relance,
          tool_calls_length: data.tool_calls?.length || 0,
          tool_results_length: data.tool_results?.length || 0,
          content_length: data.content?.length || 0
        });

        // üéØ PRIORIT√â 1 : R√©ponse finale (is_relance = true)
        // Le LLM a termin√© son traitement apr√®s avoir utilis√© des tools
        if (data.is_relance) {
          logger.dev('[useChatResponse] ‚úÖ R√©ponse finale apr√®s tool calls re√ßue');
          logger.tool('[useChatResponse] ‚úÖ R√©ponse finale re√ßue');
          
          // Traiter les tool results si pr√©sents
          if (data.tool_results && data.tool_results.length > 0) {
            for (const toolResult of data.tool_results) {
              onToolResult?.(
                toolResult.name,
                toolResult.result,
                toolResult.success,
                toolResult.tool_call_id
              );
            }
          }
          
          // Informer si des tools ont √©chou√©
          if (data.has_failed_tools) {
            logger.dev('[useChatResponse] ‚ö†Ô∏è Des tools ont √©chou√© mais le LLM a g√©r√© intelligemment');
          }
          
          // ‚úÖ Toujours appeler onComplete pour une r√©ponse finale
          logger.dev('[useChatResponse] üéØ Appel onComplete (r√©ponse finale)');
          
          onComplete?.(
            data.content || '', 
            data.reasoning || '', 
            data.tool_calls || [], 
            data.tool_results || []
          );
          return;
        }
        
        // üéØ PRIORIT√â 2 : Tool calls en cours (is_relance = false)
        if (data.tool_calls && data.tool_calls.length > 0) {
          const toolCallIds = data.tool_calls.map((tc: { id: string }) => tc.id);
          setPendingToolCalls(new Set(toolCallIds));
          
          if (data.tool_calls.length > 10) {
            logger.tool(`[useChatResponse] ‚ö° ${data.tool_calls.length} tool calls d√©tect√©s`);
          } else {
            logger.tool(`[useChatResponse] üîß ${data.tool_calls.length} tool call(s) d√©tect√©(s)`);
          }
          
          onToolCalls?.(data.tool_calls, 'tool_chain');
          
          // Traiter les tool results s'ils sont d√©j√† disponibles
          if (data.tool_results && data.tool_results.length > 0) {
            for (const toolResult of data.tool_results) {
              onToolResult?.(
                toolResult.name,
                toolResult.result,
                toolResult.success,
                toolResult.tool_call_id
              );
              
              // Marquer ce tool call comme termin√©
              setPendingToolCalls(prev => {
                const newSet = new Set(prev);
                newSet.delete(toolResult.tool_call_id);
                return newSet;
              });
            }

            // Logger la progression
            const completedCount = data.tool_results.length;
            const totalCount = data.tool_calls.length;
            
            if (completedCount === totalCount) {
              logger.dev(`[useChatResponse] ‚úÖ Tous les ${totalCount} tool calls termin√©s`);
              onToolExecutionComplete?.(data.tool_results);
            } else {
              logger.dev(`[useChatResponse] ‚è≥ ${completedCount}/${totalCount} tool calls termin√©s`);
            }
          }
          
          // ‚ùå NE PAS appeler onComplete ici - attendre la r√©ponse finale
          return;
        }
        
        // üéØ PRIORIT√â 3 : R√©ponse simple sans tool calls
        logger.dev('[useChatResponse] ‚úÖ R√©ponse simple sans tool calls');
        logger.dev('[useChatResponse] üéØ Appel onComplete (r√©ponse simple)');
        
        onComplete?.(
          data.content || '', 
          data.reasoning || '', 
          [], 
          []
        );
        return;
      } else {
        // üîß AM√âLIORATION: Gestion des erreurs serveur
        if (data.error) {
          const errorMessage = data.error || data.details || 'Erreur inconnue du serveur';
          logger.warn('[useChatResponse] ‚ö†Ô∏è R√©ponse d\'erreur du serveur:', { error: errorMessage, data });
          throw new Error(errorMessage);
        } else {
          // Fallback pour les r√©ponses invalides
          logger.warn('[useChatResponse] ‚ö†Ô∏è R√©ponse invalide du serveur:', data);
          throw new Error('Format de r√©ponse invalide');
        }
      }
    } catch (error) {
      // Gestion d'erreur
      let errorMessage: string;
      
      if (error instanceof Error) {
        errorMessage = error.message;
        logger.dev('[useChatResponse] ‚ùå Erreur:', {
          message: error.message,
          stack: error.stack
        });
      } else if (typeof error === 'string') {
        errorMessage = error;
        logger.dev('[useChatResponse] ‚ùå Erreur:', { error });
      } else {
        errorMessage = 'Erreur inconnue';
        logger.dev('[useChatResponse] ‚ùå Erreur:', { error: String(error) });
      }
      
      // Appeler le callback d'erreur si disponible
      onError?.(errorMessage);
    } finally {
      setIsProcessing(false);
    }
  }, [onComplete, onError, onToolCalls, onToolResult, onToolExecutionComplete, onStreamChunk, onStreamStart, onStreamEnd, useStreaming]);

  const reset = useCallback(() => {
    setIsProcessing(false);
    setPendingToolCalls(new Set());
  }, []);

  return {
    isProcessing,
    sendMessage,
    reset
  };
} 