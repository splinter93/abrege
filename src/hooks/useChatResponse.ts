import { useState, useCallback } from 'react';
import { simpleLogger as logger } from '@/utils/logger';
import { StreamTimeline, StreamTimelineItem } from '@/types/streamTimeline';
import type { ToolCall, ToolResult } from '@/hooks/useChatHandlers';
import type { ChatMessage } from '@/types/chat';
import type { MessageContent } from '@/types/image';

interface UseChatResponseOptions {
  onComplete?: (
    fullContent: string, 
    fullReasoning: string, 
    toolCalls?: ToolCall[], 
    toolResults?: ToolResult[],
    streamTimeline?: StreamTimeline // âœ… NOUVEAU: Timeline capturÃ©e du stream
  ) => void;
  onError?: (error: string) => void;
  onToolCalls?: (toolCalls: Array<{ id: string; name: string; arguments: Record<string, unknown> }>, toolName: string) => void;
  onToolResult?: (toolName: string, result: unknown, success: boolean, toolCallId?: string) => void;
  onToolExecutionComplete?: (toolResults: Array<{ name: string; result: unknown; success: boolean; tool_call_id: string }>) => void;
  // âœ… NOUVEAU : Callbacks pour streaming
  onStreamChunk?: (content: string) => void;
  onStreamStart?: () => void;
  onStreamEnd?: () => void;
  onToolExecution?: (toolCount: number, toolCalls: Array<{ id: string; type: string; function: { name: string; arguments: string } }>) => void; // âœ… Quand les tools commencent Ã  s'exÃ©cuter
  useStreaming?: boolean; // Activer/dÃ©sactiver le streaming
  onAssistantRoundComplete?: (content: string, toolCalls: ToolCall[]) => void; // âœ… NOUVEAU
}

interface UseChatResponseReturn {
  isProcessing: boolean;
  sendMessage: (message: string | MessageContent, sessionId: string, context?: Record<string, unknown>, history?: ChatMessage[], token?: string) => Promise<void>;
  reset: () => void;
}

export function useChatResponse(options: UseChatResponseOptions = {}): UseChatResponseReturn {
  const [isProcessing, setIsProcessing] = useState(false);
  const [pendingToolCalls, setPendingToolCalls] = useState<Set<string>>(new Set());

  const { 
    onComplete, 
    onError, 
    onToolCalls, 
    onToolResult, 
    onToolExecutionComplete,
    onStreamChunk,
    onStreamStart,
    onStreamEnd,
    onToolExecution,
    useStreaming = false, // âœ… DÃ©sactivÃ© par dÃ©faut pour compatibilitÃ©
    onAssistantRoundComplete, // âœ… NOUVEAU: Pour persister chaque round
  } = options;

  const sendMessage = useCallback(async (message: string | MessageContent, sessionId: string, context?: Record<string, unknown>, history?: ChatMessage[], token?: string) => {
    try {
      // Extraire un aperÃ§u du message pour le logging
      const messagePreview = typeof message === 'string' 
        ? message.substring(0, 50) + '...'
        : `[Multi-modal: ${message.length} parts]`;
      
      logger.dev('[useChatResponse] ðŸŽ¯ sendMessage appelÃ©:', {
        message: messagePreview,
        isMultiModal: typeof message !== 'string',
        sessionId,
        hasContext: !!context,
        historyLength: history?.length || 0,
        hasToken: !!token,
        useStreaming
      });

      setIsProcessing(true);

      const headers: Record<string, string> = { 'Content-Type': 'application/json' };
      
      // Ajouter le token d'authentification si fourni
      if (token) {
        headers['Authorization'] = `Bearer ${token}`;
      }
      
      // âœ… NOUVEAU : Router vers l'endpoint streaming si activÃ©
      if (useStreaming) {
        logger.dev('[useChatResponse] ðŸŒŠ Mode streaming activÃ©');
        onStreamStart?.();
        
        const response = await fetch('/api/chat/llm/stream', {
          method: 'POST',
          headers,
          body: JSON.stringify({
            message,
            context: context || { sessionId }, 
            history: history || [],
            sessionId,
            // âœ… Passer skipAddingUserMessage si prÃ©sent dans le contexte
            skipAddingUserMessage: context?.skipAddingUserMessage || false
          })
        });

        if (!response.ok) {
          const errorText = await response.text();
          throw new Error(`HTTP ${response.status}: ${errorText}`);
        }

        if (!response.body) {
          throw new Error('Response body is null');
        }

        // Consommer le stream SSE
        const reader = response.body.getReader();
        const decoder = new TextDecoder();
        let buffer = '';
        let currentRoundContent = ''; // âœ… Content du round actuel seulement
        let currentRoundReasoning = ''; // âœ… Reasoning du round actuel
        let currentRoundToolCalls = new Map<string, ToolCall>(); // âœ… Map pour le round actuel
        const allNotifiedToolCallIds = new Set<string>(); // âœ… Track pour Ã©viter re-notifications
        const executionNotifiedToolCallIds = new Set<string>(); // âœ… Track des tool calls dÃ©jÃ  notifiÃ©s pour exÃ©cution
        
        // âœ… NOUVEAU: Collections globales pour tous les tool calls/results du cycle complet
        const allToolCalls = new Map<string, ToolCall>(); // Tous les tool calls de tous les rounds
        const allToolResults: Array<{
          tool_call_id: string;
          name: string;
          content: string;
          success: boolean;
        }> = []; // Tous les tool results
        
        // âœ… NOUVEAU : Accumulateur global pour TOUT le contenu
        let allContent = '';
        
        // âœ… CORRECTION : Pour Ã©viter les hallucinations, on va rÃ©initialiser allContent
        // aprÃ¨s chaque tool execution pour ne garder QUE le contenu post-tool
        
        // âœ… NOUVEAU: Timeline pour capturer l'ordre exact des Ã©vÃ©nements
        const streamTimeline: StreamTimelineItem[] = [];
        const streamStartTime = Date.now();
        let currentRoundNumber = 0;

        while (true) {
          const { done, value } = await reader.read();
          
          if (done) {
            logger.dev('[useChatResponse] âœ… Stream terminÃ©');
            break;
          }

          // DÃ©coder le chunk
          buffer += decoder.decode(value, { stream: true });
          const lines = buffer.split('\n');
          buffer = lines.pop() || '';

          for (const line of lines) {
            const trimmed = line.trim();
            
            if (!trimmed || !trimmed.startsWith('data: ')) {
              continue;
            }

            const data = trimmed.slice(6);
            
            try {
              const chunk = JSON.parse(data);
              
              // GÃ©rer les diffÃ©rents types de chunks
              if (chunk.type === 'start') {
                logger.dev('[useChatResponse] ðŸš€ Stream dÃ©marrÃ©');
                continue;
              }

              if (chunk.type === 'delta') {
                  // Content progressif du round actuel
                  if (chunk.content) {
                    // âœ… Si on reÃ§oit du content juste aprÃ¨s tool_execution, c'est un nouveau round
                    // On doit REMPLACER le content au lieu d'accumuler
                    if (chunk.content && currentRoundToolCalls.size === 0) {
                      // Probablement un nouveau round aprÃ¨s exÃ©cution tools
                      // Mais on garde l'accumulation pour le streaming normal
                    }
                    
                    currentRoundContent += chunk.content;
                    // âœ… NOUVEAU : Accumuler TOUT le contenu globalement
                    allContent += chunk.content;
                  onStreamChunk?.(chunk.content);
                  
                  // âœ… NOUVEAU: Ajouter/mettre Ã  jour l'Ã©vÃ©nement text dans la timeline
                  // On fusionne les chunks delta en un seul Ã©vÃ©nement text par round
                  const lastEvent = streamTimeline[streamTimeline.length - 1];
                  if (lastEvent && lastEvent.type === 'text' && lastEvent.roundNumber === currentRoundNumber) {
                    // Fusionner avec l'Ã©vÃ©nement text existant du mÃªme round
                    lastEvent.content += chunk.content;
                  } else {
                    // CrÃ©er un nouvel Ã©vÃ©nement text
                    streamTimeline.push({
                      type: 'text',
                      content: chunk.content,
                      timestamp: Date.now() - streamStartTime,
                      roundNumber: currentRoundNumber
                    });
                  }
                }

                // Reasoning du round actuel
                if (chunk.reasoning) {
                  currentRoundReasoning += chunk.reasoning;
                }

                // âœ… Tool calls avec dÃ©duplication par ID
                if (chunk.tool_calls && Array.isArray(chunk.tool_calls)) {
                  for (const tc of chunk.tool_calls) {
                    if (!currentRoundToolCalls.has(tc.id)) {
                      // Nouveau tool call
                      const toolCall = {
                        id: tc.id,
                        type: tc.type || 'function',
                        function: {
                          name: tc.function?.name || '',
                          arguments: tc.function?.arguments || ''
                        }
                      };
                      currentRoundToolCalls.set(tc.id, toolCall);
                      allToolCalls.set(tc.id, toolCall); // âœ… NOUVEAU: Ajouter au Map global
                    } else {
                      // Accumuler arguments progressifs (streaming)
                      const existing = currentRoundToolCalls.get(tc.id);
                      if (tc.function?.name) existing.function.name = tc.function.name;
                      if (tc.function?.arguments) existing.function.arguments += tc.function.arguments;
                      
                      // âœ… NOUVEAU: Mettre Ã  jour aussi dans le Map global
                      const globalExisting = allToolCalls.get(tc.id);
                      if (globalExisting) {
                        if (tc.function?.name) globalExisting.function.name = tc.function.name;
                        if (tc.function?.arguments) globalExisting.function.arguments += tc.function.arguments;
                      }
                    }
                  }
                }
              }
              
              // âœ… GÃ©rer tool_execution : notifier et rÃ©initialiser pour le prochain round
              if (chunk.type === 'tool_execution') {
                logger.dev(`[useChatResponse] ðŸ”§ ExÃ©cution de ${chunk.toolCount || 0} tools...`);
                
                // âœ… CORRIGÃ‰: Utiliser allToolCalls au lieu de currentRoundToolCalls
                // car les tool_calls arrivent peut-Ãªtre dans des chunks aprÃ¨s tool_execution
                const toolCallsToNotify = Array.from(allToolCalls.values()).filter(
                  tc => !allNotifiedToolCallIds.has(tc.id)
                );
                
                if (toolCallsToNotify.length > 0) {
                  onToolCalls?.(toolCallsToNotify, 'stream');
                  // Marquer comme notifiÃ©s
                  toolCallsToNotify.forEach(tc => allNotifiedToolCallIds.add(tc.id));
                }
                
                // âœ… CORRIGÃ‰ : Prendre les nouveaux tool calls depuis allToolCalls
                // On filtre ceux qui n'ont pas encore Ã©tÃ© notifiÃ©s pour exÃ©cution
                const newToolCallsForExecution = Array.from(allToolCalls.values())
                  .filter(tc => !executionNotifiedToolCallIds.has(tc.id));
                
                const toolCallsSnapshot = newToolCallsForExecution.map(tc => ({
                  id: tc.id,
                  type: tc.type,
                  function: {
                    name: tc.function.name,
                    arguments: tc.function.arguments
                  }
                }));
                
                // âœ… Marquer ces tool calls comme notifiÃ©s pour exÃ©cution
                newToolCallsForExecution.forEach(tc => executionNotifiedToolCallIds.add(tc.id));
                
                // âœ… Notifier dÃ©but d'exÃ©cution avec les tool calls
                onToolExecution?.(chunk.toolCount || 0, toolCallsSnapshot);
                
                logger.dev(`[useChatResponse] ðŸ“‹ Tool execution capturÃ© pour timeline:`, {
                  toolCount: toolCallsSnapshot.length,
                  toolNames: toolCallsSnapshot.map(tc => tc.function.name),
                  allToolCallsSize: allToolCalls.size,
                  newToolCallsCount: newToolCallsForExecution.length,
                  executionNotifiedCount: executionNotifiedToolCallIds.size
                });
                
                streamTimeline.push({
                  type: 'tool_execution',
                  toolCalls: toolCallsSnapshot,
                  toolCount: chunk.toolCount || toolCallsSnapshot.length,
                  timestamp: Date.now() - streamStartTime,
                  roundNumber: currentRoundNumber
                });
                
                // Passer au prochain round
                currentRoundNumber++;
                
                // âœ… NE PAS rÃ©initialiser ici - le prochain delta va Ã©craser
                currentRoundToolCalls.clear();
              }
              
              if (chunk.type === 'tool_result') {
                logger.dev(`[useChatResponse] âœ… Tool result: ${chunk.toolName}`);
                
                // âœ… NOUVEAU: Collecter le tool result
                const toolResult = {
                  tool_call_id: chunk.toolCallId || `call_${Date.now()}`,
                  name: chunk.toolName || 'unknown_tool',
                  content: typeof chunk.result === 'string' ? chunk.result : JSON.stringify(chunk.result || {}),
                  success: chunk.success || false
                };
                allToolResults.push(toolResult);
                
                // âœ… NOUVEAU: Ajouter l'Ã©vÃ©nement tool_result Ã  la timeline
                streamTimeline.push({
                  type: 'tool_result',
                  toolCallId: chunk.toolCallId || `call_${Date.now()}`,
                  toolName: chunk.toolName || 'unknown_tool',
                  result: chunk.result,
                  success: chunk.success || false,
                  timestamp: Date.now() - streamStartTime
                });
                
                onToolResult?.(chunk.toolName || '', chunk, chunk.success || false, chunk.toolCallId);
              }

              // âœ… NOUVEAU: GÃ©rer la fin d'un round assistant
              if (chunk.type === 'assistant_round_complete') {
                logger.dev(`[useChatResponse] ðŸ”µ Round terminÃ©: ${chunk.finishReason}`);
                if (onAssistantRoundComplete && (chunk.content || (chunk.tool_calls && chunk.tool_calls.length > 0))) {
                  onAssistantRoundComplete(chunk.content || '', chunk.tool_calls || []);
                }
                // RÃ©initialiser le contenu pour le prochain round potentiel
                currentRoundContent = '';
                currentRoundToolCalls.clear();
              }

              if (chunk.type === 'done') {
                logger.dev('[useChatResponse] ðŸ Stream [DONE]', {
                  contentLength: currentRoundContent.length,
                  toolCallsCount: allToolCalls.size,
                  toolResultsCount: allToolResults.length,
                  timelineEvents: streamTimeline.length
                });
                onStreamEnd?.();
                // âœ… CORRIGÃ‰: Passer TOUS les tool calls, results ET la timeline
                const finalTimeline: StreamTimeline = {
                  items: streamTimeline,
                  startTime: streamStartTime,
                  endTime: Date.now()
                };
                onComplete?.(
                  allContent, // âœ… CORRIGÃ‰: Utiliser TOUT le contenu au lieu du round actuel
                  currentRoundReasoning, 
                  Array.from(allToolCalls.values()), // Tous les tool calls du cycle
                  allToolResults, // Tous les rÃ©sultats collectÃ©s
                  finalTimeline // âœ… NOUVEAU: Timeline complÃ¨te
                );
              }

              if (chunk.type === 'error') {
                throw new Error(chunk.error || 'Erreur stream');
              }

            } catch (parseError) {
              logger.warn('[useChatResponse] âš ï¸ Erreur parsing chunk:', parseError);
              continue;
            }
          }
        }

        return;
      }
      
      // âœ… MODE CLASSIQUE (sans streaming)
      logger.dev('[useChatResponse] ðŸš€ Envoi de la requÃªte Ã  l\'API LLM (mode classique)');
      
      const response = await fetch('/api/chat/llm', {
        method: 'POST',
        headers,
        body: JSON.stringify({
          message,
          context: context || { sessionId }, 
          history: history || [],
          sessionId
        })
      });

      logger.dev('[useChatResponse] âœ… Fetch terminÃ©, traitement de la rÃ©ponse...');

      logger.dev('[useChatResponse] ðŸ“¥ RÃ©ponse HTTP reÃ§ue:', {
        status: response.status,
        ok: response.ok,
        statusText: response.statusText,
        headers: Object.fromEntries(response.headers.entries())
      });

      if (!response.ok) {
        const errorText = await response.text();
        let errorData;
        try {
          errorData = JSON.parse(errorText);
        } catch {
          errorData = { error: `HTTP ${response.status}: ${response.statusText}` };
        }
        
        logger.dev('[useChatResponse] âŒ RÃ©ponse HTTP non-OK:', {
          status: response.status,
          statusText: response.statusText,
          errorText: errorText.substring(0, 500),
          errorData: errorData
        });
        
        throw new Error(errorData.error || `HTTP ${response.status}: ${response.statusText}`);
      }

      logger.dev('[useChatResponse] ðŸ”„ DÃ©but du parsing JSON...');
      
      let data;
      try {
        data = await response.json();
        logger.dev('[useChatResponse] âœ… JSON parsÃ© avec succÃ¨s');
        logger.dev('[useChatResponse] ðŸ” RÃ©ponse brute reÃ§ue:', {
          status: response.status,
          ok: response.ok,
          data: data,
          dataType: typeof data,
          hasSuccess: 'success' in data,
          success: data?.success,
          hasContent: 'content' in data,
          content: data?.content?.substring(0, 100) + '...',
          contentLength: data?.content?.length || 0
        });
      } catch (parseError) {
        logger.dev('[useChatResponse] âŒ Erreur parsing JSON:', {
          error: parseError instanceof Error ? parseError.message : String(parseError)
        });
        const textResponse = await response.text();
        logger.dev('[useChatResponse] âŒ RÃ©ponse texte brute:', {
          response: textResponse.substring(0, 500)
        });
        throw new Error('Erreur parsing JSON de la rÃ©ponse');
      }

      // ðŸ”§ AMÃ‰LIORATION: Validation de base de la rÃ©ponse
      if (!data) {
        throw new Error('RÃ©ponse vide du serveur');
      }

      // âœ… NOUVELLE LOGIQUE CLAIRE ET ROBUSTE
      if (data.success) {
        logger.dev('[useChatResponse] ðŸ” Structure de la rÃ©ponse:', {
          success: data.success,
          is_relance: data.is_relance,
          tool_calls_length: data.tool_calls?.length || 0,
          tool_results_length: data.tool_results?.length || 0,
          content_length: data.content?.length || 0
        });

        // ðŸŽ¯ PRIORITÃ‰ 1 : RÃ©ponse finale (is_relance = true)
        // Le LLM a terminÃ© son traitement aprÃ¨s avoir utilisÃ© des tools
        if (data.is_relance) {
          logger.dev('[useChatResponse] âœ… RÃ©ponse finale aprÃ¨s tool calls reÃ§ue');
          logger.tool('[useChatResponse] âœ… RÃ©ponse finale reÃ§ue');
          
          // Traiter les tool results si prÃ©sents
          if (data.tool_results && data.tool_results.length > 0) {
            for (const toolResult of data.tool_results) {
              onToolResult?.(
                toolResult.name,
                toolResult.result,
                toolResult.success,
                toolResult.tool_call_id
              );
            }
          }
          
          // Informer si des tools ont Ã©chouÃ©
          if (data.has_failed_tools) {
            logger.dev('[useChatResponse] âš ï¸ Des tools ont Ã©chouÃ© mais le LLM a gÃ©rÃ© intelligemment');
          }
          
          // âœ… Toujours appeler onComplete pour une rÃ©ponse finale
          logger.dev('[useChatResponse] ðŸŽ¯ Appel onComplete (rÃ©ponse finale)');
          
          onComplete?.(
            data.content || '', 
            data.reasoning || '', 
            data.tool_calls || [], 
            data.tool_results || [],
            undefined // Pas de timeline en mode classique (non-streaming)
          );
          return;
        }
        
        // ðŸŽ¯ PRIORITÃ‰ 2 : Tool calls en cours (is_relance = false)
        if (data.tool_calls && data.tool_calls.length > 0) {
          const toolCallIds = data.tool_calls.map((tc: { id: string }) => tc.id);
          setPendingToolCalls(new Set(toolCallIds));
          
          if (data.tool_calls.length > 10) {
            logger.tool(`[useChatResponse] âš¡ ${data.tool_calls.length} tool calls dÃ©tectÃ©s`);
          } else {
            logger.tool(`[useChatResponse] ðŸ”§ ${data.tool_calls.length} tool call(s) dÃ©tectÃ©(s)`);
          }
          
          onToolCalls?.(data.tool_calls, 'tool_chain');
          
          // Traiter les tool results s'ils sont dÃ©jÃ  disponibles
          if (data.tool_results && data.tool_results.length > 0) {
            for (const toolResult of data.tool_results) {
              onToolResult?.(
                toolResult.name,
                toolResult.result,
                toolResult.success,
                toolResult.tool_call_id
              );
              
              // Marquer ce tool call comme terminÃ©
              setPendingToolCalls(prev => {
                const newSet = new Set(prev);
                newSet.delete(toolResult.tool_call_id);
                return newSet;
              });
            }

            // Logger la progression
            const completedCount = data.tool_results.length;
            const totalCount = data.tool_calls.length;
            
            if (completedCount === totalCount) {
              logger.dev(`[useChatResponse] âœ… Tous les ${totalCount} tool calls terminÃ©s`);
              onToolExecutionComplete?.(data.tool_results);
            } else {
              logger.dev(`[useChatResponse] â³ ${completedCount}/${totalCount} tool calls terminÃ©s`);
            }
          }
          
          // âŒ NE PAS appeler onComplete ici - attendre la rÃ©ponse finale
          return;
        }
        
        // ðŸŽ¯ PRIORITÃ‰ 3 : RÃ©ponse simple sans tool calls
        logger.dev('[useChatResponse] âœ… RÃ©ponse simple sans tool calls');
        logger.dev('[useChatResponse] ðŸŽ¯ Appel onComplete (rÃ©ponse simple)');
        
        onComplete?.(
          data.content || '', 
          data.reasoning || '', 
          [], 
          []
        );
        return;
      } else {
        // ðŸ”§ AMÃ‰LIORATION: Gestion des erreurs serveur
        if (data.error) {
          const errorMessage = data.error || data.details || 'Erreur inconnue du serveur';
          logger.warn('[useChatResponse] âš ï¸ RÃ©ponse d\'erreur du serveur:', { error: errorMessage, data });
          throw new Error(errorMessage);
        } else {
          // Fallback pour les rÃ©ponses invalides
          logger.warn('[useChatResponse] âš ï¸ RÃ©ponse invalide du serveur:', data);
          throw new Error('Format de rÃ©ponse invalide');
        }
      }
    } catch (error) {
      // Gestion d'erreur
      let errorMessage: string;
      
      if (error instanceof Error) {
        errorMessage = error.message;
        logger.dev('[useChatResponse] âŒ Erreur:', {
          message: error.message,
          stack: error.stack
        });
      } else if (typeof error === 'string') {
        errorMessage = error;
        logger.dev('[useChatResponse] âŒ Erreur:', { error });
      } else {
        errorMessage = 'Erreur inconnue';
        logger.dev('[useChatResponse] âŒ Erreur:', { error: String(error) });
      }
      
      // Appeler le callback d'erreur si disponible
      onError?.(errorMessage);
    } finally {
      setIsProcessing(false);
    }
  }, [onComplete, onError, onToolCalls, onToolResult, onToolExecutionComplete, onStreamChunk, onStreamStart, onStreamEnd, onToolExecution, useStreaming, onAssistantRoundComplete]);

  const reset = useCallback(() => {
    setIsProcessing(false);
    setPendingToolCalls(new Set());
  }, []);

  return {
    isProcessing,
    sendMessage,
    reset
  };
} 