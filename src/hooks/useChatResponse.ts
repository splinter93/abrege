import { useState, useCallback } from 'react';
import { simpleLogger as logger } from '@/utils/logger';

interface UseChatResponseOptions {
  onComplete?: (fullContent: string, fullReasoning: string) => void;
  onError?: (error: string) => void;
  onToolCalls?: (toolCalls: any[], toolName: string) => void;
  onToolResult?: (toolName: string, result: any, success: boolean, toolCallId?: string) => void;
  onToolExecutionComplete?: (toolResults: any[]) => void;
}

interface UseChatResponseReturn {
  isProcessing: boolean;
  sendMessage: (message: string, sessionId: string, context?: any, history?: any[], token?: string) => Promise<void>;
  reset: () => void;
}

export function useChatResponse(options: UseChatResponseOptions = {}): UseChatResponseReturn {
  const [isProcessing, setIsProcessing] = useState(false);
  const [pendingToolCalls, setPendingToolCalls] = useState<Set<string>>(new Set());

  const { onComplete, onError, onToolCalls, onToolResult, onToolExecutionComplete } = options;

  const sendMessage = useCallback(async (message: string, sessionId: string, context?: any, history?: any[], token?: string) => {
    try {
      setIsProcessing(true);

      const headers: Record<string, string> = { 'Content-Type': 'application/json' };
      
      // Ajouter le token d'authentification si fourni
      if (token) {
        headers['Authorization'] = `Bearer ${token}`;
      }
      
      const response = await fetch('/api/chat/llm', {
        method: 'POST',
        headers,
        body: JSON.stringify({
          message,
          context: context || { sessionId }, 
          history: history || [],
          sessionId
        })
      });

      if (!response.ok) {
        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
      }

      const data = await response.json();

      if (data.success) {
        // ðŸŽ¯ GÃ©rer le cas des nouveaux tool calls (continuation du cycle)
        if (data.has_new_tool_calls && data.tool_calls && data.tool_calls.length > 0) {
          logger.dev('[useChatResponse] ðŸ”„ Nouveaux tool calls dÃ©tectÃ©s, continuation du cycle');
          logger.tool('[useChatResponse] ðŸ”„ Nouveaux tool calls dÃ©tectÃ©s, continuation du cycle');
          
          // Traiter les nouveaux tool calls
          const toolCallIds = data.tool_calls.map((tc: any) => tc.id);
          setPendingToolCalls(new Set(toolCallIds));
          
          onToolCalls?.(data.tool_calls, 'tool_chain');
          
          // Si on a des tool results, les traiter immÃ©diatement
          if (data.tool_results && data.tool_results.length > 0) {
            for (const toolResult of data.tool_results) {
              onToolResult?.(
                toolResult.name,
                toolResult.result,
                toolResult.success,
                toolResult.tool_call_id
              );
              
              // Marquer ce tool call comme terminÃ©
              setPendingToolCalls(prev => {
                const newSet = new Set(prev);
                newSet.delete(toolResult.tool_call_id);
                return newSet;
              });
            }
          }
          
          // ðŸŽ¯ IMPORTANT: Ne pas appeler onComplete ici car le cycle continue
          // L'utilisateur doit attendre la rÃ©ponse finale
          return;
        }
        
        // ðŸŽ¯ GÃ©rer le cas de la relance automatique (LLM a rÃ©pondu aprÃ¨s tool calls)
        // PRIORITÃ‰: VÃ©rifier is_relance AVANT de vÃ©rifier tool_calls
        if (data.is_relance && !data.has_new_tool_calls) {
          logger.dev('[useChatResponse] âœ… Relance automatique terminÃ©e, rÃ©ponse finale reÃ§ue');
          logger.tool('[useChatResponse] âœ… Relance automatique terminÃ©e, rÃ©ponse finale reÃ§ue');
          
          // Traiter les tool results si prÃ©sents
          if (data.tool_results && data.tool_results.length > 0) {
            for (const toolResult of data.tool_results) {
              onToolResult?.(
                toolResult.name,
                toolResult.result,
                toolResult.success,
                toolResult.tool_call_id
              );
            }
          }
          
          // ðŸŽ¯ NOUVEAU: Informer si des tools ont Ã©chouÃ© mais ont Ã©tÃ© gÃ©rÃ©s intelligemment
          if (data.has_failed_tools) {
            logger.dev('[useChatResponse] âš ï¸ Des tools ont Ã©chouÃ© mais le LLM a gÃ©rÃ© intelligemment');
            // Optionnel: Ajouter un indicateur visuel pour l'utilisateur
          }
          
          // Appeler onComplete avec la rÃ©ponse finale
          onComplete?.(data.content || '', data.reasoning || '');
          return;
        }
        
        // GÃ©rer les tool calls normaux si prÃ©sents (premier appel)
        if (data.tool_calls && data.tool_calls.length > 0 && !data.is_relance) {
          // ðŸ”§ AMÃ‰LIORATION: Gestion des multiples tool calls
          const toolCallIds = data.tool_calls.map((tc: any) => tc.id);
          setPendingToolCalls(new Set(toolCallIds));
          
          // ðŸ”§ NOUVEAU: Log spÃ©cial pour les multiples tool calls
          if (data.tool_calls.length > 10) {
            logger.dev(`[useChatResponse] âš¡ Multiple tool calls dÃ©tectÃ©s: ${data.tool_calls.length} tools`);
            logger.tool(`[useChatResponse] âš¡ Multiple tool calls dÃ©tectÃ©s: ${data.tool_calls.length} tools`);
          }
          
          logger.tool(`[useChatResponse] ðŸ”§ Tool calls dÃ©tectÃ©s: ${data.tool_calls.length} tools`);
          onToolCalls?.(data.tool_calls, 'tool_chain');
          
          // Si on a des tool results, les traiter immÃ©diatement
          if (data.tool_results && data.tool_results.length > 0) {
            for (const toolResult of data.tool_results) {
              onToolResult?.(
                toolResult.name,
                toolResult.result,
                toolResult.success,
                toolResult.tool_call_id
              );
              
              // Marquer ce tool call comme terminÃ©
              setPendingToolCalls(prev => {
                const newSet = new Set(prev);
                newSet.delete(toolResult.tool_call_id);
                return newSet;
              });
            }

            // ðŸ”§ AMÃ‰LIORATION: Gestion intelligente de la relance pour multiples tools
            if (data.tool_results.length === data.tool_calls.length) {
              logger.dev(`[useChatResponse] âœ… Tous les ${data.tool_calls.length} tool calls sont terminÃ©s`);
              onToolExecutionComplete?.(data.tool_results);
            } else {
              logger.dev(`[useChatResponse] â³ ${data.tool_results.length}/${data.tool_calls.length} tool calls terminÃ©s`);
            }
          }
        } else {
          // Pas de tool calls ou rÃ©ponse finale, appeler onComplete directement
          logger.dev('[useChatResponse] âœ… RÃ©ponse simple sans tool calls, appel onComplete');
          logger.dev('[useChatResponse] ðŸ“„ Contenu:', { content: data.content, contentLength: data.content?.length || 0 });
          onComplete?.(data.content || '', data.reasoning || '');
        }
      } else {
        throw new Error(data.error || 'Erreur inconnue');
      }
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : 'Erreur inconnue';
      logger.error('[useChatResponse] âŒ Erreur:', error);
      onError?.(errorMessage);
    } finally {
      setIsProcessing(false);
    }
  }, [onComplete, onError, onToolCalls, onToolResult, onToolExecutionComplete]);

  const reset = useCallback(() => {
    setIsProcessing(false);
    setPendingToolCalls(new Set());
  }, []);

  return {
    isProcessing,
    sendMessage,
    reset
  };
} 