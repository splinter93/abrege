/**
 * SimpleToolExecutor - Syst√®me de tools intelligent avec relance automatique
 * Style ChatGPT : ex√©cution ‚Üí erreur ‚Üí relance ‚Üí r√©ponse finale
 */

import { ApiV2ToolExecutor } from '../executors/ApiV2ToolExecutor';
import { simpleLogger as logger } from '@/utils/logger';
import type { LLMResponse } from '../types/strictTypes';

/**
 * Type pour le callback LLM
 */
export type LLMCallback = (message: string, history: unknown[], tools: ToolCall[], results: ToolResult[]) => Promise<LLMResponse>;

export interface ToolCall {
  id: string;
  type: 'function';
  function: {
    name: string;
    arguments: string;
  };
}

export interface ToolResult {
  tool_call_id: string;
  name: string;
  content: string;
  success: boolean;
  error?: string;
  timestamp?: string;
}

export interface ExecutionContext {
  userToken: string;
  sessionId: string;
  maxRetries?: number;
  maxToolCalls?: number;
}

export interface ExecutionResult {
  success: boolean;
  content: string;
  toolCalls: ToolCall[];
  toolResults: ToolResult[];
  finalResponse?: string;
  error?: string;
}

/**
 * Ex√©cuteur de tools simple et intelligent
 * G√®re automatiquement les relances et les erreurs comme ChatGPT
 */
export class SimpleToolExecutor {
  private toolExecutor: ApiV2ToolExecutor;
  private readonly maxRetries: number = 3;
  private readonly maxToolCalls: number = 10;

  constructor() {
    this.toolExecutor = new ApiV2ToolExecutor();
  }

  /**
   * Ex√©cuter des tools avec relance intelligente
   * Style ChatGPT : ex√©cution ‚Üí analyse ‚Üí relance si n√©cessaire ‚Üí r√©ponse finale
   */
  async executeWithRetry(
    toolCalls: ToolCall[],
    context: ExecutionContext,
    llmCallback: LLMCallback
  ): Promise<ExecutionResult> {
    const { userToken, sessionId } = context;
    const maxRetries = context.maxRetries || this.maxRetries;
    const maxToolCalls = context.maxToolCalls || this.maxToolCalls;

    logger.info(`[SimpleToolExecutor] üöÄ D√©marrage ex√©cution ${toolCalls.length} tools`);

    let allToolCalls: ToolCall[] = [...toolCalls];
    let allResults: ToolResult[] = [];
    let retryCount = 0;
    let currentToolCalls = toolCalls;

    while (retryCount < maxRetries && currentToolCalls.length > 0) {
      logger.info(`[SimpleToolExecutor] üîÑ Tentative ${retryCount + 1}/${maxRetries} - ${currentToolCalls.length} tools`);

      try {
        // 1. Ex√©cuter les tools actuels
        const results = await this.executeTools(currentToolCalls, userToken);
        allResults.push(...results);

        // 2. Analyser les r√©sultats
        const analysis = this.analyzeResults(results);
        
        if (analysis.needsRetry && retryCount < maxRetries - 1) {
          // 3. Demander au LLM de corriger/relancer
          const retryMessage = this.buildRetryMessage(analysis);
          const llmResponse = await llmCallback(retryMessage, [], allToolCalls, allResults);
          
          // 4. Extraire les nouveaux tool calls
          const newToolCalls = this.extractToolCalls(llmResponse);
          
          if (newToolCalls.length > 0) {
            currentToolCalls = newToolCalls;
            allToolCalls.push(...newToolCalls);
            retryCount++;
            continue;
          }
        }

        // 5. Succ√®s ou √©chec final
        break;

      } catch (error) {
        logger.error(`[SimpleToolExecutor] ‚ùå Erreur tentative ${retryCount + 1}:`, error);
        
        if (retryCount < maxRetries - 1) {
          // Demander au LLM de g√©rer l'erreur
          const errorMessage = this.buildErrorMessage(error);
          const llmResponse = await llmCallback(errorMessage, [], allToolCalls, allResults);
          
          const newToolCalls = this.extractToolCalls(llmResponse);
          if (newToolCalls.length > 0) {
            currentToolCalls = newToolCalls;
            allToolCalls.push(...newToolCalls);
            retryCount++;
            continue;
          }
        }
        
        break;
      }
    }

    // 6. G√©n√©rer la r√©ponse finale
    const finalResponse = await this.generateFinalResponse(allToolCalls, allResults, llmCallback);

    const result: ExecutionResult = {
      success: allResults.some(r => r.success),
      content: finalResponse,
      toolCalls: allToolCalls,
      toolResults: allResults
    };

    logger.info(`[SimpleToolExecutor] ‚úÖ Ex√©cution termin√©e - ${allResults.filter(r => r.success).length}/${allResults.length} succ√®s`);
    
    return result;
  }

  /**
   * Ex√©cuter une liste de tools
   */
  private async executeTools(toolCalls: ToolCall[], userToken: string): Promise<ToolResult[]> {
    const results: ToolResult[] = [];

    for (const toolCall of toolCalls) {
      try {
        const result = await this.toolExecutor.executeToolCall(toolCall, userToken);
        results.push(result);
      } catch (error) {
        logger.error(`[SimpleToolExecutor] Tool ${toolCall.function.name} failed:`, error);
        results.push({
          tool_call_id: toolCall.id,
          name: toolCall.function.name,
          content: JSON.stringify({
            success: false,
            error: error instanceof Error ? error.message : 'Erreur inconnue'
          }),
          success: false,
          error: error instanceof Error ? error.message : 'Erreur inconnue'
        });
      }
    }

    return results;
  }

  /**
   * Analyser les r√©sultats pour d√©terminer si une relance est n√©cessaire
   */
  private analyzeResults(results: ToolResult[]): {
    needsRetry: boolean;
    failedTools: string[];
    errorTypes: string[];
  } {
    const failedTools = results.filter(r => !r.success).map(r => r.name);
    const errorTypes = results
      .filter(r => !r.success)
      .map(r => this.categorizeError(r.error || 'Unknown error'));

    const needsRetry = failedTools.length > 0 && 
      errorTypes.some(type => ['NETWORK_ERROR', 'TIMEOUT', 'SERVER_ERROR'].includes(type));

    return {
      needsRetry,
      failedTools,
      errorTypes
    };
  }

  /**
   * Cat√©goriser une erreur
   */
  private categorizeError(error: string): string {
    const errorLower = error.toLowerCase();
    
    if (errorLower.includes('timeout') || errorLower.includes('timed out')) return 'TIMEOUT';
    if (errorLower.includes('network') || errorLower.includes('connection')) return 'NETWORK_ERROR';
    if (errorLower.includes('500') || errorLower.includes('server error')) return 'SERVER_ERROR';
    if (errorLower.includes('404') || errorLower.includes('not found')) return 'NOT_FOUND';
    if (errorLower.includes('403') || errorLower.includes('forbidden')) return 'PERMISSION_ERROR';
    if (errorLower.includes('401') || errorLower.includes('unauthorized')) return 'AUTH_ERROR';
    
    return 'UNKNOWN_ERROR';
  }

  /**
   * Construire un message de relance
   */
  private buildRetryMessage(analysis: { failedTools: string[]; errorTypes: string[] }): string {
    const { failedTools, errorTypes } = analysis;
    
    return `Les outils suivants ont √©chou√© : ${failedTools.join(', ')}. 
    Types d'erreurs : ${errorTypes.join(', ')}. 
    Peux-tu r√©essayer avec des param√®tres diff√©rents ou des outils alternatifs ?`;
  }

  /**
   * Construire un message d'erreur
   */
  private buildErrorMessage(error: unknown): string {
    const errorMsg = error instanceof Error ? error.message : String(error);
    return `Une erreur s'est produite lors de l'ex√©cution des outils : ${errorMsg}. 
    Peux-tu proposer une solution alternative ?`;
  }

  /**
   * Extraire les tool calls d'une r√©ponse LLM
   */
  private extractToolCalls(llmResponse: LLMResponse): ToolCall[] {
    if (!llmResponse || typeof llmResponse !== 'object') return [];
    
    const toolCalls = llmResponse.tool_calls || [];
    
    if (!Array.isArray(toolCalls)) return [];
    
    return toolCalls.filter((tc): tc is ToolCall => 
      !!tc && 
      typeof tc.id === 'string' && 
      !!tc.function && 
      typeof tc.function.name === 'string'
    );
  }

  /**
   * G√©n√©rer la r√©ponse finale
   */
  private async generateFinalResponse(
    toolCalls: ToolCall[], 
    results: ToolResult[], 
    llmCallback: LLMCallback
  ): Promise<string> {
    const successfulResults = results.filter(r => r.success);
    const failedResults = results.filter(r => !r.success);

    if (successfulResults.length === 0) {
      return "Je n'ai pas pu ex√©cuter les outils demand√©s. Veuillez r√©essayer avec des param√®tres diff√©rents.";
    }

    if (failedResults.length === 0) {
      return "Tous les outils ont √©t√© ex√©cut√©s avec succ√®s.";
    }

    // Demander au LLM de g√©n√©rer une r√©ponse bas√©e sur les r√©sultats
    const summaryMessage = `Voici les r√©sultats des outils :
    Succ√®s : ${successfulResults.length}
    √âchecs : ${failedResults.length}
    
    Peux-tu fournir un r√©sum√© des r√©sultats et des prochaines √©tapes ?`;

    try {
      const llmResponse = await llmCallback(summaryMessage, [], toolCalls, results);
      return llmResponse.content || llmResponse.message || "R√©sum√© des r√©sultats g√©n√©r√©.";
    } catch (error) {
      logger.error('[SimpleToolExecutor] Erreur g√©n√©ration r√©ponse finale:', error);
      return "Les outils ont √©t√© ex√©cut√©s avec des r√©sultats mitig√©s.";
    }
  }

  /**
   * Ex√©cution simple sans relance (pour compatibilit√©)
   */
  async executeSimple(toolCalls: ToolCall[], userToken: string): Promise<ToolResult[]> {
    return this.executeTools(toolCalls, userToken);
  }

  /**
   * Alias pour executeSimple (utilis√© par SimpleOrchestrator)
   */
  async executeToolCalls(toolCalls: ToolCall[], userToken: string): Promise<ToolResult[]> {
    return this.executeTools(toolCalls, userToken);
  }
}

// Instance singleton
export const simpleToolExecutor = new SimpleToolExecutor();
