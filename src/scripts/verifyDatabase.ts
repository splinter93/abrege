import { config } from 'dotenv';
import { resolve } from 'path';
import { createClient } from '@supabase/supabase-js';
// import.*logger.*from '@/utils/logger';

// Charger les variables d'environnement depuis .env
config({ path: resolve(process.cwd(), '.env') });

const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL!;
const supabaseAnonKey = process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!;
// // const supabase = [^;]+;]+;

// ğŸš§ Temp: Authentification non implÃ©mentÃ©e
    // TODO: Remplacer USER_ID par l'authentification Supabase
    // ğŸš§ Temp: Authentification non implÃ©mentÃ©e
    // TODO: Remplacer USER_ID par l'authentification Supabase
    const USER_ID = "3223651c-5580-4471-affb-b3f4456bd729";

async function checkTableStructure(tableName: string) {
  logger.dev(`\nğŸ” VÃ©rification de la table ${tableName}...`);
  
  try {
    // VÃ©rifier si la colonne slug existe
    const { data: _testData, error: testError } = await supabase
      .from(tableName)
      .select('slug')
      .limit(1);
    
    if (testError && testError.message.includes('column') && testError.message.includes('does not exist')) {
      logger.dev(`âŒ La colonne slug n'existe pas dans la table ${tableName}`);
      return false;
    } else {
      logger.dev(`âœ… La colonne slug existe dans la table ${tableName}`);
      
      // Compter les enregistrements avec et sans slug
      const { data: withSlug } = await supabase
        .from(tableName)
        .select('id')
        .not('slug', 'is', null);
      
      const { data: withoutSlug } = await supabase
        .from(tableName)
        .select('id')
        .is('slug', null);
      
      logger.dev(`ğŸ“Š ${tableName}: ${withSlug?.length || 0} avec slug, ${withoutSlug?.length || 0} sans slug`);
      
      return true;
    }
  } catch (error) {
    logger.error(`âŒ Erreur lors de la vÃ©rification de ${tableName}:`, error);
    return false;
  }
}

async function checkIndexes() {
  logger.dev('\nğŸ” VÃ©rification des index uniques...');
  
  try {
    // Test de contrainte d'unicitÃ© sur articles
    const { data: articlesTest } = await supabase
      .from('articles')
      .select('slug, user_id')
      .not('slug', 'is', null)
      .limit(10);
    
    if (articlesTest) {
      const uniqueSlugs = new Set(articlesTest.map(a => `${a.slug}-${a.user_id}`));
      logger.dev(`âœ… Index articles: ${articlesTest.length} enregistrements, ${uniqueSlugs.size} combinaisons uniques`);
    }
    
    // Test de contrainte d'unicitÃ© sur folders
    const { data: foldersTest } = await supabase
      .from('folders')
      .select('slug, user_id')
      .not('slug', 'is', null)
      .limit(10);
    
    if (foldersTest) {
      const uniqueSlugs = new Set(foldersTest.map(f => `${f.slug}-${f.user_id}`));
      logger.dev(`âœ… Index folders: ${foldersTest.length} enregistrements, ${uniqueSlugs.size} combinaisons uniques`);
    }
    
    // Test de contrainte d'unicitÃ© sur classeurs
    const { data: classeursTest } = await supabase
      .from('classeurs')
      .select('slug, user_id')
      .not('slug', 'is', null)
      .limit(10);
    
    if (classeursTest) {
      const uniqueSlugs = new Set(classeursTest.map(c => `${c.slug}-${c.user_id}`));
      logger.dev(`âœ… Index classeurs: ${classeursTest.length} enregistrements, ${uniqueSlugs.size} combinaisons uniques`);
    }
    
  } catch (error) {
    logger.error('âŒ Erreur lors de la vÃ©rification des index:', error);
  }
}

async function checkSampleData() {
  logger.dev('\nğŸ“Š VÃ©rification des donnÃ©es d\'exemple...');
  
  try {
    // RÃ©cupÃ©rer quelques exemples de chaque type
    const { data: notes } = await supabase
      .from('articles')
      .select('id, slug, source_title, user_id')
      .eq('user_id', USER_ID)
      .not('slug', 'is', null)
      .limit(3);

    const { data: folders } = await supabase
      .from('folders')
      .select('id, slug, name, user_id')
      .eq('user_id', USER_ID)
      .not('slug', 'is', null)
      .limit(3);

    const { data: classeurs } = await supabase
      .from('classeurs')
      .select('id, slug, name, user_id')
      .eq('user_id', USER_ID)
      .not('slug', 'is', null)
      .limit(3);

    logger.dev('\nğŸ“ Exemples de notes:');
    notes?.forEach(note => {
      logger.dev(`  - ID: ${note.id}, Slug: ${note.slug}, Titre: ${note.source_title}`);
    });

    logger.dev('\nğŸ“ Exemples de dossiers:');
    folders?.forEach(folder => {
      logger.dev(`  - ID: ${folder.id}, Slug: ${folder.slug}, Nom: ${folder.name}`);
    });

    logger.dev('\nğŸ“š Exemples de classeurs:');
    classeurs?.forEach(classeur => {
      logger.dev(`  - ID: ${classeur.id}, Slug: ${classeur.slug}, Nom: ${classeur.name}`);
    });

    return { notes, folders, classeurs };
  } catch (error) {
    logger.error('âŒ Erreur lors de la vÃ©rification des donnÃ©es:', error);
    return { notes: [], folders: [], classeurs: [] };
  }
}

async function testSlugGeneration() {
  logger.dev('\nğŸ§ª Test de gÃ©nÃ©ration de slugs...');
  
  try {
    // Test avec un titre simple
    const testTitle = 'Test Slug Generation 2024';
    const expectedSlug = 'test-slug-generation-2024';
    
    logger.dev(`ğŸ“ Test: "${testTitle}" -> "${expectedSlug}"`);
    
    // VÃ©rifier si ce slug existe dÃ©jÃ 
    const { data: existing } = await supabase
      .from('articles')
      .select('id')
      .eq('slug', expectedSlug)
      .eq('user_id', USER_ID);
    
    if (existing && existing.length > 0) {
      logger.dev(`âš ï¸  Le slug "${expectedSlug}" existe dÃ©jÃ `);
    } else {
      logger.dev(`âœ… Le slug "${expectedSlug}" est disponible`);
    }
    
  } catch (error) {
    logger.error('âŒ Erreur lors du test de gÃ©nÃ©ration:', error);
  }
}

async function main() {
  logger.dev('ğŸ” VÃ©rification complÃ¨te de la base de donnÃ©es');
  logger.dev('=============================================');
  logger.dev(`ğŸ‘¤ USER_ID: ${USER_ID}`);
  logger.dev(`ğŸŒ Supabase URL: ${supabaseUrl}`);
  
  try {
    // VÃ©rifier la structure des tables
    const articlesOk = await checkTableStructure('articles');
    const foldersOk = await checkTableStructure('folders');
    const classeursOk = await checkTableStructure('classeurs');
    
    // VÃ©rifier les index
    await checkIndexes();
    
    // VÃ©rifier les donnÃ©es d'exemple
    // const _sampleData = [^;]+;
    
    // Test de gÃ©nÃ©ration de slugs
    await testSlugGeneration();
    
    // RÃ©sumÃ©
    logger.dev('\nğŸ“‹ RÃ©sumÃ© de la vÃ©rification:');
    logger.dev(`- Articles: ${articlesOk ? 'âœ…' : 'âŒ'}`);
    logger.dev(`- Folders: ${foldersOk ? 'âœ…' : 'âŒ'}`);
    logger.dev(`- Classeurs: ${classeursOk ? 'âœ…' : 'âŒ'}`);
    
    if (articlesOk && foldersOk && classeursOk) {
      logger.dev('\nğŸ‰ Base de donnÃ©es prÃªte pour l\'API LLM-friendly !');
      logger.dev('\nğŸ“‹ Prochaines Ã©tapes:');
      logger.dev('1. Lancer: npm run migrate-slugs (si des donnÃ©es sans slug)');
      logger.dev('2. Lancer: npm run test-endpoints (pour tester l\'API)');
      logger.dev('3. Utiliser le guide Donna pour tester manuellement');
    } else {
      logger.dev('\nâš ï¸  ProblÃ¨mes dÃ©tectÃ©s !');
      logger.dev('ğŸ“‹ Actions requises:');
      logger.dev('1. ExÃ©cuter la migration SQL dans Supabase Dashboard');
      logger.dev('2. Relancer: npm run add-slug-columns');
      logger.dev('3. Lancer: npm run migrate-slugs');
    }
    
  } catch (error) {
    logger.error('âŒ Erreur lors de la vÃ©rification:', error);
  }
}

// ExÃ©cuter le script si appelÃ© directement
if (require.main === module) {
  main();
}

export { main as verifyDatabase }; 