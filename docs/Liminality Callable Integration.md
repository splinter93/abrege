# IntÃ©gration des callables dans les requÃªtes LLM Exec

Documentation Ã  lâ€™usage du client (autre projet) qui appelle lâ€™API Synesia **LLM Exec**. Objectif : vÃ©rifier que lâ€™injection des **callables** dans les requÃªtes est correcte et que le flux (round + stream) est bien gÃ©rÃ©.

**Avec ce document, un dÃ©veloppeur a tout pour implÃ©menter un chat externe et afficher les appels vers un callable** : endpoints et auth (Â§1â€“2), format de la requÃªte et des callables (Â§3â€“4), format SSE et procÃ©dure pour rÃ©cupÃ©rer les tool calls dans le stream (Â§6), Ã©vÃ©nements Ã  Ã©couter et exemples de payloads pour lâ€™affichage (Â§7), checklist de vÃ©rification (Â§8) et exemple cURL (Â§9).

---

## 1. Endpoints concernÃ©s

| Endpoint | MÃ©thode | Usage |
|----------|---------|--------|
| `/llm-exec/round` | POST | Round complet, rÃ©ponse JSON (non-streaming). |
| `/llm-exec/round/stream` | POST | Round en streaming (SSE). |

Pour un chat avec callables, les deux sont utilisables ; le **stream** est recommandÃ© pour lâ€™UX (texte progressif + Ã©vÃ©nements dâ€™outils).

---

## 2. Authentification

Le **project_id** est requis cÃ´tÃ© Synesia (rÃ©solution des callables, runs, etc.). Il doit Ãªtre fourni via lâ€™un des mÃ©canismes suivants.

### Option A : ClÃ© API (recommandÃ©)

- Header : **`x-api-key`**
- Valeur : clÃ© du projet (format type `apiKey.25.xxxx` ou Ã©quivalent).
- Le serveur dÃ©rive le `project_id` Ã  partir de cette clÃ©.

```http
x-api-key: apiKey.25.OGIwMzllY2MtYWIxZS00Y2E2LTg4MjQtMGQ4OTFiMWFmZDA1
```

### Option B : Bearer + project

- Header : **`Authorization: Bearer <token>`**
- Header : **`x-project-id: <uuid_du_projet>`**

Si le client utilise un autre schÃ©ma (ex. prÃ©fixe "Entity"), lâ€™erreur typique sera du type : *"Invalid authorization format. Must start with Bearer or Entity"*. Il faut alors adapter les headers cÃ´tÃ© client pour quâ€™ils correspondent Ã  ce que Synesia attend.

---

## 3. Corps de la requÃªte (body)

Body JSON commun pour `/llm-exec/round` et `/llm-exec/round/stream`.

### Champs obligatoires

- **`model`** (string) : slug du modÃ¨le, ex. `groq/gpt-oss-120b`, `openai/gpt-4o-mini`.
- **`messages`** (array) : liste de messages (au moins un), chacun avec `role` et `content` (pour user/assistant/system).

### Champs optionnels utiles pour les callables

- **`tools`** (array) : liste dâ€™outils exposÃ©s au modÃ¨le. Pour les callables, voir Â§4.
- **`instructions`** (string) : instructions systÃ¨me (prompt systÃ¨me) pour guider lâ€™agent sur lâ€™usage des outils.
- **`config`** (object) : ex. `{ "max_loops": 10 }` pour limiter les tours dâ€™orchestration.

Exemple minimal **avec** callable :

```json
{
  "model": "groq/gpt-oss-120b",
  "messages": [
    { "role": "user", "content": "Demande Ã  Tim d'envoyer un message Telegram Ã  K pour lui demander s'il va bien." }
  ],
  "tools": [
    { "type": "callable", "callable_id": "c89f020d-404b-4429-be25-ec7dec0e7a56" }
  ],
  "instructions": "You have access to Tim. When the user asks Tim to do something, call Tim with that request and then confirm the result to the user."
}
```

---

## 4. Injection des callables dans `tools`

### Format dâ€™un outil callable

Un callable est un outil dont le type est **`callable`** et qui rÃ©fÃ©rence un callable Synesia par son identifiant.

```json
{
  "type": "callable",
  "callable_id": "<uuid_ou_slug>"
}
```

- **`type`** : doit Ãªtre exactement **`"callable"`**.
- **`callable_id`** (string) :
  - soit un **UUID** du callable (ex. `c89f020d-404b-4429-be25-ec7dec0e7a56`) ;
  - soit un **slug** si le callable en a un (ex. `tim`).
  - Lâ€™UUID ou le slug se rÃ©cupÃ¨re dans lâ€™interface Synesia (dÃ©tail du callable) ou via lâ€™API projet.

Aucun autre champ nâ€™est nÃ©cessaire pour lâ€™injection cÃ´tÃ© requÃªte. Le nom, la description et le schÃ©ma dâ€™entrÃ©e du tool sont **rÃ©cupÃ©rÃ©s cÃ´tÃ© Synesia** Ã  partir du callable (vue `project_available_callables_view`, projet = celui dÃ©rivÃ© de lâ€™auth).

### RÃ¨gles cÃ´tÃ© Synesia (pour comprendre les erreurs)

- Le callable doit **exister** et Ãªtre **disponible pour le projet** (mÃªme `project_id` que celui de la clÃ© / du token).
- Le callable doit avoir une **description** ; sinon Synesia renverra une erreur du type *"Callable X must have a description"*.
- Un callable peut Ãªtre un **agent**, un **script**, une **pipeline**, etc. Lorsque le modÃ¨le appelle ce â€œtoolâ€, Synesia exÃ©cute le callable (ex. `ExecutionService.execute(callable_id, args, project_id, ...)`) et renvoie le rÃ©sultat comme **tool_response** au modÃ¨le.

### Exemple avec plusieurs outils (dont un callable)

```json
{
  "model": "groq/gpt-oss-120b",
  "messages": [ { "role": "user", "content": "Ask Tim to say hello to K on Telegram." } ],
  "tools": [
    { "type": "callable", "callable_id": "c89f020d-404b-4429-be25-ec7dec0e7a56" }
  ],
  "instructions": "You have access to Tim. Call Tim when the user asks to contact or message someone."
}
```

Ne pas mÃ©langer avec dâ€™autres types dâ€™outils si vous voulez uniquement des callables ; pour ajouter dâ€™autres outils (MCP, OpenAPI, etc.), voir le schÃ©ma `InputTool` dans lâ€™OpenAPI Synesia (`openapi-schemas/llm-exec.json`).

---

## 5. Comportement cÃ´tÃ© Synesia (rÃ©sumÃ©)

1. Le serveur reÃ§oit `tools` avec des entrÃ©es `{ "type": "callable", "callable_id": "..." }`.
2. Pour chaque callable, il charge **name**, **description**, **input_schema** depuis la base (vue projet).
3. Il convertit chaque callable en un outil â€œmanagedâ€ exposÃ© au LLM (nom dÃ©rivÃ© du name/slug, description, paramÃ¨tres dÃ©rivÃ©s de `input_schema`).
4. Lorsque le modÃ¨le renvoie un **tool_call** dont le nom correspond Ã  ce callable, Synesia exÃ©cute le callable (agent, script, pipeline, etc.) avec les arguments fournis par le modÃ¨le.
5. Le rÃ©sultat (succÃ¨s ou erreur) est renvoyÃ© comme **tool_response** au modÃ¨le ; le round continue (tour suivant) jusquâ€™Ã  ce que le modÃ¨le renvoie une rÃ©ponse finale (sans tool_call) ou que `max_loops` soit atteint.

Donc cÃ´tÃ© client : il suffit dâ€™envoyer **model**, **messages** et **tools** (avec les callables au format ci-dessus). Pas besoin dâ€™envoyer le schÃ©ma ou la description du callable ; Synesia sâ€™en charge.

---

## 6. Streaming : `/llm-exec/round/stream`

### Headers de la requÃªte

- **Content-Type**: `application/json`
- **x-api-key** (ou Authorization + x-project-id) comme en Â§2.
- Pas de header particulier pour accepter le stream : la rÃ©ponse est en **text/event-stream** (SSE).

### Format de la rÃ©ponse (SSE)

Chaque Ã©vÃ©nement est envoyÃ© sous la forme dâ€™une ligne **`data: <json>`** suivie dâ€™un double saut de ligne (`\n\n`). Le client reÃ§oit un flux **text/event-stream** ; comme la requÃªte est un **POST** (avec body), il faut utiliser **fetch** (ou Ã©quivalent) avec lecture du body en stream (**ReadableStream**), et non `EventSource` (rÃ©servÃ© au GET).

**RÃ©cupÃ©rer les tool calls dans le stream :**

1. Ouvrir la connexion **POST** vers `/llm-exec/round/stream` avec le body JSON (model, messages, tools, etc.).
2. Lire **response.body** en stream ; dÃ©coder les chunks en texte UTF-8.
3. DÃ©couper le flux par Ã©vÃ©nements SSE : repÃ©rer les blocs sÃ©parÃ©s par `\n\n`, puis pour chaque bloc prendre la ligne qui commence par `data: ` et parser la suite comme **JSON**.
4. Dans chaque objet parsÃ©, utiliser le champ **`type`** pour dispatcher :
   - `internal_tool.start` â†’ dÃ©but dâ€™un tool call : stocker `tool_call_id`, `name`, `arguments` et afficher un bloc Â« en cours Â».
   - `internal_tool.done` â†’ fin dâ€™un tool call : associer au `tool_call_id` et afficher `result`.
   - `internal_tool.error` â†’ Ã©chec : associer au mÃªme `tool_call_id` et afficher `error`.
5. Utiliser **`tool_call_id`** pour faire le lien entre `.start`, `.done` et `.error` (un mÃªme appel est identifiÃ© par ce champ).

Les Ã©vÃ©nements pertinents pour les callables et le texte final :

| Type dâ€™Ã©vÃ©nement | Description |
|------------------|-------------|
| `start` | DÃ©but du round. |
| `tool_block.start` | DÃ©but dâ€™un bloc dâ€™exÃ©cution dâ€™outils (un ou plusieurs tool_calls). |
| `internal_tool.start` | DÃ©but de lâ€™exÃ©cution dâ€™un outil (ex. callable) : `tool_call_id`, `name`, `arguments`. |
| `internal_tool.done` | Fin de lâ€™outil : `tool_call_id`, `name`, `result` (rÃ©ponse du callable ou message dâ€™erreur). |
| `internal_tool.error` | Erreur lors de lâ€™exÃ©cution de lâ€™outil : `tool_call_id`, `name`, `error`. |
| `tool_block.done` | Fin du bloc dâ€™outils. |
| `text.start` / `text.delta` / `text.done` | RÃ©ponse texte du modÃ¨le (streaming). |
| `done` | Fin du round : contient `complete`, `usage`, `messages` (historique complet). |

Exemple dâ€™enchaÃ®nement typique avec un callable :

1. `start`
2. `tool_block.start`
3. `internal_tool.start` (name = nom du callable, ex. `tim`, arguments = ce que le modÃ¨le a passÃ©s)
4. `internal_tool.done` (result = rÃ©ponse du callable) ou `internal_tool.error` (error = message dâ€™erreur)
5. `tool_block.done`
6. `text.start` puis `text.delta` (plusieurs) puis `text.done` (rÃ©ponse finale de lâ€™agent)
7. `done` avec `complete: true` et `messages` contenant tout lâ€™historique (user, tool_request, tool_response, assistant)

CÃ´tÃ© client, il faut :

- Parser chaque ligne `data: <json>`.
- GÃ©rer **internal_tool.start** / **internal_tool.done** / **internal_tool.error** pour afficher lâ€™Ã©tat des appels callable (chargement, succÃ¨s, erreur).
- Accumuler **text.delta** (ou utiliser **text.done**) pour afficher la rÃ©ponse finale.
- Utiliser **done** pour considÃ©rer le round terminÃ© et Ã©ventuellement mettre Ã  jour lâ€™historique Ã  partir de `messages`.

---

## 7. Afficher les appels callable comme des Â« tool calls Â» dans le chat

**Oui** : un chat externe peut rÃ©cupÃ©rer et afficher le tool call lorsque lâ€™agent appelle un callable. En **stream** (`/llm-exec/round/stream`), les Ã©vÃ©nements SSE `internal_tool.start`, `internal_tool.done` et `internal_tool.error` exposent chaque appel (nom, arguments, rÃ©sultat). En **non-stream** (`/llm-exec/round`), la rÃ©ponse JSON finale contient `messages` avec lâ€™historique complet (messages assistant avec tool_calls + tool_response). Il suffit dâ€™Ã©couter le stream ou de parser `messages` pour afficher ces appels dans lâ€™UI.

Quand lâ€™agent appelle un callable, tout sâ€™exÃ©cute **cÃ´tÃ© Synesia** (llm-exec). Votre chat ne reÃ§oit pas de structure Â« tool_call Â» au sens brut OpenAI : il reÃ§oit soit le **stream SSE** (Ã©vÃ©nements par Ã©vÃ©nement), soit le **JSON final** avec `messages`. Pour que lâ€™utilisateur voie un **tool call** (ex. Â« Agent appelle Tim Â» puis le rÃ©sultat), il faut **Ã©couter les Ã©vÃ©nements SSE** et les traduire en blocs Â« tool call Â» dans votre UI.

### Ã‰vÃ©nements Ã  Ã©couter

| Ã‰vÃ©nement SSE | RÃ´le | DonnÃ©es utiles | Action UI suggÃ©rÃ©e |
|---------------|------|----------------|--------------------|
| **`internal_tool.start`** | DÃ©but dâ€™un appel (callable ou autre outil) | `tool_call_id`, `name`, `arguments` | Afficher un bloc Â« Tool call : &lt;name&gt; Â» (ex. Â« Appel de Tim Â»), optionnellement les `arguments`, Ã©tat Â« en cours Â». |
| **`internal_tool.done`** | Fin rÃ©ussie | `tool_call_id`, `name`, `result` | Associer au bloc identifiÃ© par `tool_call_id`, afficher le `result`, passer en Ã©tat Â« terminÃ© Â». |
| **`internal_tool.error`** | Ã‰chec de lâ€™outil | `tool_call_id`, `name`, `error` | Associer au mÃªme bloc, afficher lâ€™erreur, Ã©tat Â« erreur Â». |

Le **`tool_call_id`** permet de faire le lien entre `.start`, `.done` et `.error` pour un mÃªme appel. Le champ **`block_id`** (optionnel) identifie le bloc dâ€™outils ; utile pour grouper plusieurs appels dans lâ€™UI.

**Ã€ noter :** dans un mÃªme round, plusieurs tool calls peuvent se succÃ©der (plusieurs `internal_tool.start` / `.done` dâ€™affilÃ©e dans un mÃªme `tool_block`). En cas dâ€™Ã©chec, le serveur envoie Ã  la fois **`internal_tool.error`** et **`internal_tool.done`** pour le mÃªme `tool_call_id` (`.done` contient alors le message dâ€™erreur dans `result`). Il suffit de gÃ©rer les trois types dâ€™Ã©vÃ©nements et de mettre Ã  jour le bloc correspondant.

### Exemple de structure cÃ´tÃ© client

Pour chaque **`internal_tool.start`** :

- CrÃ©er un objet Â« tool call Â» dans votre state (ex. `{ id: tool_call_id, name, arguments, status: 'running', result: null }`).
- Afficher dans le chat un bloc du type : Â« ğŸ”§ Appel de **tim** Â» (ou le `name` reÃ§u).

Pour **`internal_tool.done`** avec le mÃªme `tool_call_id` :

- Mettre Ã  jour le bloc : `status: 'done'`, `result: event.result`.
- Afficher le rÃ©sultat (texte ou JSON tronquÃ©) sous le libellÃ© du tool call.

Pour **`internal_tool.error`** avec le mÃªme `tool_call_id` :

- Mettre Ã  jour le bloc : `status: 'error'`, afficher `event.error`.

### Exemple de payload (Ã  parser depuis `data: ...`)

**DÃ©but dâ€™appel :**
```json
{
  "type": "internal_tool.start",
  "tool_call_id": "fc_9f594179-b783-437f-84fe-51a14a433f25",
  "block_id": "tool_block_xxx",
  "name": "tim",
  "arguments": { "value": "Envoie un message Telegram Ã  K pour lui demander s'il va bien." }
}
```

**Fin dâ€™appel (succÃ¨s) :**
```json
{
  "type": "internal_tool.done",
  "tool_call_id": "fc_9f594179-b783-437f-84fe-51a14a433f25",
  "block_id": "tool_block_xxx",
  "name": "tim",
  "result": "My dear companion, the telegram has winged its way to K..."
}
```

**Fin dâ€™appel (erreur) :**
```json
{
  "type": "internal_tool.error",
  "tool_call_id": "fc_9f594179-b783-437f-84fe-51a14a433f25",
  "block_id": "tool_block_xxx",
  "name": "tim",
  "error": "Invalid tool results: ..."
}
```

### En rÃ©sumÃ©

- **Sans** gestion de `internal_tool.*` : le callable sâ€™exÃ©cute bien cÃ´tÃ© Synesia, mais votre chat nâ€™a rien Ã  afficher pour cet appel.
- **Avec** gestion de ces trois types dâ€™Ã©vÃ©nements et affichage de blocs Â« tool call Â» par `tool_call_id`, lâ€™utilisateur voit clairement que lâ€™agent a appelÃ© un outil (callable) et quel en est le rÃ©sultat.

---

## 8. VÃ©rification de lâ€™implÃ©mentation client (checklist)

Checklist pour lâ€™agent dÃ©veloppeur sur lâ€™autre projet :

- [ ] **Auth** : Envoi de **x-api-key** (ou Bearer + **x-project-id**) sur chaque requÃªte vers `/llm-exec/round` et `/llm-exec/round/stream`. Pas dâ€™auth = 401.
- [ ] **Body** : Envoi de **model** et **messages** ; pour les callables, envoi de **tools** avec des objets `{ "type": "callable", "callable_id": "<id_ou_slug>" }`. Pas de champ `callable_id` ou mauvais type = le callable ne sera pas reconnu.
- [ ] **URL** : Utilisation de la bonne base (ex. `https://api.synesia.com` ou `http://localhost:3001` selon lâ€™environnement ; lâ€™URL de base est fournie par Synesia ou configurÃ©e dans votre projet) et du chemin exact `/llm-exec/round` ou `/llm-exec/round/stream` (pas de typo, pas de slash en trop).
- [ ] **Stream** : Pour le stream, lecture du body en SSE (lignes `data: ...`), parsing JSON de chaque Ã©vÃ©nement, et gestion au minimum de `internal_tool.start`, `internal_tool.done`, `internal_tool.error`, `text.delta`/`text.done`, et `done`.
- [ ] **Affichage des tool calls** : Pour que lâ€™utilisateur voie les appels callable comme des tool calls, rÃ©agir aux Ã©vÃ©nements `internal_tool.start` / `internal_tool.done` / `internal_tool.error` et afficher des blocs Â« tool call Â» dans le chat (voir Â§7).
- [ ] **Timeout** : Les callables (surtout les agents) peuvent prendre du temps (plusieurs secondes Ã  dizaines de secondes). PrÃ©voir un timeout cÃ´tÃ© client/proxy suffisant (ex. 2â€“5 minutes) pour ne pas couper la connexion avant la fin du round.
- [ ] **Erreurs** : En cas dâ€™erreur (4xx/5xx ou Ã©vÃ©nement `error` dans le stream), afficher ou logger le message dâ€™erreur pour faciliter le debug (ex. callable introuvable, validation, timeout).

---

## 9. Exemple cURL complet (stream + callable)

```bash
curl -s -N -X POST "http://localhost:3001/llm-exec/round/stream" \
  -H "Content-Type: application/json" \
  -H "x-api-key: apiKey.25.XXXX" \
  -d '{
    "model": "groq/gpt-oss-120b",
    "messages": [
      {"role": "user", "content": "Demande Ã  Tim d'\''envoyer un message sur Telegram Ã  K pour lui demander s'\''il va bien."}
    ],
    "tools": [
      {"type": "callable", "callable_id": "c89f020d-404b-4429-be25-ec7dec0e7a56"}
    ],
    "instructions": "You have access to Tim. When the user asks Tim to send a Telegram message, call Tim with that request and confirm the result to the user."
  }'
```

Remplacer `apiKey.25.XXXX` et Ã©ventuellement le `callable_id` par les valeurs du projet. On obtient une suite dâ€™Ã©vÃ©nements SSE ; la rÃ©ponse finale utile pour lâ€™utilisateur se trouve dans les `text.delta` / `text.done` et dans le dernier message assistant de lâ€™Ã©vÃ©nement `done.messages`.

---

## 10. RÃ©fÃ©rences

- SchÃ©ma OpenAPI : `openapi-schemas/llm-exec.json` (dÃ©finition de `InputTool`, endpoints, sÃ©curitÃ©).
- Types serveur : `apps/server/src/features/llm-exec/llm-exec.types.ts` (`InputCallableTool` = `{ type: 'callable', callable_id: string }`).
- Conversion callable â†’ outil LLM : `apps/server/src/features/llm-exec/converters/callable-tool.converter.ts`.
- Script de test local : `scripts/call-llm-exec-stream.sh` (exemple dâ€™appel stream avec un callable).
