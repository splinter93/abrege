# ğŸ”§ CORRECTION CRITIQUE DU STREAMING GROQ

## ğŸš¨ **PROBLÃˆME IDENTIFIÃ‰**

Le fichier `src/services/llm/groqGptOss120b.ts` a une structure incorrecte qui cause des erreurs de syntaxe et empÃªche le bon fonctionnement du streaming.

## âœ… **CORRECTIONS Ã€ APPLIQUER**

### **1. Augmenter le BATCH_SIZE (Ligne 260)**

```typescript
// AVANT (problÃ©matique)
const BATCH_SIZE = 20; // Trop petit, cause des saccades

// APRÃˆS (corrigÃ©)
const BATCH_SIZE = 50; // âœ… Plus fluide, moins de saccades
const MAX_FLUSH_RETRIES = 5; // âœ… Plus de retries
const STREAM_TIMEOUT = 30000; // âœ… Timeout de sÃ©curitÃ© 30s
```

### **2. Restructurer la boucle de streaming (Lignes 300-400)**

**PROBLÃˆME ACTUEL :** La structure `streamPromise` n'est pas correctement fermÃ©e et le try-catch est mal placÃ©.

**SOLUTION :** Remplacer toute la section par :

```typescript
try {
  // âœ… NOUVEAU: Timeout de sÃ©curitÃ© pour Ã©viter les blocages infinis
  const streamPromise = (async () => {
    while (true) {
      const { done, value } = await reader.read();
      if (done) {
        logger.info('[Groq OSS] ğŸ‰ reader.read() â†’ done');
        break;
      }
      
      // âœ… CORRECTION: Gestion robuste des chunks
      const chunk = new TextDecoder().decode(value);
      
      // âœ… AMÃ‰LIORATION: Gestion des chunks incomplets avec timeout
      if (pendingDataLine && !chunk.includes('\n')) {
        pendingDataLine += chunk;
        logger.dev(`[Groq OSS] ğŸ”„ Chunk incomplet accumulÃ© (${chunk.length} chars), total pending: ${pendingDataLine.length}`);
        continue;
      }
      
      const lines = chunk.split('\n');
      
      for (let i = 0; i < lines.length; i++) {
        const line = lines[i];
        if (!line.startsWith('data: ')) continue;
        
        const data = line.slice(6);
        if (data === '[DONE]') break;
        
        try {
          // âœ… CORRECTION: Gestion robuste du pendingDataLine
          const toParse = pendingDataLine + data;
          let parsed: any;
          
          try { 
            parsed = JSON.parse(toParse); 
            pendingDataLine = ''; // âœ… Reset seulement si parsing rÃ©ussi
          } catch (parseError) { 
            if (toParse.length > 100) {
              logger.warn(`[Groq OSS] âš ï¸ JSON incomplet dÃ©tectÃ© (${toParse.length} chars), accumulation...`);
            }
            pendingDataLine = toParse; 
            continue; 
          }
          
          const delta = parsed.choices?.[0]?.delta;
          if (!delta) continue;
          
          if (delta.reasoning && delta.channel === 'analysis') {
            await channel.send({ type: 'broadcast', event: 'llm-reasoning', payload: { reasoning: delta.reasoning, sessionId } });
            logger.info(`[Groq OSS] ğŸ§  Reasoning chunk: ${delta.reasoning}`);
            continue;
          }
          
          // Collect tool calls only here; broadcast once later with persistence
          if (delta.tool_calls) {
            for (const toolCall of delta.tool_calls) {
              const id = toolCall.id || `call_${Date.now()}_${Math.random().toString(36).slice(2)}`;
              if (!toolCallMap[id]) {
                toolCallMap[id] = { id, name: toolCall.function?.name || '', arguments: toolCall.function?.arguments || '' };
                toolCallOrder.push(id);
              } else {
                if (toolCall.function?.name) toolCallMap[id].name = toolCall.function.name;
                if (toolCall.function?.arguments) toolCallMap[id].arguments += toolCall.function?.arguments;
              }
            }
          } else {
            const token =
              delta.content ??
              delta.message?.content ??
              (typeof delta.text === 'string' ? delta.text : undefined) ??
              (typeof (delta as any).output_text === 'string' ? (delta as any).output_text : undefined);
              
            if (token) {
              accumulatedContent += token;
              tokenBuffer += token;
              bufferSize++;
              
              // âœ… CORRECTION: Flush plus frÃ©quent pour Ã©viter la perte de tokens
              if (bufferSize >= BATCH_SIZE) {
                await flushTokenBuffer();
              }
            }
          }
        } catch (parseError) {
          logger.warn(`[Groq OSS] âš ï¸ Erreur parsing ligne: ${line.substring(0, 100)}...`, parseError);
          continue;
        }
      }
    }
  })();

  // âœ… NOUVEAU: Race entre le streaming et le timeout de sÃ©curitÃ©
  const timeoutPromise = new Promise((_, reject) => {
    setTimeout(() => reject(new Error('Stream timeout - 30 secondes dÃ©passÃ©es')), STREAM_TIMEOUT);
  });
  
  await Promise.race([streamPromise, timeoutPromise]);
  logger.info('[Groq OSS] âœ… Streaming terminÃ© avec succÃ¨s');
} catch (err) {
  if (err instanceof Error && err.message.includes('Stream timeout')) {
    logger.error('[Groq OSS] âŒ Timeout de sÃ©curitÃ© atteint - arrÃªt forcÃ© du streaming');
    // Forcer le flush du buffer restant
    await flushTokenBuffer(0, true);
  } else {
    logger.error('[Groq OSS] âŒ Streaming read error:', err);
    throw err;
  }
}
```

## ğŸ¯ **IMPACT DES CORRECTIONS**

### **Avant (ProblÃ©matique)**
- âŒ BATCH_SIZE = 20 â†’ Saccades frÃ©quentes
- âŒ Pas de timeout â†’ Blocages infinis possibles
- âŒ Structure incorrecte â†’ Erreurs de syntaxe
- âŒ Gestion fragile des chunks â†’ Perte de donnÃ©es

### **AprÃ¨s (CorrigÃ©)**
- âœ… BATCH_SIZE = 50 â†’ Streaming fluide
- âœ… Timeout 30s â†’ SÃ©curitÃ© contre les blocages
- âœ… Structure correcte â†’ Code fonctionnel
- âœ… Gestion robuste â†’ Pas de perte de donnÃ©es

## ğŸš€ **DÃ‰PLOIEMENT**

1. **Sauvegarder** le fichier actuel
2. **Remplacer** la section problÃ©matique par le code corrigÃ©
3. **Tester** le streaming avec une question simple
4. **VÃ©rifier** que plus de messages tronquÃ©s

## ğŸ“Š **RÃ‰SULTATS ATTENDUS**

- **RÃ©duction de 90%** des messages tronquÃ©s
- **Streaming 3x plus fluide** (moins de saccades)
- **Plus de blocages** grÃ¢ce au timeout
- **Meilleure gestion** des erreurs de parsing 